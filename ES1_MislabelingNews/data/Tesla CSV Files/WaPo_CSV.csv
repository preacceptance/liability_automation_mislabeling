"AccessionNum","SE","HD","BY","WC","PD","SN","SC","ED","PG","VOL","LA","CY","LP","TD","PUB"
"Document WP00000020230217ej2h0001o","	A-Section","	Tesla recall centers on self-driving software","	Faiz Siddiqui","	672 words","	17 February 2023","	The Washington Post","	WP","	FINAL","	A06",NA,"	English","	Copyright 2023, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - Tesla is recalling more than 360,000 vehicles equipped with its Full Self-Driving Beta software over apparent crash risks, according to a government regulator, the biggest setback yet for technology that Tesla has tied heavily to its valuation and future ambitions.  Officials said the software - part of Tesla's driver-assistance package - is being recalled because of the vehicles' failure to stop at intersections or exercise proper caution at yellow signals, come to a complete stop at stop signs, as well as adhere to posted speed limits. The company says it will send a remote update to remedy the problem, as it has done with past recalls. ","  It is the widest recall yet for the software, which has garnered widespread attention for Tesla's promises to leverage it to make vehicles autonomous.  Tesla CEO Elon Musk has said successfully executing on self-driving is ""the difference between Tesla being worth a lot of money and being worth basically zero.""  In its current form, Full Self-Driving Beta is a set of features that allows Tesla vehicles to maneuver city and residential streets, accelerating and stopping, making turns and navigating a route, without the physical input of the driver. Drivers are supposed to keep their hands on the wheel and pay attention at all times.  The recall notice, dated Wednesday, was posted to the National Highway Traffic Safety Administration website this week. It affects 362,758 vehicles, including Tesla models dating back to 2016.  ""The FSD Beta system may allow the vehicle to act unsafe around intersections, such as traveling straight through an intersection while in a turn-only lane, entering a stop sign-controlled intersection without coming to a complete stop, or proceeding into an intersection during a steady yellow traffic signal without due caution,"" the National Highway Traffic Safety Administration wrote in a letter. ""In addition, the system may respond insufficiently to changes in posted speed limits or not adequately account for the driver's adjustment of the vehicle's speed to exceed posted speed limits.""  Tesla did not immediately respond to a request for comment.  In a post on Twitter on Thursday, Musk argued the need for a software update should not constitute a recall by the traditional definition.  ""The word 'recall' for an over-the-air software update is anachronistic and just flat wrong!"" he tweeted.  The recall adds to an emerging series of challenges for the software and, following Musk's acquisition of Twitter, for Tesla itself. Tesla has shed hundreds of billions of dollars' worth of value since Musk set out to buy the social media site he now heads, though the electric vehicle company has recovered some of those losses this year.  Meanwhile, regulatory and public scrutiny has mounted since Full Self-Driving's wide release: the Justice Department has requested documents related to Autopilot and Full Self-Driving, Tesla confirmed in a regulatory filing last month, and a Tesla critic funded a Super Bowl commercial highlighting alleged flaws with the software.  Investors have expressed concern that Musk's focus on Twitter has the potential to take momentum away from Tesla.  Tesla had recalled Full Self-Driving Beta in the past, but not since making the software widely available to drivers who purchase the option, which costs $15,000 per vehicle.  Full Self-Driving Beta is a part of Tesla's larger driver-assistance suite, Autopilot, which allows vehicles to navigate from highway on-ramp to off-ramp, though drivers are supposed to monitor it at all times. Full Self-Driving expands the capabilities of Autopilot to city and residential streets.  In the past, Tesla had patched issues without immediate public notice through software updates, which are sometimes known as ""stealth recalls.""  But regulators have pressured Tesla to be more forthcoming about issues with its software. That has prompted a steady stream of recall notices in recent years, sometimes to the chagrin of Tesla and Musk.  Aaron Gregg contributed to this report.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20230217teslarecall  CO 	 nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc.  IN 	 i3302 : Computers/Consumer Electronics | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iaut : Automotive  NS 	 crecal : Product Recalls | c13 : Regulation/Government Policy | gptech : Personal Technology | c131 : Regulatory Bodies | cinfpo : Information Technology Policy | c26 : Product/Consumer Safety | ccat : Corporate/Industrial News | cexpro : Products/Services | gcat : Political/General News | glife : Living/Lifestyle | ncat : Content Types | nfact : Factiva Filters | nfcpin : C&E Industry News Filter  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020230215ej2f00028","	A-Section","	Digest","	Emily Birnbaum|Bloomberg News","	671 words","	15 February 2023","	The Washington Post","	WP","	FINAL","	A17",NA,"	English","	Copyright 2023, The Washington Post Co. All Rights Reserved","  AVIATION  Air India buys 470 jets from Boeing, Airbus ","  Air India unveiled deals for a record 470 jets from Airbus and Boeing, accelerating the rebirth of a national emblem under new owners Tata Group as Europe and the United States hailed deepening economic and political ties with New Delhi.  The provisional deals include 220 planes from Boeing and 250 from Airbus and eclipse previous records for a single airline as Air India vies with domestic giant IndiGo to serve what soon will be the world's largest population.  President Biden called the agreement ""historic.""  The Airbus order includes 210 A320neo narrow-body planes and 40 A350 wide-body aircraft, which Air India will use to fly ""ultralong routes,"" Tata Chairman N. Chandrasekaran said.  Boeing will supply 190 737 Max, 20 of its 787 Dreamliners and 10 mini-jumbo 777X.  Together with another 25Airbus jets to be leased to meet immediate needs, the overall acquisition reaches 495 jets, an Airbus executive said.  - Reuters  LABOR  Tesla workers launch union effort in N.Y.  Tesla workers in New York state are launching a unionization campaign, teeing up a potential first for the electric-vehicle maker and the latest labor challenge for chief executive Elon Musk.  The employees, who label data for Tesla's Autopilot technology at the company's plant in Buffalo, sent an email to Musk early Tuesday with their intent to unionize. Employees say they're seeking better pay and job security alongside a reduction in production pressures that they say have been harmful to their health.  Workers at the plant told Bloomberg News that Tesla monitors keystrokes to track how long employees spend per task and how much of the day they spend actively working, leading some to avoid taking bathroom breaks, six employees said.  ""People are tired of being treated like robots,"" said Al Celli, a member of the union's organizing committee.  If successful, the union would be a first for Tesla, which unlike other leading automakers has successfully resisted unionization at its U.S. factories.  Musk and Tesla's human resources chief did not respond to emailed inquiries. Tesla disbanded its media relations team in 2020.  - Bloomberg News  Also in Business  Christine Wilson, the sole Republican on the Federal Trade Commission, announced she is resigning from the agency over her fierce opposition to liberal FTC Chair Lina Khan's agenda. Wilson, who has spent months publicly criticizing Khan's efforts to crack down on corporate power using antitrust laws, said she is resigning because of Khan's ""defiance of legal precedent and her abuse of power to achieve desired outcomes."" Wilson's departure will leave the FTC without a Republican leader, although an effort is underway to nominate a new Republican to sit on the commission soon. Republican FTC Commissioner Noah Phillips stepped down from the agency late last year. The FTC declined to comment.  Hyundai and Kia will offer software upgrades for 8.3 million U.S. vehicles to help curb increasing car thefts using a method popularized on TikTok and other social media channels, the Korean automakers said Monday. TikTok videos showing how to steal cars made from 2015 to 2019 without push-button ignitions and immobilizing anti-theft devices have spread nationwide. That had led to at least 14 reported crashes and eight fatalities, the National Highway Traffic Safety Administration said.  Ford Motor has temporarily halted production and stopped shipments of its hot-selling F-150 Lightning electric pickup truck over an unidentified problem with its battery. Ford confirmed it had stopped building the plug-in pickup at its factory in Dearborn, Mich., while engineers seek a solution to a ""potential quality issue"" discovered on a truck at the plant. Ford said in an emailed statement that it is not delivering trucks that are in transit to dealers. Demand for the Lightning has been strong since Ford began selling the battery-powered model of the best-selling vehicle in the United States last April.  - From news services   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20230215digest0215  CO 	 tata : Tata Group | boeing : The Boeing Company | nia : Airbus SE | tsonsl : Tata Sons Ltd  IN 	 i364 : Aerospace Products/Parts | i3640010 : Civil Aircraft | i8396 : Diversified Holding Companies | iaer : Aerospace/Defense | ibcs : Business/Consumer Services | iindstrls : Industrial Goods  NS 	 ccat : Corporate/Industrial News | nnam : News Agency Materials | ncdig : Corporate Digests | ncat : Content Types | nfact : Factiva Filters | nfce : C&E Exclusion Filter | niwe : IWE Filter  RE 	 india : India | usa : United States | asiaz : Asia | bric : BRICS Countries | devgcoz : Emerging Market Countries | dvpcoz : Developing Economies | namz : North America | sasiaz : South Asia  IPD 	 National-Economy  PUB 	 Washington Post ",NA
"Document WP00000020230212ej2c0001d","	A-Section","	Critic blitzes Tesla with a Super Bowl ad","	Gerrit De Vynck Faiz Siddiqui","	1437 words","	12 February 2023","	The Washington Post","	WP","	FINAL","	A03",NA,"	English","	Copyright 2023, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - Electric carmaker Tesla is facing multiple challenges and distractions right now. This Super Bowl Sunday it will get another one, shown to audiences across the country.  California tech entrepreneur Dan O'Dowd, who has already poured millions of his own money into a campaign to get Tesla's Full Self-Driving tech banned from public roads, is funding a Super Bowl commercial that will play in D.C. and a handful of state capitals, including Austin, Tallahassee, Albany, Atlanta and Sacramento. ","  The ad shows a Tesla Model 3 that O'Dowd says has Full Self-Driving turned on running into a child-size mannequin, crossing over the centerline into oncoming traffic, driving past ""do not enter"" signs, passing a school bus with its flashing stop lights on and hitting a stroller in the road.  Tesla has released the latest version of its Full Self-Driving tech - which allows the car to maneuver city and residential streets without human input - to around 400,000 people in North America, quadrupling the number of people using it during much of 2022. That has renewed questions about the tech's safety. Government investigators are looking into whether Tesla's driver-assistance features caused crashes. And in January, a report emerged that a former Tesla engineer had testified that a 2016 demo of in which the company claimed one of its cars was driving itself was actually staged.  Some politicians, including Sens. Richard Blumenthal (D-Conn.) and Edward J. Markey (D-Mass.), have called for more oversight over Tesla's tech. But O'Dowd says he's making the investment in a new ad campaign because he wants to pressure politicians to make it a bigger priority.  Tesla doesn't advertise its cars in the traditional way, so the Super Bowl ad could reach people who don't already have a strong idea of what the company is, said Gene Munster, a longtime stock analyst and managing partner of Deepwater Asset Management. That said, Tesla chief executive Elon Musk is a ""master of spin"" and will just keep moving forward with his plans even if the ad generates bad publicity for him, Munster said.  ""At the end of the day he's just going to keep plowing forward with this until somebody, some governing body, tells him he can't,"" he said.  Musk did not respond to a request for comment. In the past, Musk has called O'Dowd crazy, and many of his supporters have accused O'Dowd of having a conflict of interest because his company, Green Hills Software, sells to Intel-owned Mobileye, which makes a computer chip that runs driver-assist software.  O'Dowd says that Mobileye is just one of hundreds of customers and that his motivation is driven purely by his concerns about the safety of Tesla's technology. He owns several Teslas himself and is especially fond of the Roadster, the first model the company produced.  Last year, Tesla issued a cease-and-desist letter after O'Dowd's group, the Dawn Project, published footage of the cars repeatedly striking child-size mannequins. A test run by a prominent Musk supporter included a real child to show the car recognizing the child and stopping. O'Dowd has offered to run the test with Musk or any of his other critics in-person, to prove the car is making the mistakes without any tampering.  Full Self-Driving is a set of features that enables Tesla vehicles to accelerate, steer, make turns and maneuver a car along a route on city and residential streets without physical input. It is part of Tesla's Autopilot driver-assistance package, but the ability to access the expanded features costs $15,000.  The company has led the way in pushing out driver-assistance features billed as steppingstones toward autonomy. Many other automakers provide lane-keeping, automatic braking and the ability for a car to keep a certain distance from the vehicle in front of it. But Tesla's Full Self-Driving has gone further, essentially letting the car maneuver itself beyond just on highways and onto busy city streets, though the company does caution drivers to remain alert and keep their hands on the steering wheel at all times.  Tesla pioneered the mass market for electric vehicles and began touting its self-driving ambitions in 2016. But it has had a rough few months.  In late January, as Musk stood trial for a 2018 tweet in which he declared he had ""funding secured"" to take the company private at $420 a share, a news report from Reuters revealed a top executive's testimony that Tesla's original self-driving video from 2016 was staged. Musk, meanwhile, had been distracted with Twitter as Tesla investors put pressure on him to turn his attention back to the company that is the source of much of his net worth.  After peaking at more than $1.2 trillion in valuation in late 2021, Tesla's stock price dove during 2022, as higher interest rates, Musk's chaotic takeover of Twitter and concerns about slowing demand and increased competition led many to sell their shares.  Now there are further signs that Tesla's Full Self-Driving Beta is falling short of its ambitions. Despite continual software updates, cars are repeating the same mistakes they have made for years: driving down light-rail tracks they should know are off-limits, video footage showed, or suddenly braking when there are no obstacles in the way.  Tesla has argued that its driver-assistance suite, Autopilot, is safer than normal driving, with Musk calling Autopilot ""unequivocally safer"" when crash data is compared. And the company has touted improvements to the software with its steady stream of releases.  Beyond the issues with Full Self-Driving, Tesla is facing a situation in which older, larger automakers have committed to electric vehicles, and Musk's public embrace of right-wing politics and culture war issues turns off some of his potential customers. Musk himself has said that successfully building self-driving software is ""the difference between Tesla being worth a lot of money and being worth basically zero.""  The technology is highly controversial, with some Tesla supporters saying it can easily take people on long drives without the need for intervention, and other users saying it makes repeated, dangerous mistakes. The latest version of the tech has generally been available to a group of tens of thousands of Tesla owners who the company says it has vetted.  Tesla Autopilot, the driver-assistance suite that encompasses Full Self-Driving Beta, is facing multiple investigations from the National Highway Traffic Safety Administration. The investigations relate to more than a dozen crashes with parked emergency vehicles while Autopilot was activated, and Tesla vehicles' tendency to suddenly brake for imaginary hazards, a phenomenon known as ""phantom braking.""  Lucia Sanchez, a spokesperson for NHTSA, declined to comment on the open investigation.  Meanwhile, Tesla confirmed in a regulatory filing last month that the Department of Justice had requested documents related to Autopilot and Full Self-Driving, part of an ongoing probe. Public scrutiny has mounted over the performance of the software as more vehicles equipped with it have hit the roads.  In January, the Intercept published footage of an eight-vehicle crash on the San Francisco Bay Bridge that allegedly was prompted by a Tesla using driver-assistance features, which abruptly braked in traffic, injuring nine people including a 2-year-old child, according to the report. The crash came not long after Musk announced the wide release of Full Self-Driving Beta to any users in the United States and Canada who had purchased the option - which was previously restricted to approved beta testers.  O'Dowd's Super Bowl ad is the first volley in a broader new media campaign that will target lawmakers across the country. O'Dowd says he hopes politicians will enact new laws regulating the testing of driver-assistance and autonomous driving features, and pressure regulators such as NHTSA, to speed up their investigations of the technology. Currently, carmakers can add new driver-assistance features - even those marketed as part of a self-driving package - as long as they warn drivers to stay alert at all times.  That isn't enough for O'Dowd and other critics of the technology. ""There isn't any urgency,"" he said. By hammering politicians with videos of the car making dangerous errors, O'Dowd says he hopes the government will move faster.  ""It needs to come off the road,"" he added.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20230212TESLASUPERBOWL  CO 	 teslmi : Tesla, Inc.  IN 	 i35101 : Passenger Cars | iintcir : Integrated Circuits | i35104 : Alternative Fuel Vehicles | iadrive : Autonomous Driving Technologies | iaut : Automotive | i34531 : Semiconductors | i351 : Motor Vehicles | iindele : Industrial Electronics | iindstrls : Industrial Goods | itech : Technology  NS 	 gcar : Cars | reqrau : Suggested Reading Automobiles | gcat : Political/General News | glife : Living/Lifestyle | redit : Selection of Top Stories/Trends/Analysis | reqr : Suggested Reading Industry News  RE 	 usca : California | usa : United States | namz : North America | usw : Western U.S.  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020221225eicp0000i","	A-Section","	Musk's Twitter drama depletes his stature","	Faiz Siddiqui","	2326 words","	25 December 2022","	The Washington Post","	WP","	FINAL","	A01",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  Elon Musk was speechless.  The Twitter CEO was on a live audio chat Tuesday night with software engineers when one user started quizzing him about the internal workings of the company's systems. Musk, who hours earlier said he would keep control of Twitter's software systems even though he plans to relinquish the CEO role, said the company's code needed a complete rewrite. One of the participants asked what he meant - pushing for him to explain it from top to bottom. ","  ""Amazing, wow,"" Musk said after hesitations and pauses. ""You're a jackass. … What a moron.""  The incident highlights the new reality facing Musk, who also runs Tesla and SpaceX: a crisis of confidence in his once-unquestioned brilliance.  That crisis accelerated as Tesla's stock price plunged nearly 20 percent last week to $123 per share on Friday, largely because of concerns about Musk. Also last week, roughly 58 percent of 17 million Twitter accounts that responded to an unscientific poll from Musk said he should step down as Twitter CEO, after helping create, then reverse new policies that proved controversial last weekend.  ""Historically he's been a pendulum between genius and reckless,"" said Gene Munster, managing partner at Loup Ventures. ""He's on reckless right now. He's way over recklessness.""  He added, ""It leaves people to view him … as slightly less of a genius.""  Musk has built his reputation on having a Midas touch with the companies he runs - something many investors and experts thought he would bring to Twitter when he purchased it for $44 billion in October, paying nearly twice as much as it was worth by some analyst estimates. He is known for sleeping on the factory floor at Tesla, demanding long hours and quick turnarounds from his workers. He is seen as an engineering genius, propelling promises of cars that can drive themselves and rockets that can take humans to Mars.  But that image is unraveling. Some Twitter employees who worked with Musk are doubtful his management style will allow him to turn the company around. And some investors in Tesla, by far the biggest source of his wealth, have begun to see him as a liability. Musk's distraction has prompted questions about leadership of SpaceX as well, though it is much less reliant on his active involvement. Meanwhile, Neuralink and Boring Co., two companies he founded, lag on promises.  Musk's net worth - largely fueled by his stake in Tesla, which has fallen by more than half in 2022 - has plunged this year from roughly $270 billion to below $140 billion on Friday, according to the Bloomberg Billionaires Index. That fall has relieved him of the title of the world's richest man and called into question his ability to keep up with his billions of dollars in loans.  Musk is repeatedly described as a man obsessed with Twitter in all the wrong ways, who is failing at protecting both his new investment and his previous ones, according to interviews with a half-dozen former Twitter employees and people in Musk's orbit, who spoke on the condition of anonymity for fear of retribution or because they were not authorized to speak publicly about company matters.  Musk last week said Twitter is in a financial hole and facing a cash crunch - even as it slashed more than half of the workforce and closed offices.  ""We have an emergency fire drill on our hands,"" Musk said on Twitter Spaces. ""Aspirationally, I'm not naturally capricious.""  Musk has always been unpredictable and freewheeling with his public persona, but with Twitter, his actions have directly affected the business, turning off some of the company's users and pushing away advertisers, said Jo-Ellen Pozner, a management professor at Santa Clara University's Leavey School of Business.  ""It really feels destabilizing for the whole Twitter community,"" she said, adding that the reputation of a CEO does affect businesses and their stock prices - and could even prompt consumers to choose another vehicle.  Musk and Twitter - which has disbanded most of its public relations team - did not respond to requests for comment.  Holed up in a 10th-floor conference room  Musk, who is South African and migrated to North America as a teenager, first forged his image as a tech wizard by founding the company that became PayPal. He funneled much of his approximately $165 million in gains from the sale of PayPal into two ventures: Tesla and SpaceX. SpaceX went on to become the most successful private spaceflight company in history, pioneering reusable rockets and launching astronauts to the International Space Station.  Tesla, meanwhile, brought electric vehicles to the mainstream with sleek, fast and competitively priced sedans and SUVs that shattered the frumpy image of eco-conscious cars. His closest allies have held out faith even as he has missed major deadlines for selling new vehicle models and rolling out self-driving technology.  Musk has been focused almost solely on Twitter since he bought it, planning to reinvent the company as an engineering-driven operation. He immediately ousted Twitter's previous executives and embarked on a campaign of harsh layoffs that cut the company in half. Many of Musk's supporters, who had followed his rise at Tesla, gave him the benefit of the doubt that he had a plan to transform Twitter.  But he immediately spooked advertisers by engaging in a baseless accusation about the attack on Paul Pelosi and dialed back Twitter's content moderation, prompting calls from civil rights groups for advertisers to suspend their marketing on the site. And he had to pull back his first major product launch - Twitter Blue Verified - after a day, when impersonators wreaked havoc.  Musk appears to be struggling to grasp Twitter's business, the people said, and he demands a stance from his employees that stifles discussion of problems. ""He doesn't see from the zoom-out view at all,"" one of the people close to Musk and his team said, describing him as ""uncovering and solving and programming all night.""  He has been holed up in a 10th-floor conference area with a staging room for visitors - where they often remain for more than an hour before being called in. They are instructed not to speak until Musk does. And when they do finally meet with him, he's sometimes watching YouTube videos.  Many staffers have learned they can't rely on the erratic and unpredictable Musk, even as he makes assurances about the various facets of the company they have raised as concerns.  The driving team behind Project Eraser - which carries out functions such as deleting the user data of those who ask, part of compliance with federal requirements - has been gutted. Musk has brought in a new roster of leaders, many of them loyalists.  When one executive met with Musk and voiced concerns about the Federal Trade Commission's consent decree, Musk assured that person there was nothing to worry about. He said Tesla had plenty of experience on privacy matters, and pointed to his deep knowledge and awareness of the constraints Twitter was under.  Minutes after the meeting concluded, a Musk subordinate emailed: Could the executive send over a copy of the consent decree they had just discussed?  Instead of focusing on plans to make the site a competitor to YouTube with video and rolling out other new features that earn revenue, he instead got sucked into the culture wars, the people said.  That took the form of the Twitter Files, an examination by some journalists of many of the company's actions before Musk's arrival, such as the blocking of a New York Post story that dug into the contents of Hunter Biden's laptop and the ban on former president Donald Trump.  Musk chose Bari Weiss, a former New York Times columnist, as one of the writers invited inside the company to go through documents.  ""Please give Bari full access to everything at Twitter,"" Musk wrote to a subordinate in a Signal message viewed by The Washington Post. ""No limits at all.""  That was concerning to many inside Twitter - particularly those familiar with the 2011 FTC settlement after hacks of high-profile accounts, including that of then-President Barack Obama. Staffers responsible for her onboarding pushed back and refused to grant Weiss the full access Musk had requested, believing it would violate the settlement.  One former employee described that step as ""super unprecedented"" and ""highly inappropriate,"" saying Twitter would never have granted that level of access to an outside party who might suddenly be able to read direct messages, for example.  The pushback, however, was not taken as seriously at senior levels.  Days later, Musk announced deputy general counsel Jim Baker had been ""exited"" from the company, as the CEO cited what he called his ""possible role in suppression of information important to the public dialogue."" Former employees said it would have been normal for an attorney to review documents for release.  That same day, Alan Rosa, Twitter's chief information security officer in charge of access matters, was fired from the company as well. Employees that week found Weiss's name searchable in Slack, the company's internal messaging service. But her access was overseen by a chaperone, new Twitter Trust and Safety chief Ella Irwin.  Irwin's name appeared in a watermark on the Twitter Files. When Twitter suspended more than half a dozen journalists this month over alleged violations of its rules on doxing - the sharing of private information - the suspensions were labeled in internal systems ""direction of Ella.""  Musk had also publicized an old message from his previous Trust and Safety head and taken aim at Twitter executives, unleashing a swarm of criticism on employees - sometimes while they were still working for the company.  ""These guys did amazing damage,"" one former employee said of Musk's circle at Twitter, which included employees of his other companies and friends who lacked expertise on Twitter. ""They are basically bullying their way to getting 'super god' access to these things. All they're doing is they're witch hunting for Elon, so they can find people talking [about him] so they can fire them.""  Musk is running the newly private company largely on his instincts - mirroring the workflows of his other major technology company: Tesla. The electric car company, the world's most valuable automaker, has eschewed market research in its dominance of the electric vehicle space, seeding the automotive industry with a raw and authentic expressions of Musk's id.  At Tesla, employees often find out about deadlines and major product changes through tweeted edicts. But they have also grown used to the CEO's shoot-from-the-hip attitude, his reliance on his gut instincts rather than the research and development arms typical of multibillion-dollar corporations.  The unraveling  But Tesla's stock price has plummeted - which Musk frequently attributes to economic trends.  ""As bank savings account interest rates, which are guaranteed, start to approach stock market returns, which are *not* guaranteed, people will increasingly move their money out of stocks into cash, thus causing stocks to drop,"" he said in a tweet Tuesday.  But analysts have pointed to problems more specific to Tesla and concern with Musk's time at Twitter, suggesting in essence that the sheen has worn off a company whose value was not rooted in its fundamentals.  ""I felt for a while he was given a pass,"" said Karl Brauer, executive analyst at the website iSeeCars. ""'Oh, it's Elon. He's Midas: If he's touching it, it's going to be successful.' Now a certain number of people have stopped giving him a pass on things that probably should have been looked at a little more critically or acknowledged as potential downside.""  The crisis in confidence in his leadership accelerated when Musk began making changes to Twitter to address his personal problems and concerns.  Earlier this month, he reneged on a previous commitment to allow an account on Twitter that published the location of his private jet, which he held up as an example of his free speech principles. After abruptly suspending @ElonJet, Twitter suspended journalists who tweeted about it, drawing ire from both sides of the political spectrum.  He launched a poll, which directed Musk to allow them back on the site.  ""The people have spoken,"" he tweeted that Friday.  Musk jetted to Qatar for the World Cup final on Sunday, where he was spotted alongside former president Trump's son-in-law Jared Kushner and Qatari leaders.  That day, Twitter announced a new policy: It was banning the promotion of outside social media sites on its platform, including Facebook, Instagram and Trump-backed Truth Social. Users would no longer be able to promote outside links to those sites and others. Twitter said cross-posting of content would be allowed, but it would no longer permit ""free promotion.""  The criticism was swift, and even loyalists expressed concern. Musk apologized.  ""Going forward, there will be a vote for major policy changes,"" he tweeted. ""My apologies. Won't happen again.""  Then Musk launched a new poll. ""Should I step down as head of Twitter?"" he wrote in a tweet. ""I will abide by the results of this poll.""  By Monday morning, the result was clear that Musk should step down. He went silent on the platform for much of the day - one of his longer stretches as a prolific tweeter to his more than 120 million followers. He responded to a few tweets later in the day calling the results into question.  On Tuesday, he said he would resign - with caveats.  ""I will resign as CEO as soon as I find someone foolish enough to take the job!"" he wrote in a tweet. ""After that, I will just run the software & servers teams.""  Gerrit De Vynck and Cat Zakrzewski contributed to this report.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20221225muskmeltdown  CO 	 twnit : Twitter Inc.  IN 	 isocial : Social Media Platforms/Tools | iint : Online Service Providers | imed : Media/Entertainment | itech : Technology  NS 	 cslmc : Senior Level Management | npag : Page One Stories | reqrio : Suggested Reading Internet/Online Services | reqrme : Suggested Reading Media | c41 : Management | ccat : Corporate/Industrial News | ncat : Content Types | nfact : Factiva Filters | nfcpin : C&E Industry News Filter | redit : Selection of Top Stories/Trends/Analysis | reqr : Suggested Reading Industry News  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020221101eib100014","	A-Section","	As his power grows, Musk worries many in Washington","	Mary Jordan","	2605 words","	1 November 2022","	The Washington Post","	WP","	FINAL","	A01",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  Between launching four astronauts and 54 satellites into orbit, unveiling an electric freight truck and taking over Twitter this past month, Elon Musk made time to offer unsolicited peace plans for Taiwan and Ukraine, antagonizing those countries' leaders and irking Washington, too.  Musk, the richest man in the world, then irritated some Pentagon officials by announcing he didn't want to keep paying for his private satellite service in Ukraine, before later walking back the threat. ","  As Musk, 51, inserts himself into volatile geopolitical issues, many Washington policymakers worry from the sidelines as he bypasses them.  A two-decade partnership between Musk and the federal government helped the United States return to global dominance in space and shift to electric cars, and made the tech geek an internationally famous CEO. But many in Washington, even as they praise his work in areas of national security, now see Musk as too powerful and too reckless.  Citing Musk's public ridicule of those who snub him - the billionaire has called President Biden a ""damp sock puppet"" and said Sen. Elizabeth Warren (D-Mass.) reminds him of ""my friend's angry mom"" - many of the two dozen top government officials interviewed for this article would only speak about Musk on the condition of anonymity. But nearly all described him as being as erratic and arrogant as he is brilliant.  ""Elon, The Everywhere"" is what one White House official called him. ""He believes he is such a gift to mankind that he doesn't need any guardrails, that he knows best.""  ""He sees himself as above the presidency,"" said Jill Lepore, a Harvard historian who hosted podcasts on Musk.  Musk declined to comment for this story, but he says he weighs in on important problems and described his mission as ""enhancing the future of humanity."" He said his Ukraine plan could avert possible nuclear war, and that his Taiwan proposal could ease dangerous regional tensions.  But Musk's freelance diplomacy is angering allies at the same time he takes over a media platform with hundreds of millions of users.  ""The bottom line is that people hang on his every word because he has delivered so many times,"" said Sen. Richard J. Durbin (D-Ill.). ""I hope he shows some respect for that responsibility.""  Sen. Lindsey O. Graham (R-S.C.) called Musk's plan for Ukraine an ""affront"" to its people, and even suggested that federal subsidies that help makers of electric cars might be better spent.  Musk's relationship with Washington started out strong. ""I love you!"" Musk blurted out when a NASA official called to tell him in 2008 that he got a $1.6 billion contract at a time when he was heavily in debt. Washington then poured billions more into Musk's company as it developed its rockets and space capsule. SpaceX delivered, rebuilding the flagging U.S. space program.  His bipartisan efforts once helped him win over Washington. He dined with President Barack Obama and joined President Donald Trump's economic councils. He donated to candidates of both parties. Now, he bashes Biden and says he plans to vote for a Republican president in 2024.  These days, the eccentric entrepreneur rarely visits Washington and is increasingly critical of the federal government. He does talk to foreign presidents and prime ministers, according to people who work directly with him. Musk sells his state-of-the-art rockets and aerospace technology to South Korea, Turkey and a growing list of other countries. He has Tesla factories in Germany and China. He also owns and controls more than 3,000 satellites circling the Earth - far more than any nation, including the United States.  In May, Brazilian officials said Musk met with Jair Bolsonaro, the right-wing ultranationalist who lost his bid for reelection as president this week. Musk said he spoke with Russian President Vladimir Putin 18 months ago, but denied a report that he talked to Putin just before offering his Ukrainian peace plan that was widely condemned as pro-Russian.  Though Musk needs Washington less now that he is a global powerhouse, Washington continues to depend on him. The U.S. military uses his rockets and satellite communications services for its drones, ships and aircraft. NASA has no way to get American astronauts to the International Space Station without his space capsule. And, at a time when climate change is a top White House priority, he has more electric cars on U.S. roads than any other manufacturer.  Several top government officials said they are working on decreasing their reliance on Musk, including partnering with and nurturing competitors with government contracts and subsidies. ""There's not just SpaceX. There are other entities that we can certainly partner with when it comes to providing Ukraine what they need on the battlefield,"" Sabrina Singh, deputy Pentagon press secretary, told reporters in October.  A key concern now that Musk has completed his purchase of Twitter is his web of overseas holdings and foreign investors, including his massive Tesla factory in China, and possible leverage others could have over Musk now that he controls a platform where some users have spread misinformation and ratcheted up political divisiveness. As a U.S. defense contractor, Musk has been vetted, but several top officials said they wanted a more thorough review, including of any expansion plans in Russia and China. Warren and others have called his Twitter purchase a ""danger to democracy.""  Washington has dealt before with powerful tycoons who dominated railroads, oil or a key economic sector, said Richard Haass, president of the Council on Foreign Relations. ""But what's a bit different here is Musk's ability to project his political agenda and the fact that now that we have technology and media that allows individuals to essentially become their own network or channel,"" Haass said.  Because Musk has business investments in China, and, according to Russian and other news reports, said last year at a Kremlin-sponsored event for students that he was planning one in Russia, several top U.S. government officials wonder if Musk's business interests affect his views on foreign affairs.  The economic turmoil since the Ukraine war began has dented the fortunes of many people including Musk, whose personal wealth dropped by tens of billions, to about $210 billion, according to Bloomberg's Billionaires Index.  Two people who know him well said Musk is impulsive and that makes him say things that harm his own interests - a tendency that makes it difficult for government officials to count on Musk. Musk himself has said he has Asperger's, a form of autism, and no one should expect him to be a ""chill, normal dude.""  ""He shoots himself in the foot all the time. He should not be getting into politics,"" said one person who has worked with him for years.  ""I have been as shocked as anyone these last few months at some of the things he has waded into,"" said Lori Garver, former deputy administrator at NASA. She worries about the consequences. SpaceX restored U.S. leadership in space, but his politically charged comments attract critics who are starting to ask, ""Why is taxpayer money going to this billionaire?""  ""It's disappointing,"" she said.  Shifting power  Musk set his sights on D.C. 20 years ago. A South African who moved to Silicon Valley, Musk became a U.S. citizen in 2002 - the year he used his payment from the sale of PayPal, the electronic payment firm he helped found, to start SpaceX. It was a big risk, and he needed high-dollar government contracts to survive. In early 2003, Musk announced he would have a ""significant presence"" in the nation's capital so that he could build a ""close working relationship with the federal government.""  He invested in Tesla around the same time and soon took over running it, tapping into financial subsidies and tax credits Washington was offering to wean the country off gasoline. California alone gave Tesla $3.2 billion in subsidies, according to figures provided by the office of California Gov. Gavin Newsom (D).  A review of public disclosure forms show that for brief periods of time, Musk hired dozens of lobbyists, many of them former staff members of powerful members of Congress. Rohan Patel, who worked on energy and transportation in the Obama White House, runs Tesla's regulatory and legislative affairs in Washington.  SpaceX has spent more than $22 million to lobby Washington over the years, according to OpenSecrets, a research group tracking money in politics. Musk, himself, proved a savvy political operator. He flew into Washington 40 times between 2008 and 2013, according to flight records obtained by Musk biographer Ashlee Vance. He knocked on doors and invited officials to breakfast.  When backroom persuasion didn't get results, he learned that publicity helps.  On a sunny Wednesday in June 2014, Musk parked his new ""space taxi"" a few blocks from Capitol Hill. He had hauled the capsule designed to carry seven astronauts into orbit across the country from his California factory and invited TV cameras, along with government officials, to check it out.  ""Great job, Elon!"" yelled Dana Rohrabacher, a Republican member of Congress, as he climbed out of the sleek spacecraft. Democrats applauded, too, that day. Musk was beaming. He was about to get richer.  The United States then relied on Russia to carry American astronauts to the International Space Station, paying Moscow tens of millions of dollars for each seat. Musk promised he would put an end to that and rebuild the American space program. Obama was in the White House and wanted to let private companies like SpaceX try. Weeks after Musk brought his space taxi to D.C., NASA awarded him a $2.6 billion contract.  Musk also pursued Pentagon contracts and found public confrontation helped. In a sparsely attended Capitol Hill hearing in 2014, he made headlines by slamming the joint venture between aerospace giants Lockheed Martin and Boeing that supplied rockets to the Air Force. He called it a ""monopoly"" and said it was vastly overcharging taxpayers.  ""Elon was saying, 'Give me a chance,'"" said Scott Pace, a former NASA official who spoke at that hearing.  The Pentagon did, and Musk delivered. His game-changing, partly reusable Falcon rockets were considerably less expensive.  Now, just eight years later, Musk is the goliath of the space industry. And Musk's success has shifted the dynamic with Washington.  Democrats are more vocal on the need to rein in Musk.  House Minority Leader Kevin McCarthy (R-Calif.) calls Musk ""my good friend,"" and Musk spoke at his August fundraiser. In June, Musk, who recently moved from California to Texas, announced he voted for Mayra Flores in a congressional primary - and said it was the first time he voted for a Republican. He also bashed Democrats as too extreme and too controlled by unions and publicly predicted a ""massive red wave"" in November.  But some Republican lawmakers are skeptical Musk's new coziness with the GOP will last. ""He's another bullshit artist"" is how former president Donald Trump described Musk at a July rally in Alaska.  A rare area of bipartisan agreement is that for certain vital issues, especially national security, the United States should not depend on any one person or company, and the federal government is making moves to lessen dependence on Musk.  NASA has funded Boeing's Starliner capsule to compete with SpaceX to transport astronauts. (Blue Origin, which is owned by Jeff Bezos, who also owns The Washington Post, is also a competitor for NASA contracts.) NASA officials said Starliner's delays and higher cost show why SpaceX is so dominant. ""But still, we need a second option,"" said one influential member of Congress.  The Federal Communications Commission in August decided it would not give SpaceX's Starlink - which is now operating in 40 countries - a $900 million subsidy to bring broadband to rural areas even though that money had been provisionally granted in the waning days of the Trump administration. The FCC said the $600 satellite dish a home would need to purchase from SpaceX was a factor. A top SpaceX official called the rejection ""unreasonable"" and ""grossly unfair.""  Congress also has been encouraging Ford and other automakers to build electric cars. A new condition on a federal $7,500 rebate is that the price of the new car cannot top $55,000. Most Tesla models cost more.  But Musk will be eligible for many subsidies and incentives, including for his electric charging stations. He just announced his Superchargers are now in 46 countries.  Musk hates ""a false narrative out there that he is a grifter who survived off government handouts,"" said Eric Berger, author of ""Liftoff,"" a history of SpaceX. ""He sees the government as a double-edge sword,"" Berger said. It can help but its bureaucracy slows him down. ""He is really frustrated by the dizzying array of federal agencies that he has to deal with - and the bigger he gets, the more there is.""  ""Those bastards"" is how Musk refers to officials at the Securities and Exchange Commission. The SEC fined Musk and Tesla $20 million each after Musk tweeted that he had ""funding secured"" to take Tesla private at $420 a share, after finding that was not true. The SEC is also now investigating Musk in connection with his Twitter takeover, including whether he complied with disclosure laws. Musk's lawyer told a judge that the SEC was trying to ""muzzle and harass"" the businessman because he is an ""outspoken critic of the government.""  Musk believes Tesla's driver assistance system will save many lives and has said he is irritated by the publicity around the federal safety investigation into his Autopilot system. But government officials say it's worth looking into whether the self-driving system was a factor in crashes, including some that were fatal.  Avoiding confrontation  Few want a head-on confrontation with Musk.  Biden got into one after Musk was not invited to a White House conference on electric vehicles in August 2021. Musk tweeted that the snub was the ""next level of insanity,"" and that Biden was controlled by unions. Musk also has been drawing attention to any Biden misstep, including when he mistakenly read instructions meant only for him on his teleprompter.  Apart from not wanting to get on his bad side, many in Washington admire his accomplishments and want to work with him. At the Pentagon, there are many who see Musk as a secret weapon. His Starlink satellite systems mean Ukrainian soldiers have real-time information about military targets, and other countries are looking at how it can help their defense efforts.  In April, the White House said Musk was invited to a discussion about electric cars and charging stations and did make an appearance by teleconferencing.  ""We used to be on the same page. Now, we are not always. It's great when we are,"" said one member of Congress. ""One thing is clear: Musk believes he knows best, and he will do whatever he wants - and that can be good and it can be bad.""  Meanwhile, Musk is also working on an ever-growing number of ventures, from building robots that can cook dinner to plans for colonizing Mars.  Lepore, the historian, said Musk's power is not like anything the country has seen before. ""We should be worried, not because it's inevitable that his influence would be malignant, but it's inevitable that it would be a huge influence.""   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20221101ElonConcerns  IN 	 i35104 : Alternative Fuel Vehicles | iaut : Automotive | i351 : Motor Vehicles  NS 	 gdip : International Relations | gvexe : Executive Branch | gcat : Political/General News | npag : Page One Stories | reqrau : Suggested Reading Automobiles | gpir : Politics/International Relations | gpol : Domestic Politics | gvbod : Government Bodies | ncat : Content Types | redit : Selection of Top Stories/Trends/Analysis | reqr : Suggested Reading Industry News  RE 	 usa : United States | ukrn : Ukraine | uss : Southern U.S. | usdc : Washington DC | dvpcoz : Developing Economies | eeurz : Central/Eastern Europe | eurz : Europe | namz : North America  IPD 	 National-Enterprise  PUB 	 Washington Post ",NA
"Document WP00000020220826ei8q0001u","	A-Section","	Tesla demands removal of video of cars hitting child-size mannequins","	Faiz Siddiqui Gerrit De Vynck","	855 words","	26 August 2022","	The Washington Post","	WP","	FINAL","	A17",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - Tesla is demanding that an advocacy group take down videos of its vehicles striking child-size mannequins, alleging the footage is defamatory and misrepresents its most advanced driver-assistance software.  In a cease-and-desist letter obtained by The Post, Tesla objects to a video commercial by anti- ""Full Self-Driving"" group the Dawn Project that appears to show the electric vehicles running over mannequins at speeds over 20 mph while allegedly using the technology. The commercial urges banning the Tesla Full Self-Driving Beta software, which enables cars on city and residential streets to automatically lane-keep, change lanes and steer. ","  The commercial led to a surge of news articles and criticism of Tesla's software, which is being tested in an early-release version by more than 100,000 users on public streets in countries including the United States and Canada. It also triggered blowback from Tesla supporters who said the test could have been manipulated. Some of them sought to re-create the demonstrations - sometimes involving real children - in an effort to show that Tesla's software does actually work.  The back and forth is the latest escalation in an ongoing spat between Tesla's vocal fan community and critics of its driver-assistance software.  The man behind the Dawn Project, tech founder and billionaire Dan O'Dowd, has become an unlikely and controversial leader of the latter group. He runs Green Hills Software, which makes operating systems for airplanes and cars, potentially making him a competitor in the market for car software. He also ran for the U.S. Senate this year, and broadcast his videos on TV and online as campaign ads. (One such ad features reporting from The Washington Post, which was not involved.)  O'Dowd says his motivation for going after Tesla is a conviction that the technology, like many other pieces of software that people rely on in the modern world, isn't safe enough and needs to be redesigned - and in this case needs to be banned.  ""We have been busy hooking up and putting computers in charge of the things that millions of people's lives depend on: self-driving cars is one of those,"" O'Dowd said.  Full Self-Driving Beta is still in development and is typically used by approved drivers who have qualified after a safety screening or have otherwise been granted access. A $12,000 software upgrade makes vehicles capable of receiving it - though the price is soon to go up. Tesla doesn't claim the software is autonomous, and the system requires the driver to be alert at all times - issuing escalating warnings if a driver is not paying attention before turning off the features.  Tesla has pointed to the ability of technologies like its Autopilot driver-assistance system to ""reduce the frequency and severity of traffic crashes and save thousands of lives each year."" Musk has said Autopilot is ""unequivocally safer"" than normal driving.  Musk and Tesla did not respond to a request for comment.  Regulatory and police agencies have urged users not to involve children in tests or attempt to simulate safety demonstrations, which are conducted under strict, tightly controlled sets of conditions.  That did not stop one Tesla superfan from conducting a test involving a child in an attempt to prove that Full Self-Driving Beta is safe, after the parent agreed to sit behind the wheel for the demo. The vehicle in the video slowly approached both a child-size mannequin and a real child, and both times slowed down and stopped. YouTube took down the video after it was flagged to the site by CNBC, the outlet reported.  The cease-and-desist letter from Tesla leaned on an investigation by the news site Electrek, which alleged that Tesla's Full Self-Driving Beta ""never engaged"" during the Dawn Project's test using mannequins. Aspects of the report have since come into question, after the Dawn Project pointed to raw data and other information indicating that Full Self-Driving was activated during the demonstrations.  ""The purported tests misuse and misrepresent the capabilities of Tesla's technology, and disregard widely recognized testing performed by independent agencies as well as the experiences shared by our customers,"" Tesla deputy general counsel Dinna Eskin wrote in the letter dated Aug. 11, the day after the Electrek article.  The letter demands the campaign immediately remove the videos and accused the group of ""unsafe and improper use"" of FSD Beta. ""Your actions actually put consumers at risk,"" Tesla alleged.  Fred Lambert, editor in chief of Electrek, pointed to what he alleged were ""serious inconsistencies"" with the footage that emerged to support the commercial's claims, and said he has repeatedly asked O'Dowd for clarification.  Cease-and-desist orders sometimes precede a lawsuit but can also be used to persuade an opponent to back down under the threat of legal action.  O'Dowd said he did not intend to take down the video commercial and instead pledged more money into the effort.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220826teslakids  CO 	 teslmi : Tesla, Inc.  IN 	 i35104 : Alternative Fuel Vehicles | iadrive : Autonomous Driving Technologies | iaut : Automotive | i351 : Motor Vehicles | itech : Technology  NS 	 reqrau : Suggested Reading Automobiles | redit : Selection of Top Stories/Trends/Analysis | reqr : Suggested Reading Industry News  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020220627ei6r0000f","	Editorial-Opinion","	The problem with self-driving cars","	Editorial Board","	515 words","	27 June 2022","	The Washington Post","	WP","	FINAL","	A18",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  THE NATIONAL Highway Traffic Safety Administration released a report this month on crashes involving vehicles with automated technology. Self-driving cars may not really be the problem - the problem is cars that don't drive themselves but manage to convince the drivers that they do. ","  The report includes data collected over a 10-month period following an order last summer that required automakers to report incidents that included cars with advanced driver-assistance systems. Fully autonomous vehicles such as Google spinoff Waymo or General Motors- controlled Cruise LLC ended up in 130 crashes, most of them occurring when the car was struck from behind, 108 of which resulted in no injuries and only one of which resulted in a serious injury. Meanwhile, cars with partially automated systems experienced nearly 400 crashes. (The NHTSA did not provide the total number of hours or miles driven.) Six people died and five were seriously injured. A previous crash in a Tesla Model S ended in a fire that took four hours and more than 30,000 gallons of water to put out.  The study is a reminder not only that the fully self-driving future many people imagine is a long way off, but also that a present in which cars can perform on their own some functions traditionally reserved for humans can prove dangerous. The NHTSA also recently upgraded a probe of Tesla Autopilot to an engineering analysis; investigators are examining the feature's responsibility for repeated collisions with parked emergency vehicles such as ambulances and police cruisers - which drivers should have been able to see about eight seconds before impact, but which they took no action to avoid until two to five seconds before impact.  The issue, it appears, may not be merely that automated systems themselves have flaws but also that drivers are relying too heavily on systems that aren't designed to do all the work without human input. After all, when something is called ""full self-driving,"" it's easy to expect, consciously or subconsciously, that it will fully drive itself. Even when software supposedly requires drivers to pay attention, the fact that a car can take care of some things can lull people into thinking the car will take care of all things - or into relaxing more generally, so that if something does go wrong they are unprepared to respond. This is what the NHTSA means when it says it will examine whether Tesla Autopilot ""may exacerbate human factors or behavioral safety risks.""  So far, there's no data to show whether partial-automation features render driving safer or less safe. The NHTSA could certainly try to make the former more likely by imposing minimum performance standards in addition to restrictions on terminology that exaggerates a vehicle's capabilities. But drivers themselves would do well to remember that the era of self-driving cars for the most part hasn't yet begun - even when they're at the wheel of a vehicle that does some of the work for them.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP202206272edit-selfdriving  CO 	 waymmo : Waymo LLC | nathg : National Highway Traffic Safety Administration | goog : Alphabet Inc.  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology  NS 	 gtacc : Transport Accidents | nedi : Editorials | gcat : Political/General News | gdis : Disasters/Accidents | gmmdis : Accidents/Man-made Disasters | gtrans : Transport | ncat : Content Types  RE 	 usa : United States | namz : North America  IPD 	 Editorial-Opinion  PUB 	 Washington Post ",NA
"Document WP00000020220616ei6g0001h","	A-Section","	Tesla's Autopilot involved in 273 crashes in the past year","	Faiz Siddiqui Rachel Lerman Jeremy B. Merrill","	1658 words","	16 June 2022","	The Washington Post","	WP","	FINAL","	A16",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - Tesla vehicles running its Autopilot software have been involved in 273 reported crashes over roughly the past year, according to regulators, far more than previously known and providing concrete evidence regarding the real-world performance of its futuristic features.  The numbers, which were published by the National Highway Traffic Safety Administration for the first time Wednesday, show that Tesla vehicles made up nearly 70 percent of the 392 crashes involving advanced driver-assistance systems reported since last July, and a majority of the fatalities and serious injuries - some of which date back further than a year. Eight of the Tesla crashes took place before June 2021, according to data released by NHTSA on Wednesday morning. ","  Previously, NHTSA said it had probed 42 crashes potentially involving driver assistance, 35 of which included Tesla vehicles, in a more limited data set that stretched back to 2016.  Of the six fatalities listed in the data set published Wednesday, five were tied to Tesla vehicles - including a July 2021 crash involving a pedestrian in Flushing, Queens, and a fatal crash in March in Castro Valley, Calif. Some dated as far back as 2019.  Tesla Autopilot is a suite of systems that allows drivers to cede physical control of their electric vehicles, though they must pay attention at all times. The cars can maintain speed and safe distance behind other cars, stay within their lane lines and make lane changes on highways. An expanded set of features, called the ""Full Self-Driving"" beta, adds the ability to maneuver city and residential streets, halting at stop signs and traffic lights, and making turns while navigating vehicles from point to point.  But some transportation safety experts have raised concerns about the technology's safety, since it is being tested and trained on public roads with other drivers. Federal officials have targeted Tesla in recent months with an increasing number of investigations, recalls and even public admonishments directed at the company.  The new data set stems from a federal order last summer requiring automakers to report crashes involving driver assistance to assess whether the technology presented safety risks. Tesla's vehicles have been found to shut off the advanced driver-assistance system, Autopilot, around one second before impact, according to the regulators.  The NHTSA order required manufacturers to disclose crashes where the software was in use within 30 seconds of the crash, in part to mitigate the concern that manufacturers would hide crashes by claiming the software wasn't in use at the time of the impact.  ""These technologies hold great promise to improve safety, but we need to understand how these vehicles are performing in real-world situations,"" NHTSA's administrator, Steven Cliff, said in a call with media about the full data set from manufacturers.  Tesla did not immediately respond to a request for comment. It has said that Autopilot is safer than normal driving when crash data is compared. The company has also pointed to the vast number of traffic crash deaths on U.S. roadways annually, estimated by NHTSA at 42,915 in 2021, hailing the promise of technologies like Autopilot to ""reduce the frequency and severity of traffic crashes and save thousands of lives each year.""  Data pitting normal driving against Autopilot is not directly comparable because Autopilot operates largely on highways. Tesla CEO Elon Musk, however, had described Autopilot as ""unequivocally safer.""  Musk said as recently as January that there had been no crashes or injuries involving the Full Self-Driving beta software, which has been rolled out to a more limited number of drivers for testing. NHTSA officials said their data was not expected to specify whether Full Self-Driving was active at the time of the crash.  The reports presents a new window into systems like Autopilot, but the database remains a work in progress - with many unknowns even in the raw data and questions left outstanding. The data does not lend itself easily to comparisons between different manufacturers, because it does not include information such as how many vehicle miles the different driver-assistance systems were used across or how widely they are deployed across carmakers' fleets.  Still, the information gives regulators a more complete look than they had before. Previously, regulators relied on a piecemeal collection of data from media reports, manufacturer notifications and other sporadic sources to learn about incidents involving advanced driver-assistance.  ""It revealed that more crashes are happening than NHTSA had previously known,"" said Phil Koopman, an engineering professor at Carnegie Mellon University who focuses on autonomous vehicle safety. He noted that the reports may omit more minor crashes, including fender benders.  The data set doesn't include every piece of information that would be helpful to know, but it could be an early indication of a focus on gathering more information and using that to improve technologies and safety regulations, said Bryant Walker Smith, a law professor at the University of South Carolina who studies emerging transport technologies.  ""The promise of these, the potential of these is ultimately to make driving safer,"" he said of the driver-assistance technologies. ""It's an open question whether these systems overall or individual systems have accomplished that.""  Companies such as Tesla collect more data than other automakers, which might leave them overrepresented in the data, according to experts in the systems as well as some officials who spoke on the condition of anonymity to candidly describe the findings. Tesla also pilots much of the technology, some of which comes standard on its cars, putting it in the hands of users who become familiar with it more quickly and use it in a wider variety of situations.  Several lawmakers weighed in on the report Wednesday, with some calling for greater investigation and possible safety standards for cars with the technology. Sen. Richard Blumenthal (D-Conn.) called the findings ""cause for deep alarm.""  Blumenthal and Sen. Edward J. Markey (D-Mass.) have previously criticized Tesla for putting software on the roads ""without fully considering its risks and implications."" On a call with media Wednesday, Markey called out Tesla's assertion that Autopilot technology makes cars safer.  ""This report provides further evidence slamming the brakes on those claims by Tesla,"" he said.  The senators plan to send a letter to NHTSA requesting the regulator ""take additional steps in order to protect safety,"" Markey said.  Driver-assistance technology has grown in popularity as owners have sought to hand over more of the driving tasks to automated features, which do not make the cars autonomous but can offer relief from certain physical demands of driving. Automakers such as Subaru and Honda have added driver-assistance features that act as a more advanced cruise control, keeping set distances from other vehicles, maintaining speed and following marked lane lines on highways.  But none of them operate in as broad a set of conditions, such as residential and city streets, as Tesla's systems do. NHTSA disclosed last week that Tesla's Autopilot is on around 830,000 vehicles dating to 2014.  Autopilot has spurred several regulatory probes, including into crashes with parked emergency vehicles and the cars' tendency to halt for imagined hazards.  As part of its probe into crashes with parked emergency vehicles, NHTSA has said it is looking into whether Autopilot ""may exacerbate human factors or behavioral safety risks.""  Autopilot has been tied to deaths in crashes in Williston and Delray Beach, Fla., as well as in Los Angeles County and Mountain View, Calif. The driver-assistance features have drawn the attention of NHTSA, which regulates motor vehicles, and the National Transportation Safety Board, an independent body charged with investigating safety incidents.  Federal regulators last year ordered car companies including Tesla to submit crash reports within a day of learning of any incident involving driver assistance that resulted in a death or hospitalization because of injury or that involved a person being struck. Companies are also required to report crashes involving the technology that included an air bag deployment or cars that had to be towed.  The agency said it was collecting the data because of the ""unique risks"" of the emerging technology, to determine whether manufacturers are making sure their equipment is ""free of defects that pose an unreasonable risk to motor vehicle safety.""  Carmakers and hardware-makers reported 46 injuries from the crashes, including five serious injuries. But the total injury rate could be higher - 294 of the crashes had an ""unknown"" number of injuries.  One additional fatality was reported, but regulators noted it wasn't clear whether the driver-assistance technology was being used.  Honda reported 90 crashes during the same time period involving advanced driver-assistance systems, and Subaru reported 10.  In a statement, Honda spokesman Chris Martin urged caution when comparing companies' crash report data, noting that the firms have different ways to collect information. Honda's reports ""are based on unverified customer statements regarding the status of ADAS systems at the time of a reported crash,"" he said.  Regulators also released data on crashes reported by automated-driving systems, which are commonly called self-driving cars. These cars are far less common on roads, loaded with sophisticated equipment and not commercially available. A total of 130 crashes were reported, including 62 from Waymo, a sister company to Google.  Waymo spokesman Nick Smith said in a statement that the company sees the value in collecting the information and said ""any reporting requirements should be harmonized across all U.S. jurisdictions to limit confusion and potentially enable more meaningful comparisons, and NHTSA's effort is a step toward achieving that goal.""  The automated-driving systems report shows no fatalities and one serious injury. There was also one report of an automated-driving crash involving Tesla, which has tested autonomous vehicles in limited capacities, though the circumstances of the incident were not immediately clear.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220616teslanhtsa  CO 	 nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc.  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles  NS 	 gmmdis : Accidents/Man-made Disasters | gtacc : Transport Accidents | gdis : Disasters/Accidents | gcat : Political/General News | gtrans : Transport  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020220610ei6a00015","	A-Section","	Agency boosts probe of Tesla Autopilot crashes","	Faiz Siddiqui","	600 words","	10 June 2022","	The Washington Post","	WP","	FINAL","	A06",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - Federal investigators are stepping up their probe of Tesla Autopilot, the driver-assistance system that comes equipped with the electric vehicles, as they evaluate the feature's role in repeated crashes with parked emergency vehicles.  The National Highway Traffic Safety Administration said this week it is upgrading a preliminary evaluation of the issue into an engineering analysis, a step that will let it better explore Autopilot's potential role in the crashes and a possible precursor to a recall. NHTSA is seeking to determine whether Autopilot undermines ""the effectiveness of the driver's supervision,"" according to documents describing its analysis. ","  The agency began evaluating the issue in August 2021, following nearly a dozen crashes under similar circumstances, which included stationary emergency vehicles such as ambulances and police cruisers, some in low-light conditions. The agency has identified 15 injuries and one death involved in the crashes, according to documents posted by the agency.  Tesla Autopilot automates some driving features, such as keeping vehicles in their lanes, making lane changes and maintaining safe distance between other vehicles. Though it allows owners to hand over some of the driving tasks to their vehicles, they are required to pay attention at all times - and their cars seek to monitor whether they are engaged.  Tesla did not immediately respond to a request for comment.  Tesla has previously touted the safety of Autopilot, describing it as safer than normal driving when crash data is compared. Tesla CEO Elon Musk has called it ""unequivocally safer."" Musk has also taken aim at federal auto safety regulators over the need to issue repeated recalls, some of which were encouraged by NHTSA.  NHTSA, in its opening filing on the upgraded investigation, said it was able to step up its probe after identifying patterns across the various crashes - which it deemed worthy of further examination. The probe encompasses approximately 830,000 vehicles dating back to model year 2014, spanning Tesla's current range of models.  ""The investigation opening was motivated by an accumulation of crashes in which Tesla vehicles, operating with Autopilot engaged, struck stationary in-road or roadside first responder vehicles tending to preexisting collision scenes,"" the agency said in its report this week.  Each of the crashes occurred on ""controlled-access"" highways, it said. Drivers would have been able to spot the emergency vehicles, such as ambulances or police cruisers, an average of eight seconds before the crash, NHTSA said. But in the cases of the Autopilot crashes, ""no drivers took evasive action between 2-5 seconds prior to impact.""  NHTSA said it is examining whether Autopilot ""may exacerbate human factors or behavioral safety risks.""  Tesla last year issued a remote software update to better detect emergency vehicles in low light. The update, issued to Tesla's fleet of internet-connected cars as a software update, drew NHTSA's attention after Tesla aimed to better equip the cars to detect emergency vehicles - without filing the requisite paperwork to inform regulators of the change.  Tesla has the ability to remotely issue software updates that change how its vehicles behave, sometimes patching safety issues in the process. But regulators' insistence that it must publicly spell out those changes has ushered in a spate of recent recalls, which led Musk to decry NHTSA as the ""fun police"" this year.  NHTSA's engineering analysis will examine 16 crashes, more than the 11 the agency had initially identified when it opened its probe last August - after officials identified additional incidents that fit the description during the course of their evaluation.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220610teslaprobe  CO 	 nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc.  IN 	 i35104 : Alternative Fuel Vehicles | i351 : Motor Vehicles | iaut : Automotive  NS 	 gtacc : Transport Accidents | gmmdis : Accidents/Man-made Disasters | crecal : Product Recalls | c26 : Product/Consumer Safety | ccat : Corporate/Industrial News | cexpro : Products/Services | gcat : Political/General News | gdis : Disasters/Accidents | gtrans : Transport  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020220521ei5l0002h","	Style","	Tesla documentary's key arguments","	Ashley Fetters Maloy","	1213 words","	21 May 2022","	The Washington Post","	WP","	FINAL","	C04",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  By now, everybody knows the two-pronged promise Tesla has been making for nearly a decade: The car company aims to revolutionize both cars' relationship to the environment (through gas-free electric power) and consumers' safety on the roads (through self-driving capabilities). Tesla CEO Elon Musk has long been fond of emphasizing that traffic deaths would decrease if driving weren't in the all-too-human hands of, well, the driver - and has promised that one day, traveling by car will be like taking an elevator. ""You'll tell it where you want to go, and it takes you there with extreme levels of safety.""  The cars are certainly electric. That second objective, a new documentary argues, has proved more elusive. ","  Informed by the reporting of the New York Times' Cade Metz and Neal Boudette, director Emma Schwartz's ""Elon Musk's Crash Course"" raises a skeptical eyebrow toward Tesla's vaunted Autopilot feature, sometimes described as its self-driving software. It maintains that Autopilot hasn't lived up to its promise and that lives have been endangered as a result. Here are three key arguments Schwartz's film puts forth.  1. Despite Tesla's claims that its technology would revolutionize cars for the safer, its cars have sometimes failed to recognize certain safety threats while in Autopilot mode - and Tesla drivers have had fatal road accidents while using it.  According to ""Elon Musk's Crash Course,"" an investigation in 2016 by the National Highway Traffic Safety Administration (NHTSA) found that some 38 Tesla crashes had taken place in the United States while the cars were in Autopilot mode, but the film details three in which drivers were killed.  The first is that of Josh Brown, a bomb dismantler for the Navy in the Iraq War and the founder of a company that aimed to extend Internet service into rural America. Described by his friends as a passionate tech enthusiast, Brown loved his Tesla and often filmed videos behind the wheel. When Musk retweeted one such video in April 2016, in which the car in Autopilot mode steered itself out of the way of a truck merging too aggressively, Brown was elated.  Brown was driving on the same mode through Williston, Fla., after leaving Disney World the following month when his Tesla drove under a tractor-trailer without slowing down. Brown, 40, was killed in the collision. (Despite rumors that Brown had been watching a movie, the documentary makes clear that no movies were found on Brown's laptop. Still, NHTSA and the National Transportation Safety Board, or NTSB, found that Brown was at fault because he was not paying attention to the road.) In the film, Musk is heard in an audio recording saying later that radar upgrades that were added to the Autopilot software after Brown's accident might have saved Brown's life.  In March 2018, 38-year-old Apple engineer Walter Huang died when his Tesla, running in Autopilot mode, hit a concrete barrier in Mountain View, Calif., at over 70 mph. Former NTSB chairman Robert L. Sumwalt says on-screen that Huang was found to have been playing a video game.  And in March 2019, Jeremy Banner, 50, was killed in another Florida highway accident, nearly identical to the one that killed Brown. The Tesla was on Autopilot when a tractor-trailer pulled across the road. Banner's car failed to recognize the side of the vehicle in the bright sunlight and went underneath it, shearing off the roof.  Sumwalt alleges in ""Crash Course"" that Tesla has ignored its safety recommendations after crashes. ""When innovation is implemented, we have to make sure it's done safely,"" he says, ""or it's going to be the Wild West out there.""  2. Some former engineers at Tesla privately harbored doubts about Musk's promises to the public about the Tesla's ability to self-drive.  Despite Musk's claims starting in 2015 that self-driving cars were essentially a ""solved problem"" and that the kinks were merely being worked out, multiple former staffers allege in ""Crash Course"" that wasn't the case behind closed doors.  They say, for example, that certain decisions were made somewhat arbitrarily - such as the decision to use cameras instead of a popular radar system known as lidar. ""There was no deep research phase where various vehicles were outfitted with a range of sensors. Many team members would have liked that,"" says Akshat Patel, Autopilot's engineering program manager from 2014 to 2015. ""Instead, the conclusion was made first, and the test and development activities began, to prove that conclusion correct.""  Others allege that they worried the Autopilot technology was being sold to and used by people who believed it would provide the same elevator-like transportation experience Musk had once described - drivers who believed they could get in, provide a destination, then sit back and relax. When Brown's crash happened, ""I was aware that people were trusting the system to do things that it was not designed or capable of doing,"" says JT Stukes, senior project engineer at Tesla from 2014 to 2018. ""The fact that that sort of accident happened is obviously tragic. But it was going to happen.""  Raven Jiang, an engineer who also worked on Autopilot at Tesla from 2015 to 2016, notes that in the same time frame, Elizabeth Holmes's transgressions at Theranos were being revealed to the public. ""Some of those stories were at the back of my mind,"" Jiang says. ""It definitely made me question a lot more about what's behind some of this public optimism.""  3. Tesla enjoys substantial public support anyway.  The most recent footage included in ""Crash Course"" comes from just last month. Musk, wearing a black cowboy hat and black aviators, grins onstage in front of a whooping, enraptured crowd at the launch party for Tesla's new Gigafactory in Austin. Partygoers hold their phones up to film him speaking - a stark reminder that Musk is a megacelebrity and a hero to many.  One Tesla owner, Alex Poulos, points out that Musk superfans sometimes call themselves ""Musketeers."" Kim Paquette, another Tesla owner who's part of an elite group that test-drives new versions of the self-driving software, shows off her collection of HotWheels-size Teslas and says she's ""honored"" to participate in the testing process. ""People who buy a Tesla understand that it's not self-driving yet,"" she says. Even Brown's family says that ""part of Joshua's legacy is that the accident [that caused his death] drove additional improvements, making the new technology even safer,"" in a statement read on their behalf at a building dedication for him. ""Our family takes solace and pride in the fact that our son is making such a positive impact on future highway safety.""  And yet, Poulos says, ""Full self-driving, that's what I paid for and I don't have it. It's right there in the name of it, right? And I don't think that's fair to say.  ""Musk, I think he has a huge responsibility,"" he adds. ""I think he needs to be a little bit more cautious about what he tells his followers.""   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220521elondoc  CO 	 teslmi : Tesla, Inc.  IN 	 i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iaut : Automotive  NS 	 gmmdis : Accidents/Man-made Disasters | gcar : Cars | gent : Arts/Entertainment | gmovie : Movies | gcat : Political/General News | gdis : Disasters/Accidents | glife : Living/Lifestyle  RE 	 usa : United States | namz : North America  IPD 	 Style  PUB 	 Washington Post ",NA
"Document WP00000020220416ei4g0001o","	A-Section","	Elon Musk's road to Twitter is paved with broken promises","	Geoffrey A. Fowler","	1964 words","	16 April 2022","	The Washington Post","	WP","	FINAL","	A15",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  Elon Musk wants to use his billions to remake Twitter as a ""platform for free speech around the globe."" He says he'll stop it from censoring speech, ban annoying bots and make tweets editable. But as Earth's richest person adds the social media industry to his conquests, keep one thing in mind: Musk's promises often need an edit button of their own. His track record is a mix of wild successes and many, many, many broken promises. I've lived it: In 2019, my family leased a Tesla Model 3 and paid thousands of dollars extra for its ""full self-driving"" capability. When we returned the lease a few months ago, we still hadn't received it. (There was no refund, either - we asked.) It's the fundamental paradox of Musk: He's both our Thomas Edison and that kid in school who made up fantastical stories about what he did on summer vacation. Last fall, Musk actually announced plans for a humanoid robot at an event by using a real human dancing in a robot suit. ","  He says so many zany things that some of his critics, who are often financially invested in his failure, catalogue them on sites including Elon's Broken Promises and Elon Musk Today. So much of what Musk utters is just wishful thinking or trolling, egged on by the temptations baked into his favorite communication medium, Twitter. Yet you'd be a fool to dismiss him completely. He's rich and powerful enough that you have to take all of it seriously. Some of Musk's biggest, wildest promises - reigniting the U.S. space program and making electric cars cool - have actually happened and really are changing the world. I mean, the man made a giant rocket called the Falcon Heavy that can launch into orbit and then stick its landing. His Starlink satellite Internet service is helping people stay online during the war in Ukraine. Closer to home, my family still drives a Tesla. We just changed models and declined to pay for full self-driving. If Musk does end up running Twitter or some other social media company, his past suggests he'll bring a unique form of chaos. He loves testing ideas, and isn't afraid to make us be the guinea pigs in a way you'd never expect from a fully baked Apple product. But make no mistake: The problems Twitter faces are just as complicated as manufacturing an affordable electric car - and quite possibly more, because everybody seems to have a different definition of ""free speech."" During an interview at the TED conference shortly after announcing a hostile bid for Twitter on Thursday, Musk acknowledged he often expresses ambitious timelines. ""I don't want to blow your mind, but I'm not always right,"" he said about his missed promises on self-driving. Musk loves free speech, but it comes with accountability - including for himself. As he sets out to change a communication tool used by more than 200 million people, the question is: What will be different about his promises this time? Here's a short history of promises that Musk never delivered or we're still waiting to arrive.  Elon Musk wants to use his billions to remake Twitter as a ""platform for free speech around the globe."" He says he'll stop it from censoring speech, ban annoying bots and make tweets editable.  But as Earth's richest person adds the social media industry to his conquests, keep one thing in mind: Musk's promises often need an edit button of their own.  His track record is a mix of wild successes and many, many, many broken promises.  I've lived it: In 2019, my family leased a Tesla Model 3 and paid thousands of dollars extra for its ""full self-driving"" capability. When we returned the lease a few months ago, we still hadn't received it. (There was no refund, either - we asked.)  It's the fundamental paradox of Musk: He's both our Thomas Edison and that kid in school who made up fantastical stories about what he did on summer vacation. Last fall, Musk actually announced plans for a humanoid robot at an event by using a real human dancing in a robot suit. He says so many zany things that some of his critics, who are often financially invested in his failure, catalogue them on sites including Elon's Broken Promises and Elon Musk Today.  So much of what Musk utters is just wishful thinking or trolling, egged on by the temptations baked into his favorite communication medium, Twitter. Yet you'd be a fool to dismiss him completely. He's rich and powerful enough that you have to take all of it seriously.  Some of Musk's biggest, wildest promises - reigniting the U.S. space program and making electric cars cool - have actually happened and really are changing the world. I mean, the man made a giant rocket called the Falcon Heavy that can launch into orbit and then stick its landing. His Starlink satellite Internet service is helping people stay online during the war in Ukraine. Closer to home, my family still drives a Tesla. We just changed models and declined to pay for full self-driving.  If Musk does end up running Twitter or some other social media company, his past suggests he'll bring a unique form of chaos. He loves testing ideas, and isn't afraid to make us be the guinea pigs in a way you'd never expect from a fully baked Apple product. But make no mistake: The problems Twitter faces are just as complicated as manufacturing an affordable electric car - and quite possibly more, because everybody seems to have a different definition of ""free speech.""  During an interview at the TED conference shortly after announcing a hostile bid for Twitter on Thursday, Musk acknowledged he often expresses ambitious timelines. ""I don't want to blow your mind, but I'm not always right,"" he said about his missed promises on self-driving.  Musk loves free speech, but it comes with accountability - including for himself. As he sets out to change a communication tool used by more than 200 million people, the question is: What will be different about his promises this time?  Here's a short history of promises that Musk never delivered or we're still waiting to arrive.  March 2016The Tesla Model 3 will cost $35,000  What he said: When Musk unveiled Tesla's Model 3 sedan, he said the standard model would cost $35,000.  What happened: Tesla did briefly sell the Model 3 for that price in 2019, but the low price never played the role Musk suggested in making electric vehicles common. Then, Tesla got rid of the $35,000 models entirely in 2020. Now Tesla lists the starting price of its rear-drive Standard Range Plus model at $46,990.  January 2017  Full self-driving Tesla cars ready in 6 months  What he said: Answering a question on Twitter about when ""full self-driving"" features would exceed ""enhanced autopilot"" features (like cruise control), Musk said: ""3 months maybe, 6 months definitely."" That was five years ago.  What happened: In September 2021, Tesla began letting select owners request ""full self-driving"" software upgrades. Video from beta testers revealed deep flaws.  March 2017  Brain implants  What he said: Musk revealed that he founded a company called Neuralink to connect brains to computers. It would enable people with spinal cord injuries to walk or eventually permit human-to-human telepathy, he suggested. In 2019, Musk predicted the technology would be implanted in a human skull by 2020.  What happened: Neuralink has implanted chips in the brains of a monkey and a pig, and in December 2021, Musk tweeted that ""progress will accelerate when we have devices in humans . . . next year."" But as of January, only two of the eight scientists Musk brought in to help him create Neuralink remain at the company.  July 2017  A tunnel will speed travel between New York and Washington  What he said: Musk founded the Boring Company to speed up digging tunnels that could be used for speedy transportation in busy urban corridors. ""Just received verbal govt approval for The Boring Company to build an underground NY-Phil-Balt-DC Hyperloop. NY-DC in 29 mins,"" Musk tweeted.  What happened: Today, the Hyperloop tunnel project between Washington and New York is no longer listed on the company's website. The company demonstrated a California test tunnel in 2018 and opened a 1.7-mile tunnel at the Las Vegas Convention Center in April 2021.  November 2017  A Tesla Semi truck will arrive by 2019  What he said : Musk announced a large truck with an ambitious range of 500 miles and an even more ambitious production timeline of 2019.  What happened : Tesla has taken Semi orders, and prototypes have been seen in testing, and Musk has now committed to delivering some in 2023.  July 2018  Musk offers a submarine to rescue soccer team trapped in a cave  What he said : When 12 soccer players trapped in a cave in Thailand made global headlines, Musk offered to help by developing a submarine to extract them. ""Mini-sub arriving in about 17 hours. Hopefully useful. If not, perhaps it will be in a future situation,"" he tweeted.  What happened : The boys were rescued by divers who carried them through the cave on stretchers and did not use Musk's submarine. Some rescuers said the tech wasn't practical.  April 2019  1 million robotaxis on the road by 2020  What he said : ""I feel very confident predicting autonomous robotaxis for Tesla next year,"" Musk said in 2019 at an investor event. (He also warned: ""Sometimes I am not on time, but I get it done."") He also predicted that within two years, Tesla would be making cars with no pedals or steering wheels.  What happened : Tesla's self-driving technology is still limited to tests with selected car owners, not autonomous taxis. In April 2022, Musk said that Tesla would build a vehicle dedicated for use as a robotaxi and that it will ""look quite futuristic.""  November 2019  Tesla Cybertruck to begin production in 2021  What he said: Musk unveiled a futuristic electric pickup with a steel ""exoskeleton"" and sharp angles. Production was supposed to begin in late 2021 with a release date in 2022.  What happened : During a demonstration of the strength of the car's new unbreakable windows, Musk asked one of the people onstage to try to break the glass - and it shattered. As of April, the Cybertruck's release has been pushed to 2023.  May 2020  Tesla workers told it's okay to stay home during covid-19  What he said: When Musk defied local covid-19 orders and reopened Tesla's factory in Fremont, Calif., he told employees they could stay home. If ""you feel uncomfortable coming back to work at this time, please do not feel obligated to do so,"" he wrote in an email.  What happened : Several employees said they received termination notices for ""failure to return to work"" after they took unpaid leave to protect themselves.  April 2022  Tesla's humanoid robot will be ready for production in 2023  What he said: In August 2021, Musk unveiled plans for a ""friendly"" humanoid robot called Optimus or Tesla Bot that could ""navigate through a world built for humans and eliminate dangerous, repetitive and boring tasks."" In April, Musk said, ""We have a shot of being in production for version one of Optimus hopefully next year.""  What happened: To date, Tesla has not shown a working prototype.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220416MUSKGRAPHIC  CO 	 spaetc : Space Exploration Technologies Corp. | teslmi : Tesla, Inc. | twnit : Twitter Inc.  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | i364 : Aerospace Products/Parts | i3640046 : Spacecraft | iaer : Aerospace/Defense | iindstrls : Industrial Goods | iint : Online Service Providers | imed : Media/Entertainment | isocial : Social Media Platforms/Tools  NS 	 gcens : Censorship | ghum : Human Rights/Civil Liberties | gcat : Political/General News | gcom : Society/Community  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020220328ei3s0001f","	A-Section","	How auto regulators played mind games with Elon Musk","	Faiz Siddiqui","	2094 words","	28 March 2022","	The Washington Post","	WP","	FINAL","	A03",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - The first time Washington regulators tried to investigate Tesla's Autopilot software, CEO Elon Musk was irate.  Weeks earlier, a Tesla using the company's advanced driver-assistance system had crashed into a tractor-trailer at about 70 mph, killing the driver. When National Highway Traffic Safety Administration officials called Tesla executives to say they were launching an investigation, Musk screamed, protested and threatened to sue, said a former safety official who spoke on the condition of anonymity to discuss sensitive matters. ","  The regulators knew Musk could be impulsive and stubborn; they would need to show some spine to win his cooperation. So they waited. And in a subsequent call, ""when tempers were a little bit cool,"" the official said, Musk agreed to cooperate: ""He was a changed person.""  Since that success in 2016, officials have learned to work with Musk, using a combination of pressure, flattery and threats to persuade him to comply with federal safety measures, according to a half-dozen former regulators, some of whom spoke on the condition of anonymity to discuss sensitive matters. In the past six months, Tesla has issued at least a dozen voluntary recalls, a dramatic turnaround for a company known to quietly issue software updates direct to cars - without alerting the public - to fix sometimes alarming safety problems.  With about 2 million cars on the road, Tesla recently has experienced a wave of troubles: Cars using its driver-assistance features have slammed on the brakes for no reason and rolled through stop signs - the latter because Tesla programmed them to do so. A string of crashes into parked emergency vehicles is under investigation. And the cars' batteries have been documented exploding in crashes and while parked in garages.  Such issues typically prompt NHTSA to investigate and sometimes to push for voluntary or mandatory recalls.  If an automaker refuses to cooperate, NHTSA can impose cash fines of about $23,000 per day. The threat of fines - which can add up to nearly $115 million - generally works with traditional companies, the former officials said, but hasn't proven effective when dealing with Tesla, an extraordinarily valuable company owned by the richest man in the world.  So NHTSA officials have turned to less conventional strategies to force the electric vehicle manufacturer to be more transparent about safety issues - a critical matter at a time when more than 50,000 drivers can now use Tesla's ""Full Self-Driving"" software to navigate the nation's public roads.  ""Tesla is presumably smart enough to realize when they don't have the upper hand anymore,"" said Phil Koopman, an associate professor at Carnegie Mellon University whose focus includes federal auto regulations. ""Tesla has a choice to make - they have to decide whether to cave or go to the mat. And the reality is, on [federal safety regulations] they're going to lose.""  Tesla and Musk did not respond to specific questions in a detailed request for comment. Musk said in an email, ""For the 100th time, please give my regards to your puppetmaster,"" referring to Amazon founder Jeff Bezos, who owns The Washington Post. In a subsequent email, he also criticized The Post's paywall for online articles.  NHTSA declined to make anyone available for an interview, citing ongoing investigations. But the agency issued written statements to The Post expressing its commitment to protect public safety.  Tesla has publicly touted the safety of its vehicles and its driver-assistance technology, boasting that it has won the highest possible score - five stars - in crash tests where NHTSA slams cars into barriers and then examines the results. Tesla also has said its cars have the lowest probability of injury of any car tested, though NHTSA has disputed that characterization.  Musk's own attitude was part of the problem with efforts to enforce safety, the officials said. Some experienced personal encounters with Musk that escalated into yelling matches or otherwise proved unproductive because of the CEO's skepticism about their findings.  NHTSA's experiences with Tesla were unique among major automakers, the officials said. It was not rare for companies under scrutiny to fiercely push back against their findings, sometimes resulting in mandatory rather than voluntary recalls, they said. But with Tesla, issues as simple as a malfunctioning heat pump or noncompliant sound effects to alert pedestrians to a vehicles' presence could result in stubbornness.  Tesla eventually issued recalls in both cases - decisions influenced by NHTSA, a spokeswoman said.  ""NHTSA will ensure that vehicle manufacturers and developers prioritize safety while they usher in the latest technologies,"" spokeswoman Lucia Sanchez said.  Regulators have been slow to take action on some software suites that power automated features, in part because they are wary of appearing to stifle emerging technologies, the former officials said. There also are few rules governing these technologies, further hindering efforts at regulation.  Since 2016, NHTSA has opened 31 special crash investigation cases involving advanced driver-assistance technology, according to data provided by the agency. Twenty-four have involved Tesla vehicles.  Safety experts and some of the former regulators who spoke with The Post raised concerns about ""Full Self-Driving"" in particular because of its experimental nature. Tesla says the software is in ""beta,"" meaning it is a pilot through which the company hopes to learn and improve its features for an eventual full release.  Lawmakers have pressed for more transparency regarding Tesla's practices. In February, following a Post report on the cars' sudden braking, Sens. Richard Blumenthal (D-Conn.) and Edward J. Markey (D-Mass.) criticized Tesla for putting software on the roads ""without fully considering its risks and implications."" They urged NHTSA ""to continue taking all appropriate action to protect all users of the road."" And they called on the Federal Trade Commission to launch an investigation into what they called ""misleading advertising and marketing"" of Autopilot and ""Full Self-Driving"" systems.  During much of the Obama administration, Tesla slid under the radar of federal safety regulators. As a niche automaker delivering at most tens of thousands of luxury cars per year, officials said it would not have ranked on the agency's priority list, compared with high-volume automakers such as Ford and Toyota.  From 2013 to 2015, there was just one recall per year for early Tesla Model S luxury sedans. Those recalls - which involved seat back mountings, charging equipment and incorrectly secured seat belts - compare with a total of 2,261 vehicle recalls over the same period, according to NHTSA data.  One early run-in set the tone for regulators' interactions with Tesla. In 2013, Tesla claimed its Model S was the safest car ever tested by NHTSA.  Officials at the agency were dumbstruck, according to some of those who spoke with The Post. The agency issues up to 5-star ratings, but it does not take its designations beyond the star score.  At one point, two former officials recalled, NHTSA officials threatened to contact the FTC, which regulates marketing. ""If Tesla wasn't willing to pull the plug, FTC was probably going to take action,"" one of the former officials said.  Tesla backed down.  But Tesla continued to make similar claims, including in 2019, when it said its Model 3 had the ""lowest probability of injury of any vehicle ever tested"" by NHTSA. The agency ultimately referred the automaker to the FTC. The FTC declined to comment.  NHTSA, meanwhile, focused increasing attention on the automaker as it built more and more cars, launching the Model X SUV in 2015 and steadily growing its production in the buildup to the mass market-aimed Model 3. The agency also had to deal with emerging issues, such as fires caused by road debris striking the cars' underbodies, where the high-voltage battery is located. Musk wrote in a statement at the time that Tesla would introduce a fix to bring that risk ""down to virtually zero.""  One official recalled that regulators were confused by Musk's reluctance to address one battery-related issue. The only evident solution was to appeal to his sense of pride.  ""NHTSA staff backs Musk into a corner and challenges his ego and says, 'Wait, you can't solve this?' "" a former official said. ""And the next day he has a solution.""  The Trump administration was even less hands-on. The NHTSA website lists only one recall for the 2017 through 2020 Tesla Model 3, then the automaker's most popular model. Depending on the model year, there were up to eight recalls issued for the same car beginning May 25, 2021, after President Biden took office.  Under the Trump administration, career officials and top staff were reluctant to take a strong stance on a mounting catalogue of safety concerns, wary of appearing to target innovation and already under pressure from the president to ease regulations.  The officials said staffers were reluctant to take on a rapidly emerging automotive power with a massive public platform, worried they wouldn't have the backing of top officials if they received a browbeating from Musk.  ""My former staff felt they had nothing to do - twiddling their thumbs,"" one former official said. ""The professional staff - the career staff - wanted to do stuff either from a regulatory standpoint or investigation perspective"" but were stymied.  Musk praised NHTSA as ""great"" in April 2021.  Then, things changed.  Although Labor Secretary Marty Walsh recently met with Musk and took a factory tour in Texas, Axios reported, Musk has criticized President Biden for leaving Tesla out of major events. Musk also has parroted Republican barbs, joking at one point Biden was ""sleeping.""  Last summer, NHTSA began requiring companies such as Tesla to report on certain crashes involving automated features within one day of learning of the incident. Then in August, the agency launched an investigation into about a dozen crashes involving parked emergency vehicles while Autopilot was active. In a letter, it called out Tesla for pushing out a software update to help its cars better see emergency vehicles, without formally issuing a recall.  A surge of investigations, recalls and public admonitions has followed.  Former officials who spoke with The Post said Tesla's haphazard approach has grated on some NHTSA staff, and the enforcement reflects an attempt at a course correction.  ""The agency does hold a very firm line on [federal motor vehicle regulations], and I don't think any of us want to live in a world where the automakers do essential recalls without going through that process,"" said Bryan Thomas, who was communications director at NHTSA during the Obama administration. ""If the car's going to react differently at a stop sign tomorrow than it did today, you should know that as a driver.""  The former officials said that NHTSA is not singling out Tesla. Instead, they said the agency is using a calculated approach to try to force the combative automaker to recognize findings that can't be denied. That means picking targets - the seat belt chime, rolling stops, a windshield defroster - that may strike executives and even some owners as trivial. But those narrow targets offer an entree to larger issues that are not yet addressed by federal regulations, which often lag behind the latest software advances.  In February, NHTSA cracked down on a feature known as ""Boombox,"" which plays sounds that bystanders can hear - such as an ice cream truck jingle - but can drown out sounds that warn pedestrians of approaching vehicles. On Twitter, Musk decried the agency as the ""fun police.""  Federal safety investigators from the National Transportation Safety Board have also focused their attention on Tesla. Late last year, NTSB Chair Jennifer Homendy wrote a letter to Musk calling out the company's ""inaction"" on recommendations that would have added safeguards to the Autopilot system in response to the fatal 2016 crash with the tractor-trailer.  In a statement posted to its website at the time, Tesla called the death ""A Tragic Loss."" The company defended the performance of Autopilot across the tens of millions of miles it had logged and emphasized that drivers should be prepared to take control of the vehicle at any time.  In September, Homendy expressed her concern about Musk's approach to safety in an interview with The Post.  ""I think Elon Musk is an incredible innovator,"" she said, expressing hope for ""the ultimate success of [autonomous vehicle] technologies - which could save lives.""  But she also encouraged Musk to ""really prioritize safety for his company,"" adding: ""I don't want to see lives lost in the meantime.""   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220328teslaregulators  CO 	 nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc.  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles  NS 	 c13 : Regulation/Government Policy | crecal : Product Recalls | gtacc : Transport Accidents | c26 : Product/Consumer Safety | ccat : Corporate/Industrial News | cexpro : Products/Services | gcat : Political/General News | gdis : Disasters/Accidents | gmmdis : Accidents/Man-made Disasters | gtrans : Transport | ncat : Content Types | nfact : Factiva Filters | nfcpin : C&E Industry News Filter  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020220218ei2i0002n","	A-Section","	Regulators probe Tesla 'phantom braking' issue","	Faiz Siddiqui Jeremy B. Merrill","	958 words","	18 February 2022","	The Washington Post","	WP","	FINAL","	A16",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - The National Highway Traffic Safety Administration is probing sudden unexpected braking in Tesla vehicles, the latest safety probe faced by the electric-vehicle maker.  The agency said it had received 354 complaints about the issue in nine months, in two models across multiple model years: the 2021 and 2022 Tesla Model 3 and Model Y. NHTSA said the preliminary evaluation will affect approximately 416,000 vehicles. ","  ""The complaints allege that while utilizing the [advanced driver-assistance] features including adaptive cruise control, the vehicle unexpectedly applies its brakes while driving at highway speeds,"" the agency said. ""Complainants report that the rapid deceleration can occur without warning, at random, and often repeatedly in a single drive cycle.""  Tesla owners flooded NHTSA's website with hundreds of complaints of alleged ""phantom braking"" this month following a Washington Post report that noted a sharp uptick in the phenomenon. The issue, a glitch in the cars' forward collision warning and automatic emergency-braking systems, occurs when Tesla's vehicles suddenly slow down in response to falsely detected hazards.  Owners began complaining of the issue in larger numbers beginning in November, days after the automaker issued a recall of its ""Full Self-Driving"" software over a glitch that could lead to phantom braking. More broadly, the surge has followed Tesla's shift from a multi-sensor perception system combining cameras and radar to a camera-based system that relies on what the automaker calls ""Tesla Vision."" The spate of complaints included several common patterns as well as at least one report of an injury.  After The Post's article in early February, NHTSA received about 250 complaints about phantom braking during the following two weeks. That compared to 107 complaints in the previous three months - a steep surge of its own - and only 34 in the preceding 22 months.  Tesla, which disbanded its public relations department in 2020, did not respond to requests for comment. ""NHTSA will determine the scope and severity of the potential problem and fully assess the potential safety-related issues,"" said NHTSA spokeswoman Lucia Sanchez.  Tesla CEO Elon Musk has repeatedly defended the use of its automated features, calling its Autopilot driver assistance ""unequivocally safer"" than normal driving and decrying the ""fun police"" as the company faced multiple recalls in recent weeks - an apparent reference to federal regulators.  Complaints of phantom braking involving Tesla vehicles also far surpass those for other automakers that likewise have advanced driver assistance but largely rely on radar-equipped systems. The increase in complaints sheds light on the types of common scenarios in which owners report phantom braking. Among all the complaints, about a third of the sudden slowdowns occurred on two-lane roads or highways when, for example, an oncoming truck was approaching in the distance, according to a Post analysis.  ""It's when the traffic is coming towards me that it randomly throws on the brake,"" Sally Bergquist, of Alexander City, Ala., who experienced repeated sudden slowdowns on her 2021 Tesla Model S on drives to Birmingham, said in an interview. ""This random braking is really concerning to me.""  The NHTSA complaints are not individually verified by the agency - owners describe the issue they experience, and provide their vehicle identification number along with other identifying information when they send their report. Complaints to NHTSA can - as apparently occurred here - be more frequent as owners learn about the possibility of telling the government about safety problems with their car, so increases in complaints might not always be due to an increase in the rate of problems.  But the sheer number of complaints for Teslas related to phantom braking far outpaced those for other vehicle makes and models, indicating a known problem of growing prominence among the owner population.  The Post's analysis covered the 2019 Tesla Model 3 along with 2020 through 2022 Tesla Model Y and Model 3 vehicles.  Tesla has faced mounting pressure from NHTSA over Autopilot and its practice of issuing over-the-air software updates to remedy issues with its vehicles, without initiating the formal recall process. The agency is investigating the potential role of Autopilot in about a dozen crashes involving Teslas and parked emergency vehicles while the driver-assistance system was active. Tesla has issued a steady stream of recalls since October, when NHTSA publicly called out the company for its failure to issue a formal recall when it updated its cars to better detect emergency vehicles in low light.  Tesla is facing scrutiny from other regulators, who have trained a lens on Musk's leadership.  Tesla disclosed in its annual financial report, for example, that the Securities and Exchange Commission issued a subpoena Nov. 16 looking for information on the company's compliance with a settlement governing Musk's tweets. Musk and the company each faced $20 million fines, and Musk had to give up his chairmanship of Tesla's board, after a 2018 tweet where he said he had secured funding to take Tesla private at $420 a share. Musk's potentially market-moving tweets also had to be vetted by a securities lawyer.  But a letter from Musk's attorney Thursday accused the SEC of hounding the CEO and Tesla with ""endless, unfounded investigations.""  ""Without coming before this Court, it has been weaponizing the consent decree by using it to try to muzzle and harass Mr. Musk and Tesla, while ignoring its Court-ordered duty to remit the $40 million that it continues to hold while Tesla's shareholders continue to wait,"" wrote Musk attorney Alex Spiro, in a letter to U.S. District Judge Alison J. Nathan.  The SEC did not immediately respond to a request for comment.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220218teslabraking-001  CO 	 nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc.  IN 	 i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iaut : Automotive  NS 	 c24 : Capacity/Facilities | c13 : Regulation/Government Policy | ccat : Corporate/Industrial News | ncat : Content Types | nfact : Factiva Filters | nfcpin : C&E Industry News Filter  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020220211ei2b00012","	A-Section","	Still a rough road for 'Full Self-Driving'","	Faiz Siddiqui Reed Albergotti","	2644 words","	11 February 2022","	The Washington Post","	WP","	FINAL","	A14",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - In one video, a Tesla tries to drive down some light-rail tracks. In another, a Tesla fails to stop for a pedestrian in a crosswalk. And at one point, the most advanced driver-assistance product available to consumers appears to slam into a bike lane bollard at 11 mph.  Each of these moments - captured on video by a Tesla owner and posted online - reveals a fundamental weakness in Tesla's ""Full Self-Driving"" technology, according to a panel of experts assembled by The Washington Post and asked to examine the videos. These are problems with no easy fix, the experts said, where patching one issue might introduce new complications, or where the nearly infinite array of possible real-life scenarios is simply too much for Tesla's algorithms to master. ","  The footage includes a scene in which a driver appears to be fighting for control with the advanced driver-assistance software, as well as clips showing cars failing to properly interpret critical road markings and signs and ordinary pedestrian behavior.  The Post selected six videos from a large array posted on YouTube and contacted the people who shot them to confirm their authenticity. The Post then recruited a half-dozen experts to conduct a frame-by-frame analysis.  The experts include academics who study self-driving vehicles; industry executives and technical staff who work in autonomousvehicle safety analysis; and self-driving-vehicle developers. None work in capacities that put them in competition with Tesla, and several said they did not fault Tesla for its approach. Two spoke on the condition of anonymity to avoid angering Tesla, its fans or future clients.  Their analysis suggests that, as currently designed, Full SelfDriving (FSD) could be dangerous on public roadways, according to several of the experts. Some defects appear to plague multiple versions of Tesla's software, such as inability to recognize light-rail tracks: One video shows a driver shifting into reverse after traveling too far onto the tracks.  ""The video [footage] shows different scenarios where the automated driving system was not able to detect and/or cope with relevant features of its Operational Design Domain,"" or the conditions under which the system is expected to safely operate, said Nicola Croce, technical program manager at Deepen AI, which helps companies deploy driver-assistance and autonomous-driving systems. Tesla is not one of its clients.  Lapses within the design domain, Croce said, are ""considered a failure to follow the safety expectations.""  Tesla did not respond to repeated requests for comment. The company disbanded its public relations department in 2020 and does not typically answer media requests.  Several drivers who spoke to The Post about the videos defended the technology. While they acknowledged that miscues happen, they said were able to safely ""disengage"" the software before a more serious incident.  ""I'm not going to put anybody in danger. I'm mindful of the cars around me,"" said Chris, a driver from Fenton, Mich., who spoke on condition that he be identified only by his first name out of concern for his privacy.  Full Self-Driving is one of two driver-assistance technologies available on Teslas. The other is ""Autopilot,"" a system primarily designed for highway use with an attentive driver behind the wheel.  When using Autopilot and Full Self-Driving, drivers must agree to ""keep your hands on the steering wheel at all times"" and always ""maintain control and responsibility for your car,"" according to Tesla's website.  The company has fiercely defended the safety record of Autopilot, with chief executive Elon Musk calling it ""unequivocally safer"" than regular driving based on crash data. However, the National Highway Traffic Safety Administration is investigating whether Autopilot played a role in about a dozen crashes involving parked emergency vehicles. Last fall, a California driver was charged with vehicular manslaughter after striking another vehicle while Autopilot was activated, killing two people.  But the company has staked its autonomy ambitions on FSD, which brings automated capabilities to city and residential streets. FSD is only available in the form of a software beta, a type of pilot that serves as an advanced testing stage before eventual wide release. Tesla recently said that nearly 60,000 vehicles in the United States are now equipped with it.  Full Self-Driving uses Tesla's suite of eight surround cameras to stitch together a view of the world outside the car. The images are fed into Tesla's software, which the company intends to leverage to help its vehicles learn. The cameras are supplemented by 12 ultrasonic sensors that detect objects around the vehicle.  Tesla has issued multiple recalls of the Full Self-Driving Beta, sending remote updates after the software raised concerns with federal auto safety regulators. In October, the company recalled the software for about 12,000 vehicles after an update led cars to begin braking abruptly at highway speeds. Tesla remotely issued a fix.  In late January, Tesla notified regulators it would update the Full Self-Driving Beta to eliminate a ""rolling stop"" function that allowed cars to proceed through stop signs without fully halting. Last week, The Post reported that owner complaints of unexpected braking, a phenomenon known as ""phantom braking,"" surged in the period after Tesla eliminated the use of radar to aid its vehicles' perception.  To further understand how the technology operates, The Post turned to videos showing the system in action. In interviews, most of the drivers who posted the videos said they did so to showcase the car's cutting-edge capabilities. The car's mistakes, they said, serve not as evidence of insurmountable limitations, but instead as mile markers to document progress.  Some drivers said they have run their own experiments to test and improve the software. Kevin Smith, who uses FSD on his Tesla Model Y in Murfreesboro, Tenn., said he identified 13 locations near his hometown that stumped his car and created a route that hit all of them. ""Each time, it gets a little bit better,"" he said.  While some experts in AI are critical of Tesla's decision to release Full Self-Driving before it's ready for the road, many say they appreciate the ability to analyze and learn from videos posted by Tesla drivers. Most show the screen in the car's center console, offering clues about how the software is interpreting data from the real world.  ""The value [of Tesla's experiment] to society, I think, is transparency,"" said Mohammad Musa, founder of Deepen AI.  ""Whatever you see from anyone else is what they want you to see,"" he said of Tesla's competitors. ""It might actually fire back at [Tesla] and become a PR nightmare. … For better or for worse, they are opening up about things.""  First recorded crash  On a clear day in early February, a Tesla in FSD Beta makes a right turn through a San Jose intersection at about 15 mph. A bike lane flanks the inner side of the road. Suddenly, the car approaches a set of green-and-white protective bollards at a sharp angle.  It slams into the first bollard after the crosswalk at about 11 mph.  The car suffered only minor scrapes, but FSD testers and experts who analyzed the video say it is the first publicly released footage of a crash involving the software. And it revealed flaws.  ""The bollard issue is both mapping and perception. As permanent bollards rather than temporary cones, they should be on a map,"" said Brad Templeton, a longtime self-driving-car developer and consultant who worked on Google's self-driving car. That way, he said, ""the car would know that nobody ever drives through these.""  ""As to why the perception missed them until too late, this is an issue with computer vision. Perhaps it never got trained on these unusually shaped and [colored] bollards,"" said Templeton, who owns a Tesla and has described himself as a ""fan.""  Tesla's ultrasonic sensors might be expected to detect such hazards, but their locations in places such as the front bumper can be a weakness. ""Sparse, thin things like posts may not be seen by these,"" Templeton said.  A pedestrian near miss  On an overcast December day in San Jose, one video shows a routine right turn at a green light leading to a close call with a pedestrian. Traveling at about 12 miles an hour, the Tesla is proceeding across light-rail tracks when a woman steps off the sidewalk and into the crosswalk.  The woman stops abruptly when she sees the Tesla heading toward her. The Tesla appears to slow down, but only after traveling through most of the crosswalk.  After analyzing the video and others like it, The Post's panel of experts said FSD does not appear to recognize pedestrian walk signs, or anticipate that a stationary pedestrian might venture into the street.  ""It's unclear whether the car reacted or not to [the pedestrian's] presence, but clearly the driver is shaken,"" said Andrew Maynard, a professor at Arizona State University, who is director of its Risk Innovation Lab.  The driver, who confirmed the veracity of the footage, declined to comment further.  Hod Finkelstein, chief research and development officer for AEye, a company that sells lidar technology to automakers, said he does not believe cameras alone are good enough to detect pedestrian intent in all conditions, in part because they aren't good at measuring the distance of faraway objects and can be blinded by car headlights and the sun. Traditional manufacturers of autonomous vehicles have used a combination of cameras, lidar, traditional radar and even ultrasonic sensors for close range.  That the Tesla keeps going after seeing a pedestrian near a crosswalk offers insight into the type of software Tesla uses, known as ""machine learning."" This type of software is capable of deciphering large sets of data and forming correlations that allow it, in essence, to learn on its own.  Tesla's software uses a combination of machine-learning software and simpler software ""rules,"" such as ""always stop at stop signs and red lights."" But as one researcher pointed out, machine-learning algorithms invariably learn lessons they shouldn't. It's possible that if the software were told to ""never hit pedestrians,"" it could take away the wrong lesson: that pedestrians will move out of the way if they are about to be hit, one expert said.  Software developers could create a ""rule"" that the car must slow down or stop for pedestrians. But that fix could paralyze the software in urban environments, where pedestrians are everywhere.  Maynard said that the early-February crash with a bollard may reveal characteristics of how Tesla's system learns.  ""[It] shows that FSD beta is still fazed by edge cases that it hasn't learned to navigate, yet most human drivers would handle with ease,"" he said. ""One question it raises is whether Tesla are teaching FSD by brute force - exposing the algorithms to every conceivable scenario - or whether they are teaching it to learn and problem solve like a human driver. The latter is what makes humans so adaptable on the road, and yet is exceptionally hard to emulate in a machine.""  Optical illusions  In another clip from early December recorded by the same driver, the Tesla appears to stop for a pedestrian crossing the road outside a crosswalk. The Tesla begins to stop long before the pedestrian approaches the curb. Many human drivers would have kept on driving.  The video suggests Teslas may be programmed to slow down for pedestrians if they are moving in the direction of the road, the experts said. But one expert suggested another possibility: The car may have stopped because of an optical illusion.  A red sign between the Tesla and the pedestrian briefly lines up with a tree on the sidewalk, for a moment creating an image generally resembling a stop sign. A later video uploaded in February demonstrated the same phenomenon, suggesting the stop sign illusion was indeed tricking the car.  Were Tesla's software to be confused by a phantom stop sign, that would highlight a key difference with many of its competitors, which use detailed maps showing the precise location of stop signs and other obstacles and road markings.  Struggle for control  In another instance, the same Tesla is passing a UPS truck stopped on a narrow street with parked vehicles on either side. Unsure what to do, the car's software prompts the driver to take over. But the driver struggles to gain control of the vehicle, swinging the steering wheel dramatically from side to side.  ""I am taking over,"" the driver says, as the wheel turns erratically. ""I'm - I'm trying.""  Experts say the incident illustrates a fundamental challenge with Tesla's decision to release software that requires regular intervention by humans. Other companies have bypassed this stage, instead releasing cars that aim to do away with the human driver entirely.  In the case of the UPS truck, both the computer system and the human were attempting to drive the car through a tight spot with very little wiggle room to the left or right. In most cases, the driver takes over by yanking the steering wheel in the opposite direction the software is trying to turn. That movement wasn't possible under these circumstances, however, leaving it unclear whether the car or the human was in control. The struggle for control was amplified by the lack of a sharp turn, preventing the driver from cranking the wheel to regain his steering input from the software.  ""It's unclear who exactly is in control at that moment,"" Maynard said. ""There's an odd glitch here where there seems to be a short fight for control between the driver and the car. It appears there are scenarios where both driver and car potentially lose control at some points.""  Maynard called the incident an ""important"" moment that reveals a glitch not in the car's judgment, ""but in the ability of the human driver to ensure safety.""  Learning to read  Another video The Post analyzed was posted in November by Chris, the Fenton, Mich., driver. The video shows the car failing to react to a ""Stop here on red"" sign, forcing Chris to apply the brakes.  An autonomous-driving researcher said such signs, which are ubiquitous on American roadways, can create vexing problems for Tesla engineers. Unless the car's cameras recognize the letters on the sign, the computer would have to look for other clues, like an arrow or a thin white line painted across the road. But that could create problems in other scenarios, prompting the car to stop erroneously when it sees a line on the road or a similar-looking arrow.  Many of Tesla's competitors use high-definition maps to take the guesswork out of where to stop and turn, the experts said. But that strategy raises other issues, including whether any map can keep pace with precise conditions on the nation's ever-changing network of roads.  ""Most of the problems here are solved if you have maps,"" Templeton said. ""If you use maps, you can drive decently in your service area,"" he wrote in an email to The Post. ""Without maps, you can crash on any street in the country.""  After driving with FSD for about a year, Chris said he thinks it will be a decade before the cars can reliably drive themselves.  The experts who spoke with The Post agreed with that timeline.  ""The last mile of safety is really the hardest part,"" said Musa. ""It's like launching aviation in the early 1900s: They didn't get the first plane right in the first go. They just kept improving every time something bad happens.""   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220211teslavideos  CO 	 teslmi : Tesla, Inc.  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles  NS 	 gcar : Cars | gcat : Political/General News | glife : Living/Lifestyle  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020220206ei2600004","	Outlook","	Companies are still racing to make self-driving cars. But why?","	David Zipper","	2270 words","	6 February 2022","	The Washington Post","	WP","	FINAL","	B01",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  The buzz is back for self-driving cars. Not long ago, blown forecasts left investors and tech enthusiasts feeling deflated: In 2016, Ford planned to offer self-driving taxis by 2021, and Lyft claimed it would start doing so even earlier.  But such unfulfilled promises now lie in the rearview mirror. ""It's beginning to feel like 2016 again,"" Axios proclaimed last month. During the CES electronics show in January, General Motors, Chinese automaker Geely and autonomous-vehicle developer Mobileye all promised that individuals would be able to buy their own self-driving cars this decade, potentially as soon as 2024. ","  If that happened - emphasis on the ""if"" - it would be groundbreaking. Right now, there are no self-driving cars available for public purchase (even if Tesla misleadingly calls its driver assistance system ""Full Self-Driving""). But if and when autonomous vehicles finally arrive en masse, should we cheer, or should we worry? It's a good time to ask an even more fundamental question: What exactly is the point of self-driving cars? The answer, despite more than $100 billion in investment over the last decade, according to McKinsey, remains surprisingly nebulous. And that should trouble us - a lot.  One hundred and 20 years ago, early adopters of ""horseless carriages"" - what we now call automobiles - were often affluent men who flocked to the vehicles as a futuristic, high-tech form of entertainment. But it didn't take long for their potential societal value to become clear, especially in urban areas.  At the time, American streets were filled with horses that required stables and regular feeding, and that left pavement covered in smelly waste. (Horses deposited about 1 million pounds of fresh manure on New York City streets every day, according to Christopher Wells's book ""Car Country."") Cars replaced these messy animals and also allowed cities to spread out, mitigating dangerous overcrowding. While their drawbacks, like smog and traffic deaths, were substantial, automobiles offered real chances for advancement.  Like cars, autonomous vehicles were born not from public need but from technological opportunity. Phil Koopman, an engineering professor at Carnegie Mellon University who has worked on autonomous technology for more than 25 years, saw classmates developing prototypes that lumbered through Carnegie Mellon's campus when he was a doctoral student in the late 1980s. ""They weren't solving a societal problem,"" he says. ""They were solving the 'It would be cool if we could get cars to drive themselves' problem.""  Early tinkerers didn't focus too much on the eventual applications of self-driving technology, but the military did. Specifically, autonomous vehicles offered a chance to limit risk among men and women in uniform - a tantalizing possibility, especially in the wake of the invasions of Iraq and Afghanistan. The Defense Advanced Research Projects Agency (DARPA) organized the first Grand Challenge for autonomous vehicles in 2004 in the Mojave Desert, offering a prize of $1 million to the team whose machine first completed the 150-mile test track. No entrant came close: The farthest any vehicle got was just over seven miles. But the competition captured the imagination of the private sector, even though no one was sure what the civilian purpose of a self-driving car might be.  Enter Google. In 2007 the company hired Sebastian Thrun, leader of the Stanford team that won the second DARPA Grand Challenge, to launch a new self-driving-car initiative that would later form the basis of the company known as Waymo. Planning to deploy its technology on public roads, Google claimed that the rationale for self-driving cars was safety. In a 2010 corporate blog post, the company zeroed in on the 1.2 million annual traffic fatalities worldwide. ""We believe our technology has the potential to cut that number, perhaps by as much as half,"" Google claimed. It was quite a vision - and one whose appeal seemed unassailable from the political right or left. Other AV players followed Google's lead, pointing to safety as the raison d'etre for their own self-driving cars.  In 2015 the National Highway Traffic Safety Administration offered those claims a tail wind when it published a memo stating that human error (along with other factors, such as flawed road engineering or dangerous car design) played a role in 94 percent of traffic collisions. Later, NHTSA's nuanced finding was often boiled down to ""94 percent of crashes are caused by human error"" (a misinterpretation that the Utah Department of Transportation calls a ""staggering fact""). Recognizing a windfall when they saw it, automakers and AV companies placed that 94 percent figure at the center of their marketing pitches.  Unfortunately, the potential safety benefits of self-driving cars are probably overblown. For one thing, many other problems cause crashes besides human error, such as confusing intersections and the blind spots of tall SUVs. But even with that significant caveat aside, it's unclear whether an autonomous driving system will ultimately be safer than a person behind the wheel.  While self-driving cars won't drive drunk or sleepy, the limitations of their machine learning will inevitably lead to mistakes that human drivers wouldn't make. As an example, Koopman recalls a self-driving system a few years ago that struggled to identify the color yellow. ""The system was missing bicyclists in yellow coats and construction workers in yellow jackets,"" he says. ""The system was 99 percent accurate - and it still missed them.""  Koopman believes that the safety hype around AVs is exaggerated. ""There's nothing I've seen showing whether AVs will be safer than humans in the short to medium term,"" he says. ""Machine learning is brittle, and it struggles with things it hasn't seen before."" Especially in cities, seeing something unprecedented - like a woman chasing a duck with a broom, a scene a Google car apparently encountered - is quite common. (Notably, self-driving trucks on highways may be more viable than self-driving cars in cities because of the simpler road environment.) And system errors have already proved deadly: A prototype AV from Uber struck and killed Elaine Herzberg while she walked her bicycle across an avenue in Tempe, Ariz., in 2018. Afterward, Arizona's governor suspended Uber's ability to test its autonomous technology there, and two years later, the company sold its self-driving unit to Aurora, a start-up.  Further complicating safety arguments is the question of whether car companies would design autonomous vehicles to break traffic laws. Until the federal government forced a recall on Tuesday, Tesla's Full-Self Driving system allowed cars to automatically do illegal ""rolling stops"" instead of coming to a complete halt.  If road safety is the goal, there are already plenty of available technologies that automakers could invest in, rather than leapfrogging to fully autonomous vehicles. Take advanced driving assistance systems (ADAS), such as automatic emergency braking and pedestrian detection. Such features have already been shown to save lives, but their capabilities vary wildly from one model to another - assuming they're available at all. According to the Insurance Institute for Highway Safety, automatic emergency braking wasn't installed on 57 percent of the vehicles produced by Stellantis or 42 percent of those from GM during the 12 months ending last Aug. 31. Improving and standardizing ADAS is relatively low-hanging fruit compared with building self-driving cars, with more assured safety benefits.  Other proposed upsides of self-driving cars are also suspect. Will they boost productivity, allowing employees to take work calls and file memos from the road? That seems unlikely: One study concluded that only 1 in 4 drivers even wants to work during their commute. Could they free up space currently allocated to on-street parking? Maybe - though Amsterdam and Paris have shown that cities can do that without relying on autonomous vehicles. Will they expand transportation options for those who are vision- or mobility-impaired? Possibly in rural areas, but in cities and suburbs, people can already call a taxi or hail an Uber.  And then there's the argument that autonomous vehicles can help fight climate change. Tara Andringa, the executive director of Partners for Automated Vehicle Education (PAVE), a national coalition educating the public about AVs, says the technology could provide sustainability benefits, ""if we ensure that AV tech is limiting fossil fuels and that we are moving away from a system where each person has their own car."" Liberation from car dependence is part of the appeal of ""robotaxis"" and autonomous shuttles. Unfortunately, little evidence supports it. Rather than share self-driving rides, studies suggest that people want to travel in their own car, alone (which is consistent with companies' struggles to make pooled ride hail profitable). Automakers have noticed; General Motors, for example, seems to be shifting away from a vision of shared autonomous rides toward one of personal car ownership.  That pivot should sound alarms for those concerned about climate change or the future of cities. While self-driving cars have advanced far beyond the playthings that Koopman encountered at Carnegie Mellon 30 years ago, their societal benefits remain speculative at best. Meanwhile their downsides are very, very real - especially if they become widely available to purchase.  To understand why, consider an experiment in Northern California a few years ago, in which 13 people were given a chauffeur to take them anywhere they wanted for a week, effectively replicating the experience of having their own autonomous vehicle. Freed from the hassles of driving, test subjects traveled a whopping 83 percent more miles than when they had to drive themselves.  A concept called the Jevons paradox explains what happened: When a thing becomes cheaper, people discover new ways to use it. Self-driving cars reduce the ""cost"" of driving - in terms of effort, if not dollars - and as a result, they will induce people to take trips that they would have otherwise foregone. Over time, people with self-driving cars could opt to move farther from the central city, worsening sprawl and leading to still more miles driven.  Even if self-driving cars are electric, those added miles would be disastrous for the environment. Whether powered by batteries or gasoline, all cars produce emissions from brake dust as well as from friction between tires and pavement. And manufacturing EVs and charging batteries both require power and materials, expanding vehicles' total carbon footprint. If we're serious about addressing climate change, promoting transit and cycling instead of driving offers greater potential than any kind of automobile technology, autonomous or electric or otherwise.  For cities, the new driving spurred by AVs would be even more ominous. Without some sort of restrictive policy like a vehicle-miles-traveled tax or decongestion pricing, overwhelmed streets could become mired in gridlock, particularly if owners of self-driving cars avoided parking fees by instructing their vehicles to circle nearby streets while they grabbed a sandwich or met with a client.  These are troubling arguments against self-driving cars, especially when placed against their dubious benefits. But when boosters need a trump card, they can always point to China. When Sens. Gary Peters (D-Mich.) and John Thune (R-S.D.) introduced legislation supporting autonomous vehicles last year, they warned that ""the United States risks losing its technological leadership in the autonomous vehicle industry … unless it enacts policies to protect its leadership against the People's Republic of China.""  But does it really matter if China takes the lead in this realm? Global competition alone seems like insufficient justification to allow unfettered civilian use of a technology that could diminish American quality of life. After all, do the Chinese look with envy at American gunmakers like Smith & Wesson and Ruger, worrying that China's strict gun control and lack of a domestic firearms market hinders them on the world stage?  With so much at stake in the future of self-driving cars, government officials should be keeping a watchful eye on new developments, ready to intervene to defend the public interest. Some do seem to assume that posture. Speaking at CES last month, Transportation Secretary Pete Buttigieg said that self-driving cars have ""raised complicated, even philosophical, questions about safety, equity and our workforce."" But public officials often seem more eager to catalyze the arrival of AVs than to protect cities and citizens - and the planet - from their risks. In 2017, the House of Representatives passed the Self Drive Act, whose goal was ""encouraging"" the deployment of autonomous vehicles; that bill died in the Senate. Last year, the Senate considered Peters and Thune's measure, which would have allowed the carmakers to request that up to 80,000 self-driving cars per year be exempt from established automotive safety rules.  Politicians' support will come as a relief to the carmakers and tech companies whose market valuations rely on an expectation of widespread autonomous vehicle adoption. Companies can't scale self-driving cars if state and federal regulators refuse to bend rules, such as requiring a driver to be behind the wheel.  It's understandable that companies want to maximize shareholder return; that's their role in a market economy. But automakers are still struggling to explain why, exactly, we should be excited about this technology, rather than alarmed by it. We shouldn't let them off the hook unless we have a convincing answer.  Twitter: @DavidZipper  David Zipper is a visiting fellow at the Harvard Kennedy School's Taubman Center for State and Local Government, where he examines the interplay between transportation policy and technology.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220206o-cars0206  IN 	 iadrive : Autonomous Driving Technologies | i3434 : Automobile Electronics | iaut : Automotive | i353 : Motor Vehicle Parts | iindele : Industrial Electronics | iindstrls : Industrial Goods | itech : Technology  NS 	 gcat : Political/General News | nedc : Commentaries/Opinions | gcar : Cars | reqrau : Suggested Reading Automobiles | glife : Living/Lifestyle | ncat : Content Types | nfact : Factiva Filters | nfcpex : C&E Executive News Filter | redit : Selection of Top Stories/Trends/Analysis | reqr : Suggested Reading Industry News  RE 	 usa : United States | namz : North America  IPD 	 Outlook  PUB 	 Washington Post ",NA
"Document WP00000020220203ei230000h","	A-Section","	Tesla drivers report a surge in 'phantom braking' to false-alarm hazards","	Faiz Siddiqui Jeremy B. Merrill","	1399 words","	3 February 2022","	The Washington Post","	WP","	FINAL","	A18",NA,"	English","	Copyright 2022, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - Teslas are unexpectedly slamming on their brakes in response to imagined hazards - such as oncoming traffic on two-lane roads - which has prompted their terrified owners to lodge a surge of complaints with the National Highway Traffic Safety Administration over the past three months, according to a Washington Post analysis of federal auto safety data.  The phenomenon, known as ""phantom braking,"" has been a persistent issue for Tesla vehicles. ","  The automaker was forced to recall a version of its Full Self-Driving software in October over false positives to its automatic emergency-braking system that it said were triggered by the software update. Complaints soared after the recall and remain elevated, signaling continued owner concern.  Owner reports of phantom braking to NHTSA rose to 107 complaints in the past three months, compared with 34 in the preceding 22 months.  In addition to the safety recall in late October, the timing of the complaints coincides with a period in which Tesla has stopped using radar sensors in its vehicles to supplement the suite of cameras that perceive their surroundings. Tesla announced last year that it would stop equipping Tesla Model Y and Model 3 vehicles built in North America with radar beginning in May 2021. Tesla's new approach is known as ""Tesla Vision.""  Tesla vehicles are equipped with eight surround-view cameras that the automaker says ""provide 360 degrees of visibility around the car at up to 250 meters of range."" It also leverages 12 ultrasonic sensors to detect objects around the vehicle. Tesla eventually wants to transition its fleet to Tesla Vision, and some owners have been left wondering whether their cars' radar sensors will be disabled.  Drivers and safety experts said they believe the systems began acting erratically after the changes.  Several of the owners who filed complaints with regulators said their cars seemed overly sensitive to trucks in the opposite lane. One owner described how around noon on a straight road, the car lurched from 50 mph to a near-stop seemingly in response to a large truck.  ""[It] was scary to almost stop in the middle of my lane,"" the owner wrote.  ""Phantom braking is what happens when the developers do not set the decision threshold properly for deciding when something is there versus a false alarm,"" said Phil Koopman, a Carnegie Mellon University professor who focuses on autonomous vehicle safety. ""What other companies do is they use multiple different sensors and they cross-check between them - not only multiple cameras, but multiple types of sensors,"" such as radar and lidar, a type of sophisticated sensor that uses laser lights to paint a dot matrix mapping the environment.  ""With only one sensor type, it's harder to be sure because you do not have the cross-check from a different type of sensor,"" he said.  The NHTSA complaints are not individually verified by the agency. Owners submit their description of the issue, their vehicle identification number and other identifying information when they report their problems to the agency. NHTSA spokeswoman Lucia Sanchez said the agency is engaging in a dialogue with Tesla over the phantom braking reports.  ""NHTSA is aware of complaints received about forward collision avoidance and is reviewing them through our risk-based evaluation process,"" she said. ""This process includes discussions with the manufacturer, as well as reviewing additional data sources, including Early Warning Reporting data. If the data show that a risk may exist, NHTSA will act immediately.""  Tesla, which disbanded its public relations department in 2020, did not respond to a request for comment. The automaker has contended in the past that its driver-assistance feature suite, Autopilot, is safer than typical driving when crash data is compared. Autopilot is a system primarily intended for highway use, so the data cannot be directly compared with vehicle crashes overall. Tesla's chief executive, Elon Musk, has called Autopilot ""unequivocally safer.""  But the company faces mounting scrutiny from regulators, including recalls and safety investigations that called into question the responsibility and performance of its driver-assistance approach.  Tesla initiated a safety recall of its Full Self-Driving driver-assistance software late last month because of a feature than enabled it to conduct ""rolling stops,"" proceeding through intersections with stop signs without fully halting. Tesla had met with NHTSA officials twice in January to discuss the issue, part of growing safety concerns about the cars' automation-targeted software. NHTSA opened a safety investigation in August over about a dozen reports of crashes with parked emergency vehicles while Autopilot was activated.  The Post analysis covered more than a year of data for Tesla vehicles from the four most recent model years.  Owners of the 2022 Tesla Model 3 complained 20 times about the issue known as phantom braking, where the car suddenly slows or stops with no external cause, out of 22 total complaints involving the model.  The events are typically triggered by false positives of the forward collision warning and automatic emergency-braking systems. Owners often cited their use of Tesla's Autopilot driver-assistance system or traffic-aware cruise control in their complaints. They also commonly referred to issues on two-lane highways, where the system was triggered by an oncoming truck in the opposite lane.  The bulk of the complaints recently about Tesla cars have been related to the phantom braking issue - 107, or 57 percent, out of 189 complaints since November about the 2020 through 2022 Tesla Model Y and Model 3, along with the 2019 Tesla Model 3.  Some drivers recalled instances of phantom braking even when they were not using Autopilot. Other owners said in complaints to NHTSA that they were shaken by the incidents and feared being rear-ended.  ""These events are hair raising for me and passengers, let alone for a driver behind me,"" one owner wrote in a report to the agency. ""If he/she does not pay attention at that very moment, the result could even be disastrous. I would never have expected such a serious safety issue with a Tesla.""  Owners also said they experienced the phenomenon one or multiple times while on extended trips. Some said their road trip experiences were marred by the brakes suddenly triggering or the frequency jolts made by their cars.  ""My wife has requested that I don't use cruise control or autopilot while she's in the car, as we experienced an unwarranted, aggressive automatic braking episode which caused great pressure against her pregnant belly on a previous road trip,"" one owner said in a report.  Owners' comments reflected apparent exasperation with the recurrence of the problem and a seeming inability to get it fixed.  ""[These] things are happening with NOTHING present in front of my vehicle, and sometimes with nothing around me at all,"" one wrote.  Luis Fernandez, who drives a 2022 Tesla Model Y, said he was at Taylor Street and Pine Street in San Francisco recently when his car spotted a plastic bag several feet in front of him. The bag didn't pose a hazard and was soon out of his view, said Fernandez, who uses the vehicle to drive for Uber.  But his car jolted him from 25 mph to 15 mph before he could intervene.  ""Suddenly the car kind of locked, but it immediately released because the plastic bag moved away. . . . The car just completely took precaution,"" he said. ""Automatically, it braked.""  A 2021 Tesla Model Y owner, Ben Morris, confirmed that he was one of the people who filed a complaint with NHTSA. He said this was his third Tesla, and the issues presented themselves more than ever before on his other models.  ""We primarily drove the car on two-lane highways, which is where the issues would show themselves consistently,"" he said in an email. ""Although my 2017 Model X has phantom braked before, it is very rare, the vision-based system released May 2021 is night and day. We were seeing this behavior every day.""  He recalled an instance when his wife was driving at highway speeds of 55 to 60 mph and ""it slammed on the brakes hard, sending our children's booster seats slamming into the front seats.""  Thankfully, he said, the children weren't in the car.  Chris Alcantara contributed to this report.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20220203teslabraking  CO 	 nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc.  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles  NS 	 crecal : Product Recalls | gtacc : Transport Accidents | c26 : Product/Consumer Safety | ccat : Corporate/Industrial News | cexpro : Products/Services | gcat : Political/General News | gdis : Disasters/Accidents | gmmdis : Accidents/Man-made Disasters | gtrans : Transport  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020211224ehco00009","	A-Section","	Tesla restricts gaming feature in moving cars","	Faiz Siddiqui","	410 words","	24 December 2021","	The Washington Post","	WP","	FINAL","	A18",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - Tesla will no longer allow drivers and front-seat passengers to play video games while its cars are in motion, the company told federal regulators after a probe was opened this week.  ""Tesla informed the agency that it is changing the functionality of this feature,"" Lucia Sanchez, a spokeswoman for the National Highway Traffic Safety Administration, said. ""In a new software update, 'Passenger Play' will now be locked and unusable when the vehicle is in motion."" ","  Sanchez said Tesla's move followed the opening of a preliminary evaluation into the feature on Tuesday, which allowed drivers and passengers to play solitaire and more advanced games while the car was moving by simply agreeing to a prompt that the software was for passenger use.  ""The Vehicle Safety Act prohibits manufacturers from selling vehicles with defects posing unreasonable risks to safety, including technologies that distract drivers from driving safely,"" Sanchez said.  She said the evaluation continues while federal regulators gather additional information from Tesla.  Tesla did not immediately respond to a request for comment from The Washington Post. The company in the past has touted potential safety benefits of its advanced driver-assistance system, Autopilot, comparing its performance to driving overall.  But federal regulators worry that in-car distractions paired with systems that introduce automation will encourage drivers to take their eyes off the road. And Autopilot's performance is not directly comparable to regular driving because the system consists of primarily highway-only features.  A second system, called Full Self-Driving, is a software beta available to limited group of thousands of testers - and is intended to be used on city and residential streets.  NHTSA opened a probe this summer into Autopilot over crashes involving a dozen parked emergency vehicles while the system was activated. The agency also asked Tesla and other carmakers, along with manufacturers of self-driving vehicles, to report on any crashes involving autonomous and advanced-driver assistance systems within a day of learning of the incidents.  Sanchez said this week that NHTSA had opened its 580,000-vehicle probe into in-car gaming because of concerns about driver distraction.  ""NHTSA based its decision on reports that Tesla's gameplay functionality is visible from the driver's seat and can be enabled while driving the vehicle,"" she said, noting that ""no commercially available motor vehicles today can drive themselves.""  faiz.siddiqui@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20211224Tesla1224  CO 	 nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc.  IN 	 i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iaut : Automotive  NS 	 gcar : Cars | gcat : Political/General News | glife : Living/Lifestyle  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020211112ehbc0001e","	A-Section","	Tesla's bumpy road with regulators","	Faiz Siddiqui","	1766 words","	12 November 2021","	The Washington Post","	WP","	FINAL","	A17",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - For a few hours late last month, Tesla cars began behaving erratically after receiving an overnight software update. Cars suddenly started slamming on the brakes at highway speeds, owners reported, risking collisions. CEO Elon Musk took to Twitter to acknowledge a problem with the software and vow that the update was being rolled back.  Ordinarily, that would have been the end of it for Musk, whose company has often flouted standard regulatory practices. But late last month, Tesla unexpectedly reported the glitch to the National Highway Traffic Safety Administration and issued an official recall notice detailing the problem, which may have affected nearly 12,000 vehicles. ","  Tesla's decision comes as the Biden administration has stepped up enforcement of federal safety regulations regarding advanced driver-assistance systems - particularly Tesla's habit of issuing software fixes without reporting underlying problems. Last month, NHTSA publicly dinged Tesla for failing to issue a formal recall when it issued a separate software update that enabled its cars to better detect parked emergency vehicles in low light. The update followed around a dozen prior crashes involving parked emergency vehicles while a system called Autopilot was activated.  It wasn't an isolated instance of criticism for the electric carmaker.  The National Transportation Safety Board, which has investigated multiple crashes involving Tesla's Autopilot software, has publicly called out the automaker over its failure to follow up on its safety recommendations. NHTSA, the top federal auto safety regulator, is investigating the Autopilot software itself - bringing potential regulatory authority to the equation. Musk has taken aim at federal regulators, but they haven't budged. Transportation Secretary Pete Buttigieg said recently the CEO was free to take up his concerns directly with him.  Longtime auto-industry observers and safety experts say Tesla is getting the message, even if Musk continues to be combative. The repeated incidents have potential financial and legal ramifications for Tesla, they said.  ""Inside Tesla, there has been a shift,"" said John Rosevear, senior auto analyst at the Motley Fool. Employees are concerned that ""'we're exposing ourselves here and we need to maybe get more serious about this,'"" he added.  Tesla, which has disbanded its public relations department, did not respond to a request for comment. The company has argued in the past that using Autopilot is safer than normal driving, based on comparisons of crash data. Musk has called Autopilot ""unequivocally safer."" Upon confirming the rollback of capabilities the company calls Full Self-Driving, he said occasional issues are ""to be expected with beta software,"" which is intended to be tested in a variety of conditions to iron out problems.  Company officials pledged to work with NHTSA in a recent earnings call, saying Tesla embraced the scrutiny on its software.  The official recall notice marks a sharp departure from Tesla's more typical mode of operation, in which it acts like its Silicon Valley neighbors to send update after update to the software that powers its products, making fixes in real time.  But Tesla vehicles are also being beta-tested in real time on the road - and the latest updates highlight the heightened dangers that come with putting software that is still a work in progress in the hands of drivers.  Full Self-Driving is the latest iteration of the company's software, now in the hands of roughly 12,000 drivers who paid as much as $10,000 to upgrade and received early access or passed a safety screening. It adds capabilities to navigate city and residential streets, with an attentive owner behind the wheel at all times. The features are not autonomous by regulatory and industry standards.  But already drivers have been reporting issues. Videos uploaded to social media show the software struggling to navigate roundabouts, veering toward pedestrians and even abruptly turning toward oncoming traffic.  Even Musk acknowledged in July that the software - which began its rollout to users a year ago - was a ""debatable"" proposition for potential subscribers.  The company's less advanced version of the software, dubbed Autopilot, is standard on Tesla vehicles. The software can navigate highways from on-ramps to off-ramps, and can also steer within marked lanes.  Things started escalating when NHTSA announced over the summer it would begin requiring Tesla and other manufacturers to report on incidents involving advanced driver-assistance systems, such as Autopilot. And in August, the agency launched a formal probe of Autopilot after nearly a dozen crashes involving parked emergency vehicles.  One of Tesla's latest run-ins with NHTSA came in October, after Tesla didn't notify officials of the emergency vehicle software update in September. It issued the update shortly after the government opened a probe into Tesla collisions with emergency vehicles.  NHTSA notified Tesla that such an action would typically be initiated through the federally established recall process, intended to remedy urgent safety risks through a combination of manufacturer expertise and government oversight.  ""Any manufacturer issuing an over-the-air update that mitigates a defect that poses an unreasonable risk to motor vehicle safety is required to timely file an accompanying recall notice to NHTSA,"" an agency official wrote in the Oct. 12 letter.  The agency also issued a letter in October raising concerns about another practice: requiring Full Self-Driving beta testers to sign a nondisclosure agreement prohibiting them from sharing certain information about the software beta. The agency noted it relies on the feedback from the public to learn of potential safety issues.  Tesla did away with the agreement, according to Musk, who compared it to toilet paper.  Kevin Smith, of Murfreesboro, Tenn., drives a Tesla Model Y and is part of the beta test. On Oct. 24, he hoped to test out the latest update but instead was locked out of the system, he said. And as he tried to get it to work, he heard from a fellow beta tester.  ""He was screaming 'Do not use it! Do not use it!'"" Smith said. ""'We are trying to wake up the folks at Tesla, trying to get the word to Tesla.'""  One of Smith's fellow testers shared a video showing one of the emergency-braking events - including ""a pretty dramatic slamming of the brakes,"" he recalled. ""For that to trigger undesirably at high speeds is an incredibly dangerous event.""  Smith noticed later that day Tesla had also remotely disabled his auto emergency braking and forward collision warning functions, safety features that he would ordinarily keep activated. And they hadn't let him know.  ""Dear @elonmusk, are you in there crossing the streams? I didn't change this brah,"" he wrote in a tweet. ""This isn't ok without any communication. Communication is not hard. I'm doing it now. Please advise.""  By the following day, NHTSA had asked Tesla for more information about the incident, according to NHTSA spokeswoman Lucia Sanchez.  Auto safety experts say Tesla's tweaks to safety features - without any notice to owners - were an unprecedented violation of trust. And it was exactly the type of behavior that had triggered the attention of federal auto safety regulators in the past.  Carnegie Mellon University professor Philip Koopman, who focuses on autonomous-vehicle safety, described it as ""incredible - not in a good way.""  ""If you're testing, you need to know if they're changing your vehicle out from under you,"" he said. ""Just taking that away and not making it super super obvious to drivers that that's happened is extremely concerning.""  Tesla submitted its recall notice on Oct. 29. In the bulletin, the company detailed why corrective action was necessary. It was the first time many drivers learned of what actually happened. That document, which confirmed what Tesla called the ""false-positive braking"" and accompanying warning chimes experienced by drivers, detailed the sequence of events that resulted from the buggy software update.  ""Tesla began to receive reports of false [forward collision warning] and [automatic emergency braking] events from customers,"" it wrote. ""In a matter of hours, we investigated the reports and took actions to mitigate any potential safety risk. This included cancelling [the update] on vehicles that had not installed it, disabling FCW and AEB on affected vehicles, and/or reverting software to the nearest available version.""  Tesla also laid out the risk to owners. ""If the AEB system unexpectedly activates while driving, the risk of a rear-end collision from a following vehicle may increase,"" it wrote.  Safety experts say it appears Tesla issued the recall because of the mounting regulatory pressure. NHTSA's Sanchez declined to say whether the recall came at federal safety regulators' urging. ""NHTSA will continue its conversations with Tesla to ensure that any safety defect is promptly acknowledged and addressed,"" she said.  Publicly, Musk has reacted to the increased regulatory attention. He's taken aim on Twitter at the Biden administration and federal auto safety appointees from both the NTSB and NHTSA.  He lashed out last month after NHTSA appointed Duke University professor Missy Cummings, who has been critical of Tesla's Autopilot and autonomous ambitions, as senior safety adviser.  In a tweet, he called her track record ""biased."" Tesla-supporting Twitter users swarmed her account, attacking her record. Buttigieg defended the appointment and invited Musk to raise his concerns with him directly, according to news reports.  NHTSA declined to make Cummings available for an interview.  NTSB chair Jennifer Homendy recently spoke with The Post and other publications, publicly scolding Tesla for rolling out new features without addressing prior recommendations about Autopilot. Those included instituting better driver monitoring and implementing safeguards to make sure it is used in the conditions for which it is intended.  Musk tweeted her Wikipedia page soon after. His followers also went after her.  Over the weekend, Musk reacted to a different type of government attention: a U.S. Senate proposal to institute a billionaire's tax that would target unrealized gains of the richest Americans. He created a poll on Twitter, in which 58 percent of the more than 3 million responses indicated he should sell 10 percent of his shares in Tesla.  ""Much is made lately of unrealized gains being a means of tax avoidance, so I propose selling 10% of my Tesla stock,"" he wrote, adding in a later tweet: ""I will abide by the results of this poll, whichever way it goes.""  Musk sold about $5 billion worth of stock this week - some of it in a planned move related to his stock options - throwing the purpose of the poll partially into question.  faiz.siddiqui@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20211112teslaregulation  CO 	 nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc.  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles  NS 	 c13 : Regulation/Government Policy | ccat : Corporate/Industrial News | ncat : Content Types | nfact : Factiva Filters | nfcpin : C&E Industry News Filter  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020210831eh8v00024","	Editorial-Opinion","	Safety and self-driving cars","	Letters to the Editor","	199 words","	31 August 2021","	The Washington Post","	WP","	FINAL","	A18",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  The Aug. 24 editorial ""Checking the 'autopiloted cars' hype"" was an overdue and honest reckoning of the misleading hype promoted by some auto and tech companies about autonomous vehicles. We are still miles from achieving safe and fully autonomous vehicles.  On this trajectory, incremental steps could save thousands of lives. Crash-avoidance technologies, such as automatic emergency brakes (AEB), are available and effective. Research by the Insurance Institute for Highway Safety shows that AEB can reduce front-to-rear car crashes by 50 percent. Meanwhile, some manufacturers are opposing federal regulation to make AEB standard equipment, overcharging consumers by offering AEB only on high-end vehicles or as part of expensive luxury packages and overpromising the self-driving capabilities of cars. ","  We commend the National Highway Traffic Safety Administration for investigating the Tesla crashes. Regulating advanced technology to ensure it is safe and before we find out there are serious problems should be the agency's next move.  Cathy Chase, Washington  The writer is president of Advocates for Highway and Auto Safety.  Jack Gillis, Washington  The writer is executive director of the Consumer Federation of America.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20210831let-chase31  CO 	 iifhsi : Insurance Institute for Highway Safety  NS 	 gmmdis : Accidents/Man-made Disasters | c26 : Product/Consumer Safety | nedi : Editorials | ccat : Corporate/Industrial News | cexpro : Products/Services | gcat : Political/General News | gdis : Disasters/Accidents | ncat : Content Types  RE 	 usa : United States | namz : North America  IPD 	 Editorial-Opinion  PUB 	 Washington Post ",NA
"Document WP00000020210824eh8o00009","	Editorial-Opinion","	Checking the 'autopiloted cars' hype","	Editorial Board","	468 words","	24 August 2021","	The Washington Post","	WP","	FINAL","	A16",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  THE TROUBLE with semiautonomous vehicles? You can't afford to fall asleep at the wheel. The National Highway Traffic Safety Administration, in beginning a broad investigation of systems used in thousands of Tesla's electric cars, has finally woken up.  The imagined future of a driverless fleet rolling down U.S. streets looks a little like a utopia: reducing car ownership, alleviating traffic and making it much easier for the elderly and disabled to move around. Accidents and deaths will also decrease, because today the vast majority are caused by human error; machines, trained and tested, will make dramatically fewer mistakes. This future is one we should want. The problem is, we're nowhere near there. Yet too many car owners act as though we are, and companies can encourage the illusion. ","  This is the context underlying the NHTSA probe. The agency has been criticized for a lackadaisical approach to its mission beyond the realm of artificially intelligent cars, and the hope was that the new administration would bring changes. The NHTSA will examine nearly a dozen crashes with parked emergency vehicles involving Tesla's Autopilot settings - both of which, crucially, are only partially self-driving and require a human to intervene should the need arise. The NHSTA will look into the common circumstances of the crashes, presumably to detect any defects in the systems' ability to identify obstacles. But crucially, the agency will also assess the way in which the systems do (or don't) keep users engaged.  Sens. Richard Blumenthal (D-Conn.) and Edward J. Markey (D-Mass.) include a matching emphasis in a letter to the Federal Trade Commission urging its members to look at what the senators described as ""potentially deceptive and unfair practices in Tesla's advertising and marketing."" The manufacturer has been selling an upgraded suite of features called Full Self-Driving as part of a promise to eventually produce vehicles that are, well, fully self-driving. Right now, however, the cars can't drive themselves without human help, a caveat that the owner's manual includes. Tesla has argued that its data shows its cars are safer than average, and that driver-assistance features such as Autopilot make them safer still. But the cars would be even safer than that if the company hammered in the need for user involvement rather than elided it in its marketing.  Regulators, understandably, have been wary of stymying innovation by interfering too much with the development of driverless vehicles. Yet companies risk getting in their cars' own way when they overhype current capabilities, prompting customers to put themselves in dangerous situations whose consequences inspire backlash to the autonomous ambition. Mandating honesty about today's limitations could pave the road for a more promising tomorrow.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP202108243edit-cars0824  IN 	 i35104 : Alternative Fuel Vehicles | iadrive : Autonomous Driving Technologies | i351 : Motor Vehicles | iaut : Automotive | itech : Technology  NS 	 nedi : Editorials | gcar : Cars | gcat : Political/General News | glife : Living/Lifestyle | ncat : Content Types  RE 	 usa : United States | namz : North America  IPD 	 Editorial-Opinion  PUB 	 Washington Post ",NA
"Document WP00000020210819eh8j0000w","	A-Section","	Digest","","	682 words","	19 August 2021","	The Washington Post","	WP","	FINAL","	A21",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  AUTO INDUSTRY  Senators want FTC to investigate Tesla ","  Two U.S. Senators are urging the Federal Trade Commission to investigate whether Tesla uses deceptive marketing practices by labeling its driver-assistance systems ""Autopilot"" and ""Full Self-Driving.""  Democratic Sens. Richard Blumenthal (Conn.) and Edward J. Markey (Mass.) wrote in a letter to FTC Chair Lina Khan on Wednesday that Tesla ""has repeatedly overstated the capabilities of its vehicles, and these statements increasingly pose a threat to motorists and other users of the road.""  ""We fear that Tesla's Autopilot and FSD features are not as mature and reliable as the company pitches to the public,"" the senators wrote. ""Tesla drivers listen to these claims and believe their vehicles are equipped to drive themselves - with potentially deadly consequence.""  The letter comes days after the National Highway Traffic Safety Administration launched an investigation into Tesla's Autopilot following almost a dozen crashes with first-responder vehicles.  - Bloomberg News  ECONOMY  2020 U.S. income tax payments decreased  Nearly 61 percent of U.S. households paid no federal income taxes during 2020 because of pandemic-related declines in income and boosts to government subsidies that wiped away tax liabilities, according to data from the Urban-Brookings Tax Policy Center.  The number of households owing nothing came in at 106.8 million, up from 75.9 million in 2019, the study, released Wednesday, showed.  The 60.6 percent proportion for last year compares with 43.3 percent over the five years before the pandemic struck.  The number of families owing no federal income taxes is projected to remain high for 2021, around 101.7 million households, or 57.1 percent, according to the estimates.  The data underscore how federal assistance measures, including stimulus payments, tax-free unemployment benefits and expanded child tax credits offset the federal tax bills many families would have otherwise owed during the pandemic.  - Bloomberg News  Also in Business  Old Navy is overhauling its approach to how it designs and markets to plus-size women. Starting Friday, Old Navy will be offering every one of its women's styles in all sizes with no price difference. That means sizes 0 to 28 in stores and up to size 30 online. The 1,200-store chain, Gap Inc.'s low-price division, will also be displaying its large sizes together with the standard sizes on the floor. The fashions will be displayed on mannequins in sizes 4, 12 and 18. Online, the chain is merging its plus size and standard sizes together, with models appearing in all three sizes.  A U.S. judge rejected a request by Toronto-Dominion Bank to dismiss a class-action lawsuit brought in December by credit card customers who alleged the lender did not adhere to the terms of their agreement. Customers who obtained TD credit cards secured by a frozen deposit between 2016 and 2019 were told that if they did not default on payments for seven months, they may be eligible to automatically ""graduate"" to an unsecured credit card. This did not happen, according to documents filed with the United States District Court in New Jersey.  BlackRock and Knighthead Capital Management are investing in a $200 million second round of capital to support the expansion of start-up low-cost carrier Breeze Airways. The funding also includes additional investments by Peterson Partners and Sandlot Partners, which helped provide an initial $100 million in capital that backed the May start of flights by the Utah-based carrier, Breeze Aviation Group said. Breeze offers nonstop flights from relatively small airports, primarily to leisure destinations.  Furniture giant Ikea will offer renewable energy to Swedish households for the first time, tapping into the growing market for green electricity as it further diversifies its business. Starting in September, the company will offer electricity produced from solar plants and wind turbines, together with energy supplier Svea Solar, it said in a statement. It plans to branch out to other markets eventually. With the new service, Ikea aims to encourage the production of more solar and wind capacity.  - From news services   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20210819digest0819  CO 	 ftrade : Federal Trade Commission | teslmi : Tesla, Inc.  IN 	 i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iaut : Automotive  NS 	 nsum : News Digests | ncdig : Corporate Digests | ncat : Content Types | nfact : Factiva Filters | nfce : C&E Exclusion Filter | niwe : IWE Filter  RE 	 usa : United States | namz : North America  IPD 	 National-Economy  PUB 	 Washington Post ",NA
"Document WP00000020210817eh8h00012","	A-Section","	Tesla's Autopilot system faces probe following collisions","	Aaron Gregg Ian Duncan Faiz Siddiqui","	1291 words","	17 August 2021","	The Washington Post","	WP","	FINAL","	A10",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  The nation's top auto safety watchdog has launched a formal investigation of Tesla's driver-assistance system after nearly a dozen crashes involving parked emergency vehicles occurred while Autopilot was engaged.  The National Highway Traffic Safety Administration inquiry, which was opened Friday and detailed in a document made public Monday, covers 765,000 Teslas - models Y, X, S and 3 - produced from 2014 to 2021. In 11 crashes recorded since 2018, one person was killed and 17 people injured. ","  The Palo Alto, Calif.-based automaker, which has disbanded its public relations department, did not respond to an emailed request for comment.  The investigation comes as the auto industry races toward a driverless future. Tesla's driver-assistance suite - starting with Autopilot and then its ""Full Self-Driving"" package - is among the most ambitious in its efforts to complete many driving tasks automatically. Waymo, owned by Google parent company Alphabet, is working on a self-driving car, along with an array of competitors sporting names such as Aurora, Cruise and Zoox.  Although regulators and industry experts caution that driver-assistance features do not make a vehicle autonomous, Tesla has sought to capitalize on the perception that such technology will one day enable their vehicles to drive themselves.  The investigation creates a potential wrinkle in those plans. Tesla has put ""Full Self-Driving"" in hundreds of vehicles with the caveat that drivers still must be alert while their cars are in motion. Regulators, so far, have taken a relatively hands-off approach; experts say they are wary of any perception they might be stifling innovation.  The inquiry may signal a new regulatory environment. In June, authorities started requiring manufacturers, including Tesla, to report crashes involving such technology within a day of learning of the incident. On Monday, a NHTSA spokeswoman told The Washington Post that the preliminary investigation will focus on Tesla's Autopilot system and ""technologies and methods used to monitor, assist, and enforce the driver's engagement with driving while Autopilot is in use.""  Sens. Richard Blumenthal (D-Conn.) and Edward J. Markey (D-Mass.), who serve on the Senate Commerce, Science and Transportation Committee, said NHTSA is ""rightly investigating"" Tesla's Autopilot after a series of crashes.  ""This probe must be swift, thorough, and transparent to ensure driver and public safety,"" they said in a joint statement. ""It should inform the agency's recommendations on fixes the company must implement to improve the safety of its automated driving and driver assistance technology and prevent future crashes.""  Tesla shares tumbled following word of the federal probe, falling 4.3 percent to close Monday at $686.17.  The agency is examining two systems: Tesla Autopilot and the Traffic Aware Cruise Control. Both are ""partial"" self-driving car systems designed to recognize and avoid oncoming traffic while a human driver retains control of the vehicle. Neither qualifies as autonomous, and drivers are expected to be at the ready even when the systems are turned on.  The investigation carries several touch points that suggest a more sophisticated, focused approach to ensuring driver-assistance systems are safe. The difference, experts say, is that authorities now appear to be taking a hard look at how human drivers interact with these new automated systems.  According to the announcement, investigators will look into the ""operational design domain,"" a term that refers to the range of places and situations in which the Autopilot can be turned on. Under current Tesla design, the driver can turn on Autopilot essentially anywhere. Investigators will also look into aspects of the vehicle's ""operational event detection and response"" technology, which refers to how the vehicle understands its surroundings.  Probing both concepts will bring NHTSA †• a relatively obscure unit of the Department of Transportation whose work typically involves more mundane matters like parts recalls †• into deeply technical debates about how drivers interact with automated technology.  ""As we navigate the emerging world of advanced driving assistance systems, it's important that [safety regulators] have insight into what these vehicles can, and cannot, do,"" National Transportation Safety Board chair Jennifer Homendy said in a statement.  The crashes that are the basis for the federal investigation bear some common threads, even beyond the presence of first-responder vehicles. Most, for example, occurred late at night.  In one incident from late February, a Tesla rear-ended a police cruiser that was conducting a traffic stop after 1 a.m., according to the local ABC affiliate. Local news reports describe a dramatic chain reaction crash that totaled two police cars; five officers and a police dog sustained minor injuries. One officer who had been underneath the vehicle at the time of the collision grabbed onto the car and was pulled along. A person who had been standing on the shoulder of the road when the crash happened was taken to the hospital in critical condition, ABC reported at the time.  The earliest crash cited by NHTSA occurred in January 2018 in Culver City, Calif. Robin Geoola, a carwash owner, had been driving his Tesla Model S to work with the Autopilot on when it slammed into a firetruck.  ""All I remember seeing is just my car stopped and my windshield was shattered, and I didn't know what happened,"" Geoola recalled in a recent interview. ""After I became a little bit more aware, I opened the door. I came out I saw my car was under a firetruck.""  Authorities concluded that both driver and vehicle were at fault. The National Transportation Safety Board investigated the crash and concluded that Geoola's ""inattention and overreliance"" on Autopilot, as well as Tesla's design of the system, caused the crash. Geoola said he wasn't ticketed, saying ""I didn't break any law.""  Geoola had to replace his vehicle after the crash and chose another Tesla, crediting his Model S with saving his life.  ""Same color, same year,"" he said. But there was one key difference: The new one wasn't capable of using Autopilot.  In a May 2018 crash in Laguna Beach, Calif., David Scott Key recalled in a recent interview that he was driving through an area where he likes to go mountain biking and was looking out at the trails. His 2015 Tesla Model S was on Autopilot.  ""All of a sudden I slammed into a police car,"" Key said.  The Laguna Beach Police Department concluded that Key caused the crash by driving too quickly, according to the report of its investigation, but a department spokesman said he wasn't issued a ticket.  Key, an engineer, said he remains confident in the vehicle's Autopilot system despite the crash.  ""It's much, much safer to be on Autopilot than it is to be a human driving, however that does not mean there won't be accidents,"" he said.  NHTSA opened the same kind of review of Autopilot in 2016, after a Tesla driver was killed when his Model S crashed into a tractor-trailer while the system was activated. The review was closed Jan. 19, 2017, †• at the end of the Obama administration †• with NHTSA saying ""a safety-related defect trend has not been identified at this time and further examination of this issue does not appear to be warranted.""  Ed Niedermeyer, communications director for the nonprofit Partners for Automated Vehicle Education, said it's critical for drivers to understand that these systems cannot drive on their own.  He said his organization ""welcomes regulators' engagement with these serious issues and affirms the importance of clear communication about the human role in any driving automation system.""  aaron.gregg@washpost.com  ian.duncan@washpost.com  faiz.siddiqui@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20210817TESLAPROBE  CO 	 waymmo : Waymo LLC | nathg : National Highway Traffic Safety Administration | teslmi : Tesla, Inc. | goog : Alphabet Inc.  IN 	 iaut : Automotive | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iadrive : Autonomous Driving Technologies | itech : Technology  NS 	 gcar : Cars | gtacc : Transport Accidents | reqrau : Suggested Reading Automobiles | gcat : Political/General News | gdis : Disasters/Accidents | glife : Living/Lifestyle | gmmdis : Accidents/Man-made Disasters | gtrans : Transport | redit : Selection of Top Stories/Trends/Analysis | reqr : Suggested Reading Industry News  RE 	 usa : United States | namz : North America  IPD 	 National-Economy  PUB 	 Washington Post ",NA
"Document WP00000020210630eh6u00023","	A-Section","	U.S. to require reporting on crashes involving driver-assistance systems","	Faiz Siddiqui","	492 words","	30 June 2021","	The Washington Post","	WP","	FINAL","	A20",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  Federal authorities will require companies such as Tesla and Alphabet-owned Waymo to report incidents involving driver-assistance and automated systems within one day of a learning of a crash, a major change that signals a tougher stance by regulators.  The National Highway Traffic Administration on Tuesday announced the change, which covers systems ranging from what are known as Level 2 to Level 5, encompassing advanced driverassistance systems such as Tesla Autopilot and automated driving systems like the autonomous vehicles being deployed by companies in Silicon Valley and elsewhere. ","  Companies will be required to report crashes where the ""system was engaged during or immediately before the crash,"" NHTSA said in a news release.  ""Access to [automated driving system] data may show whether there are common patterns in driverless vehicle crashes or systematic problems in operation,"" the agency said.  Waymo declined to comment. Tesla did not immediately respond to requests for comment.  While many autonomous vehicles are deployed in states that have regulations on the books, driver assistance systems such as Autopilot have often fallen into a regulatory gray area that allowed incidents to escape further examination. Under the new rules, a company must quickly report crashes involving a death or an injury treated at the hospital, a vehicle towed away, an air bag deployment or the involvement of a pedestrian or cyclist.  Companies must also submit monthly reports of all crashes with injuries or property damage that involve automated systems, NHTSA said.  The systems have come under scrutiny as companies have increasingly put them in the hands of drivers and deployed them on public roads. Uber halted its self-driving vehicle program after one of its SUVs struck and killed a 49-year-old woman pushing a bike across a road in 2018.  And Tesla has come under scrutiny for crashes involving Autopilot, its driver-assistance system that includes features allowing cars to navigate from highway on-ramp to off-ramp, along with detecting stop signs and traffic lights, and automatically parking and summoning the vehicles. In one case, a Tesla operating in Autopilot mode plowed into the side of a tractor-trailer, killing the Tesla's driver. The National Transportation Safety Board said the case involved overreliance on the driver-assistance features.  NHTSA says it has examined more than two dozen incidents involving Autopilot.  ""By mandating crash reporting, the agency will have access to critical data that will help quickly identify safety issues that could emerge in these automated systems,"" Steven Cliff, NHTSA's acting administrator, said in a statement. ""In fact, gathering data will help instill public confidence that the federal government is closely overseeing the safety of automated vehicles.""  According to NHTSA, failure to comply with the mandate could result in fines of up to $22,992 per day and a maximum penalty totaling more than $100 million.  faiz.siddiqui@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20210630safetyreporting  CO 	 waymmo : Waymo LLC | teslmi : Tesla, Inc. | goog : Alphabet Inc.  IN 	 i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology  NS 	 gdis : Disasters/Accidents | gcat : Political/General News  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020210523eh5n0002o","	Business","	Tesla's path as an 'iPhone on wheels'","	Faiz Siddiqui","	2667 words","	23 May 2021","	The Washington Post","	WP","	FINAL","	G03",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  Tesla released its futuristic ""Full Self-Driving"" package last year to great fanfare, criticism and the usual stream of video uploads showing off cars that could seemingly drive themselves.  Then something strange happened. ","  The electric vehicle giant revoked access for some drivers, it said. Tesla CEO Elon Musk announced on Twitter in March that some users who had received access to the company's most advanced driver-assistance features ""did not pay sufficient attention to the road."" Tesla did not say how it made the determination or who among the feature's 2,000 beta testers - who shelled out thousands for the package that Tesla now priced at $10,000 - would lose access.  But in Silicon Valley, the decision reflected a well-understood formula: Consumers are the subject, and tech giants are in control.  From the time they hit the mass market nearly a decade ago, Tesla's vehicles have garnered reputations as ""iPhones on wheels,"" a revolutionary technological leap that did for cars what Apple's smartphone did for consumer tech. They offered large touch screens, a vast charging network and groundbreaking performance that delivered on the dream of electrification seemingly without compromise, where competing products failed to stitch all aspects of that formula into one.  Like Apple, Tesla built its brand on exclusivity and aspirational products, prioritizing the experience of ownership as much as the utility of the device itself. And both companies have integrated software with hardware in a way that revolutionized their industries, making the transition to new technologies relatively intuitive for even the non-tech-savvy user.  But consumers can pay a price for being locked into Tesla's universe, like Apple customers in the computer giant's ecosystem. They are at the mercy of Tesla's way of doing things, from car repairs to software updates.  It's no accident the companies have a lot in common, according to a half-dozen former employees who worked for both Tesla and Apple, who spoke on the condition of anonymity because of the sensitive nature of the workplace dynamics and for fear of retaliation. Tesla hired managers who brought members of their teams from Apple, importing its design language and culture. Meanwhile, those employees could be dismissive of the automotive expertise within its ranks, the former employees said.  ""Tesla is not an automotive company, it's a tech company that builds cars,"" said one former employee of both companies who worked in products.  That also translates to the company's leadership. Musk, who recently crowned himself ""Technoking"" of Tesla, has taken after Apple co-founder and Silicon Valley demigod Steve Jobs in more ways than one, some of the workers said.  Musk has been known to spend meetings scrolling on his phone, before lashing out over decisions he viewed as misguided, outbursts that would often precede a firing, according to the employees.  ""In the same way Steve Jobs could be cutthroat and terse and explosive, Elon is the same way,"" said the former employee, who worked at the companies under both men.  The companies' shared vision includes an emphasis on some forms of proprietary technology. Tesla uses a unique charging connector, similar to Apple products with their ""Lightning"" connectors. It has built out what it says is the world's largest fast-charging network, consisting of more than 25,000 Superchargers. The cars' groundbreaking over-the-air updates mean users can be subject to sudden performance changes if products become out of date - like battery throttling for which Apple has come under fire. Tesla's unique systems have also proved difficult for government authorities investigating crashes to decode, a problem that echoes federal authorities' difficulty unlocking Apple devices.  It's a far cry from a traditional auto industry built largely on standardization - from gas pumps to windshield wipers, to in-car infotainment systems with Apple CarPlay and Android integration. Tesla has its own touch-screen interface that can prove to be a learning curve for new adopters, though it enables a user experience uniquely suited for its cars - an integration of hardware and software reminiscent of Apple.  Tesla, Musk and Apple did not respond to multiple detailed requests for comment. The automaker disbanded its media relations team last year.  Tesla and Musk have said they want their technology to be embraced by other players in the industry. They have promoted open-source software and criticized the overuse of patents, and Musk has even said Tesla's Superchargers are ""being made accessible to other electric cars,"" though it's unclear whether any agreements are actually in place.  Apple says its closed-source environments help it keep its products secure and free of hostile software. Some critics disagree, pointing to areas where the computer giant falls short.  Tesla's performance has dazzled investors. The company's stock has skyrocketed in recent months, prompting Musk to tweet in March that he sees Tesla becoming the world's biggest company, surpassing even Apple's more than $2 trillion market cap. (By late April, Tesla was worth more than $675 billion.)  In recent years, some current and former employees said, Tesla has become the more attractive workplace for some in Silicon Valley.  Fueling that recruiting: The prospect of working for a visionary CEO or a company with a goal to change the world. Musk has overseen Tesla's modern development into the industry leader in electric vehicles. And Tesla has pitched that vision to many who were otherwise concerned about its scrappy, start-up environment that paled in comparison to the state-of-the-art ""spaceship"" headquarters of Apple or the food and beverage perks of Google or Facebook.  One corporate recruiter in Silicon Valley described the funnel of interchanging talent between Apple and Tesla as ""incestuous."" The companies share talent pools of engineers from top schools, the current and former workers said, though Tesla is much less concerned about a person's formal education credentials than Apple, they said. The person recently in charge of Tesla's vehicle and mobile user interface design, for example, was previously a senior art director at Apple, though he recently departed Tesla as well. Tesla hired Apple alumnus George Blankenship to lead its retail strategy a decade ago, putting sleek showrooms in malls and city centers, mimicking the experience-focused store model he had pioneered at Apple.  ""There is a strong Tesla-to-Apple pipeline that is well-known within both companies,"" said another recruiter.  Even Musk has publicly heaped praise on Apple and its workers.  ""It's a great company with a lot of talented people. I love their products,"" he wrote on Twitter in 2015, saying he was glad to hear about plans that Apple was developing an electric vehicle.  Automotive alums from Detroit did not garner the same respect, however. ""There was no empathy for these people in Michigan,"" said the recruiter, describing how Tesla expected them to jump at any opportunity to work in Silicon Valley. And in the halls of Tesla, the auto alums were regarded as ""dinosaurs,"" the former products employee recalled.  That talent swap with Apple has helped Tesla build a car company that attempts to mimic the successes of the older tech giant, the current and former workers say, in some cases foisting new designs on consumers without market research to back them up.  ""I think that we have an empathy problem, a systemic empathy problem, in Silicon Valley,"" one of the former employees said, pointing to what he regarded as the companies' elite attitudes and disdain for market research.  The former employees pointed to polarizing product unveilings like the Cybertruck, which took the proven design of the pickup truck and transformed it into an apocalyptic stainless steel behemoth.  Then there are the system updates.  Months after buying a used Tesla Model S for nearly $46,000, Harpreet Singh began to notice the car wouldn't travel far enough on a single charge to cover his work trips frequently stretching more than 200 miles.  Tesla had taken about 40 miles of range off his used Model S, which began with 265 miles, in what Tesla said was an effort to protect the battery. The update also slowed down charging times, Singh said. Tesla ultimately agreed to replace what it later concluded was a faulty battery, but at the expense of what Singh has found is slower acceleration.  After the car and its new battery were working properly, Singh began to dread system updates, because they introduced new problems like the shorter range and decreased charging rates.  Singh said he thinks about it like other tech updates. ""I'm so comfortable with Windows 8. . . . Why do I have to change to Windows 10? And then everything breaks,"" said Singh, 33, of Cypress, Tex. ""Same thing here. . . . They can do anything to do it.""  That issue, among others, led to a lawsuit from Tesla owners who allege the company issued software updates that reduced range, lengthened charging times and ultimately cut into the value of their vehicles. The plaintiff named in the 2019 class-action complaint, David Rasmussen, 64, of Victorville, Calif., said his used Tesla Model S went from 252 miles of rated range to 217 miles after the software changes. And he said some owners tried to find workarounds to resist software updates.  The National Highway Traffic Safety Administration has an open investigation into Tesla's battery management software updates.  Tesla has argued it uses over-the-air updates for safety improvements and to enhance the ownership experience.  Apple was accused of ""throttling"" old devices, slowing down customers' iPhones to preserve their batteries as operating systems updated, essentially nudging them into buying new devices. The company agreed in late 2020 to pay $113 million to settle an investigation by nearly three dozen states on the matter. The agreements with states did not require Apple to admit guilt.  Tesla isn't the only automaker updating its vehicles over the air, but it has made a mark on the industry by using the technology to introduce dramatic changes that affect driving dynamics, even improving the cars' brakes overnight. Some of the changes would require a trip to the dealer for any other automaker. Jaguar, for example, boosted the range of its I-PACE electric vehicles by 12 miles in 2019, but the tweak required an in-person service to unlock.  Some of the employees who made the leap between Tesla and Apple said they found Tesla to be sloppier on execution. Tesla put still-developing products, from Autopilot software to its newest cars, in the hands of consumers without the steady hand and design direction preventing the software bugs and quality control flaws.  Tesla billed its ""Autopilot"" driver-assistance suite as a way to enable the car to drive itself, with its ultimate iteration ""Full Self-Driving"" ushering in the era of fully autonomous vehicles for consumers. But industry competitors and safety-minded officials are wary of Tesla's nomenclature, saying it paints an impression far beyond the vehicles' actual capabilities.  Owners have taken notice of the shortcomings. Stephen Raynor, an attorney who lives Richardson, Tex., was alarmed when his Model S equipped with Full Self-Driving abruptly veered toward a highway barrier as it approached a toll road exit near his home.  ""It's just not ready for prime time,"" he said of Tesla's Autopilot suite. ""It just didn't read it right and it wanted to go left and the exit was right.""  Tesla has argued that Autopilot carries a nearly 10 times lower chance of a crash than a vehicle in normal driving. The company says its connected fleet enables it to ""develop features that can help Tesla drivers mitigate or avoid accidents."" And Tesla says its over-the-air software updates allow it to make safety enhancements well after a car has been delivered.  Apple's focus on hardware and software integration has in some cases meant higher costs, limited compatibility and little customization. Apple didn't want users to manipulate its closed-source environments or mess with its meticulously designed products.  Tesla has made similar design decisions, even ones viewed as user-hostile, or that flew in the face of common industry practice. The company recently debuted a ""yoke""-style steering wheel for its refreshed Model S. With a half-moon shape that sacrificed ergonomics for a racing-inspired, futuristic look, the component was criticized as a downgrade to user-friendliness, which analysts said had implications for safety.  And Tesla has even stated it aims to phase out the gear selector, replacing the standard park, reverse, drive and neutral setup with a gear ""swipe"" option in the cars' center screens, to flick between drive and reverse. Tesla said it ultimately wants its cars to predict whether they should be going forward or backward.  Apple, too, had made design decisions that struck some as tone-deaf. Jobs famously eschewed market research, saying it was instead the job of the company to show customers what they wanted. The company nixed the ubiquitous headphone jack from its smartphones, forcing the adoption of Bluetooth ear buds, and has eliminated certain ports in favor of thinness and streamlined design, making users rely on dongles to connect accessories. And it came under a swarm of criticism for its ""butterfly keyboard,"" a space-saving component noted for its tendency to break before Apple phased it out.  Adding to the pattern: a trend toward shorter life spans generally associated with tech devices vs. traditional cars.  Consumers and critics balked earlier this year when Tesla's acting general counsel argued with regulators that its cars' iPad-like touch screens should not be expected to last the life span of the vehicle, an argument that was anathema to an industry used to ""automotive grade"" components. That was a key issue for Tesla because the touch screens serve as a command center for the car, hosting the climate controls, navigation and music, and even functions such as opening the glove box.  After initially sparring with regulators, Tesla agreed to recall tens of thousands of Model S and X vehicles over the touch screen failures.  ""It's like its superpower and Achilles' heel at the same time: It doesn't do things by the rule book,"" said a former senior employee.  Analysts said Tesla turned the traditional carmaker-owner relationship on its head.  ""The argument that equipment on modern cars that cost that much is not expected to last that long - that is a major violation of the auto industry as we know it,"" said Mike Ramsey, an automotive analyst at the firm Gartner's CIO Research Group. ""If you're going to adopt the consumer electronics ethos, you can't do it halfway.""  Full Self-Driving features are also not transferrable between cars, meaning an owner who has shelled out $10,000 for the software would have to buy it for their next Tesla as well.  Musk has said, however, that Tesla will look into upping the trade-in value for a vehicle with Full Self-Driving, after some owners complained about having to purchase it twice.  Tesla has also sought to restrict how drivers use the features it bills as self-driving, suggesting they could not, for instance, use them for ride-hailing on Uber and Lyft. Instead they could leverage them only for Tesla's own ride-hailing network built by a fleet that Musk envisioned would consist of 1 million robo-taxis by 2020, a target date that proved overly optimistic.  Owners also face difficulty finding easy repairs and frequently turn to Tesla out of fear they will void their warranties. Raynor, the Texas attorney, said his Model S touch screen suddenly went half-blank for two days, limiting access to features such as the backup camera and climate controls.  ""With all the electronics, very few mechanics want to get near it,"" he said.  faiz.siddiqui@washpost.com  Reed Albergotti contributed to this report.   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20210523teslatech  CO 	 applc : Apple Inc. | teslmi : Tesla, Inc.  IN 	 i34411 : Mobile Communications Devices | iadrive : Autonomous Driving Technologies | icellph : Cell/Mobile/Smart Phones | i3302 : Computers/Consumer Electronics | i3441 : Telecommunications Equipment | i3454 : Personal Electronics | iaut : Automotive | ielec : Consumer Electronics | ihandaps : Handheld Electronic Devices | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles  NS 	 gcar : Cars | gcat : Political/General News | glife : Living/Lifestyle  RE 	 usa : United States | namz : North America  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020210419eh4j0000k","	A-Section","	Digest","","	854 words","	19 April 2021","	The Washington Post","	WP","	FINAL","	A03",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  TEXAS  Authorities search for triple-shooting suspect ","  A 41-year-old man is wanted in the fatal shooting of three people in Austin, and police officials searching the surrounding area on Sunday warned residents that the suspect might take a hostage.  Interim Austin police chief Joseph Chacon said the suspect, Stephen Broderick, is considered armed and dangerous.  He asked area residents to continue to shelter in place and to call their neighbors to check on them.  ""We are concerned he might possibly take a hostage and be himself sheltered somewhere waiting for us to leave,"" Chacon said at a news conference Sunday afternoon.  He described Broderick as 5-foot-7 and black, wearing a gray hoodie, sunglasses and a baseball cap. He said that Broderick was a former deputy with the Travis County sheriff's office, which is based in Austin.  Chacon said police do not know whether he is in a vehicle or on foot.  Chacon said Broderick is suspected in the killing of two Hispanic women and one Black man. He said Broderick knew the victims, but he didn't elaborate.  Chacon also said that a child at the scene is safe with authorities.  Brenda Torres said she was driving by when she saw a young boy flag down a car and a Black man lying facedown on the ground.  ""I saw the little boy point down the street,"" Torres said. ""There was someone lying on the ground. I thought someone had just fallen down or something. As my light turns green and I'm driving, I see cop car after cop car after cop car rushing toward where I just was.""  Chacon said the three were not shot in a building but did not give additional details.  - Associated Press  No driver apparent  in fatal Tesla crash  A Tesla electric car that ""no one"" appeared to be driving crashed late Saturday near Houston, erupting into flames and killing the two passengers, local authorities said.  One victim was found in the front passenger seat of a 2019 Model S, and the other was in the rear, Harris County Precinct 4 Constable Mark Herman said. The car ran into a tree in the Carlton Woods subdivision near the Woodlands after traveling at high speed and failing to navigate a turn.  The position of the victims, statements and other physical evidence suggest that ""no one was driving the vehicle at the time of impact,"" Herman said. ""It's still under investigation.""  Herman said he didn't know whether the car's autopilot feature was engaged.  Tesla did not immediately respond to a request for comment Sunday.  Federal officials have criticized Tesla for fire risks related to the battery packs in its cars and for not doing enough to keep drivers from using its driver-assist function inappropriately.  - Bloomberg News  ILLINOIS  7-year-old girl killed, father hurt in shooting  A 7-year-old girl was killed and her father was seriously injured in a shooting Sunday at a McDonald's in Chicago.  Jontae Adams and his daughter, Jaslyn, were in a car Sunday afternoon in a McDonald's parking lot in the Homan Square neighborhood when they were shot, Chicago police said.  A McDonald's employee who spoke on the condition of anonymity told the Chicago Sun-Times that two people got out of a gray car in the drive-through and started shooting at Adams's car.  The girl, who has three siblings, was shot repeatedly. She was taken to a hospital, where she was pronounced dead. Her father was shot in the torso and taken to the same hospital, where his condition was listed as serious, police said.  No arrests have been made and police have not offered a possible motive.  - Associated Press  Warrant issued for teen in fatal Nebraska shooting: A murder warrant has been issued for a teenage boy suspected in a shooting at a Nebraska mall that left one man dead and a woman injured, police said Sunday. Omaha police said Makhi Woolridge-Jones, 16, is wanted on a charge of first-degree murder in the shooting Saturday at the Westroads Mall in Omaha. Brandon Woolridge-Jones, 18, has been arrested on a charge of being an accessory to the shooting. Police said a third man has been identified as a person of interest in the shooting but did not release his name. Police said Trequez Swift, 21, was shot and died at an Omaha hospital. A woman, Ja'Keya Veland, 22, was wounded in the leg.  Chicago high schools' reopening approved: The Chicago Teachers Union has approved a plan to reopen high schools starting Monday, the union said Sunday. The union tweeted that ""the CTU Rules & Elections Committee has certified the ballot results of the high school addendum to our reopening agreement with CPS. Members voted 83% in favor of ratification."" It added: ""The addendum is now a ratified agreement between our union and the district."" The vote to reopen public high schools to students for the first time since they were closed last year because of the coronavirus pandemic was expected.  - From news services   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20210419domestic0419  NS 	 gcrim : Crime/Legal Action | gmurd : Murder/Manslaughter | nnam : News Agency Materials | nsum : News Digests | gcat : Political/General News | ncat : Content Types | nfact : Factiva Filters | nfce : C&E Exclusion Filter | niwe : IWE Filter  RE 	 ustx : Texas | usa : United States | austin : Austin | namz : North America | uss : Southern U.S.  IPD 	 National-Politics  PUB 	 Washington Post ",NA
"Document WP00000020210228eh2s0003t","	Business","	Musk's load is showing at Tesla","	Faiz Siddiqui","	2453 words","	28 February 2021","	The Washington Post","	WP","	FINAL","	G02",NA,"	English","	Copyright 2021, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - Elon Musk says he is stretched too thin.  The chief executive of both electric car manufacturer Tesla and rocket company SpaceX bounces nearly daily on his private jet between locations - traveling to his longtime home in Southern California, Tesla's plant in the Bay Area, the site of a new factory in Austin, and SpaceX's launch facility on that state's Gulf Coast. ","  Twice in a matter of days recently, the 49-year-old complained of what he called an ""insane"" work schedule, juggling responsibilities with his car company and aerospace firm and taking in ""torrents of information"" in wall-to-wall meetings.  But critics say the rigors of Musk's schedule, and the seeming cult of personality that has developed around him, are beginning to show in the car company he runs - the one that he took from an upstart pioneer in electric vehicles to the world's most valuable automaker. Musk, they say, is drowning in commitments like his aerospace company and other endeavors while letting quality - and strategy - at Tesla fall victim. And there are familiar concerns.  ""There have been years past where some of his behavior was horrifying and had cost huge costs, especially from his little tussle with the SEC,"" said Ross Gerber, a Tesla investor and supporter of Musk who is close to the company. ""And he's come a long way. What I'm worried about is his success makes him a little bit loose again.""  Musk spent much of the past year trying to demonstrate his aerospace firm's viability to shuttle people into space on reusable rockets, while Tesla worked to construct multiple factories and launched a new SUV. He also juggled the birth of a son and his personal move to Texas. He sprinkled in public appearances in venues such as social media app Clubhouse in between his barrages of tweets. Musk became the world's richest person in January, thanks to skyrocketing Tesla stock.  In interviews with a dozen current and former Tesla employees, investors and analysts, critics pointed to a slate of questionable business moves, and outright missteps by Tesla, as a potential symptom of the outside demands on Musk. They described a company where Musk is less present and increasingly isolated, where subordinates are reluctant to question the CEO's vision and where the de facto position entails eschewing market research. It's a top-down, shoot-by-the-hip ethos directed by Musk.  Tesla did not respond to repeated requests for comment. In response to emails seeking comment, Musk replied only:""Give my regards to your puppet master.""  In a regulatory filing in February, the company highlighted the risk it faces by relying so much on Musk.  ""We are highly dependent on the services of Elon Musk, our Chief Executive Officer and largest stockholder,"" Tesla said in the filing, in language unusual for the way it cited a corporate CEO's numerous outside commitments. ""Although Mr. Musk spends significant time with Tesla and is highly active in our management, he does not devote his full time and attention to Tesla.""  The filing cited Musk's helm over SpaceX and ""other emerging technology ventures."" Along with Tesla and SpaceX, Musk leads an outfit focused on merging the human brain with computers, Neuralink, along with a tunnel-building firm, Boring Co.  Musk's impulsive leadership has worked to Tesla's benefit so far. His bets have vaulted it to the world's most valuable automaker. The company delivered a record of nearly 500,000 vehicles in 2020 and has cannibalized prospective U.S. electric vehicle sales from practically every other automaker.  But cracks have started to appear as Tesla has stumbled on some vehicle releases and as its vehicles grow older, prompting some recalls. Regulators are scrutinizing the company for fires and some of its more innovative features.  ""There isn't a culture at Tesla really other than 'Let's do what Elon wants to do,' "" said Ed Niedermeyer, who wrote the book ""Ludicrous: The Unvarnished Story of Tesla Motors.""  ""He becomes more powerful, and that power sort of isolates him more and more.""  Current and former Tesla employees described Musk as less present on the factory floor in recent months, involving himself primarily in higher-profile events, like end-of-quarter delivery crunches and matters related to the company's earnings calls and investor presentations. That's a contrast from around three years ago, when the chief executive was known to sleep at the factory as the Model 3 faced production issues.  ""I think the stress is definitely less now that the company's more established,"" said one former employee on an automation team paid close attention by Musk, who spoke on the condition of anonymity because he was not authorized to speak publicly on company matters. ""His pressure on certain things has certainly dropped.""  Musk grew up in South Africa and went on to study in Canada and then the University of Pennsylvania. He emerged as a tech titan with the sale of the site he co-founded, PayPal, to eBay in 2002. Musk, the payments platform's onetime CEO, pocketed $165 million. He founded SpaceX in 2002, with the ambition to take humans to Mars in a private venture.  He invested in Tesla in 2004, a year after its founding, and holds more than a 20 percent stake in the company, according to a regulatory filing this month. He was named chairman in 2004, though he would lose that title in the wake of a 2018 spat with the Securities and Exchange Commission.  Musk became Tesla CEO in 2008 and proceeded to mastermind the launch of a series of electric cars that were sporty and aspirational, yet carried enough range to make them practical. That combination helped bring electrification to the masses, as Tesla went from niche luxury automaker to an electric vehicle powerhouse, selling nearly half a million vehicles per year.  Musk has more than 47 million followers on Twitter, thanks in part to a bombastic personality there that has landed him in trouble.  He's cut in the mold of many tech company CEOs, who are under constant pressure to keep their companies fresh and innovative. But as Tesla reaches middle age, it faces similar risks as other personality-driven Silicon Valley start-ups turned giants.  Apple CEO Steve Jobs was known for his vision until his death in 2011 prompted what some view as a loss of innovation at the tech giant. Amazon will soon face the transition of founder and chief executive Jeff Bezos to executive chairman, testing the culture he has instilled. (Bezos owns The Washington Post.)  ""The biggest asset within Tesla is Elon,"" said Dan Ives, an analyst with Wedbush Securities who has followed Musk's moves closely over the years. He added that some have worried what will happen if ""Musk feels like he's had massive success with Tesla, he's built an unparalleled brand and now he could go from fifth gear to third gear.""  Even Musk recently questioned how long he can keep it up.  ""Nobody is or should be CEO forever,"" he observed during a Tesla earnings call late last month, launching a wave of speculation - almost certainly premature - about a potential looming departure. ""It would be nice to have a bit more free time.""  It's a far cry from just two years ago, when the company's stock hit a recent low amid production and demand concerns. Musk had faced an SEC investigation costing him and Tesla $20 million each, and he lost his chair on the company's board in 2018.  Musk has come out of the pandemic more famous and respected than ever. He is, depending on the day, the world's richest or second-richest person. Fortune named him its 2020 Businessperson of the Year. He made Gallup's poll of the world's most admired men, sandwiched between Pope Francis and Sen. Bernie Sanders (I-Vt.) in the top 10.  After hitting a near-term low of $177 per share in mid-2019, Tesla's stock soared to a new high of more than $2,000 just over a year later, before the company implemented a 5-for-1 split late last summer. Tesla's cash flow woes had abated and the company was posting consecutive quarters of profitability.  Tesla faced an unusual stumble in late 2019, when the company released a polarizing pickup, dubbed the Cybertruck. While its sci-fi-derived design won over the company's most ardent fans, the angular proportions and stainless steel exoskeleton were off-putting to many who would have otherwise been interested in a Tesla pickup, and it remains unclear whether the truck can be legally built with its current specifications.  As the coronavirus took hold, Musk started tweeting that the panic over it was ""dumb."" And he wrote that there would be ""close to zero new cases"" by the end of April a year ago. He was on a call with Trump where he pushed reopening and praised the president. He had a public meltdown during an earnings call in late April, raging against California officials' shutdown orders in an expletive-laden rant.  ""To say that they cannot leave their house and they will be arrested if they do, this is fascist,"" he said on the call. ""This is not democratic - this is not freedom.""  Jennifer Chatman, a management professor at the University of California at Berkeley's Haas School of Business, pointed to Tesla's firing of workers who had opted to stay home during the pandemic, a broken promise to workers first reported by The Post.  ""Every time you reduce the quality of Tesla as a workplace, then by definition you're going to reduce the quality of the employees who are willing to work there,"" she said.  In May, Musk sent his company's stock plunging with an eyebrow-raising tweet questioning its value. He also used Twitter to announce the birth of a son, X à† A-Xii (initially spelled X à† A-12 but changed to comply with California regulations).  ""I am selling almost all physical possessions,"" Musk wrote during that whirlwind period in May. ""Will own no house.""  That same month, Musk oversaw the most important mission in SpaceX's history, with the successful launch to space - and safe return - of a pair of NASA astronauts, becoming the first private company to fly humans into orbit.  And like so many Californians who have become fed up with the state's politics and frequent natural disasters, Musk last year moved to Texas.  As he moved and focused more energy on SpaceX, Tesla employees said he didn't have the same presence he once did. Special requests from Musk dwindled.  Tesla's hotly anticipated Model Y crossover, released in 2020, has struggled, prompting the company to yank some variations from the lineup and cut the price by up to $3,000 at a time. Its refreshed Model S includes a controversial half-moon ""yoke""-style steering wheel that aims to automate turn signals and gear selections, something likely to be scrutinized by regulators.  The Model Y faced quality control concerns after its launch early last year, including reports that the roof of a brand-new vehicle blew off, and a back seat was not attached. Some analysts attributed poor build quality to the strain of producing cars during the pandemic.  Meanwhile, Tesla in October debuted the feature suite it dubs ""Full Self-Driving"" amid regulatory and industry concerns it was not ready. The company is not using the most advanced hardware available and is instead opting for a cheaper approach that relies on a series of interconnected cameras to stitch together live images of what the car sees.  Some of Tesla's current fleet of passenger vehicles are nearing a decade old - with the flagship Model S and the Model X SUV facing a recall over faulty high-tech screens that failed to meet automotive standards.  And observers balked at Tesla's response to the screen recall ordered by federal regulators in January. The company's vice president of legal argued that Tesla's giant center screens should not be expected to last the life span of the vehicle, raising concerns about the longevity of the cars overall.  Musk now finds himself with the chance to expand Tesla's global reach in Europe and Asia, and stretch its appeal to the middle of the country where Tesla plans to build its Cybertruck.  Tesla has started construction on a factory in Austin, and another near Berlin that is expected to supply its vehicles in Europe. Meanwhile, it is continuing an aggressive expansion into Asia, after the company built a facility in Shanghai where it is manufacturing a locally made variant of its Model 3 and Model Y.  Musk has staked his bets on the Model Y crossover, which he has said will outsell its models S, X and 3 combined. He says he ultimately wants Tesla to build 20 million cars per year.  Such claims might normally strike investors as pie-in-the-sky predictions.  ""Even a Jobs comparison is unfair at times because [Musk is] even one step even more extreme in terms of what he's done publicly,"" said Gene Munster, an investor and managing partner of Loup Ventures who follows Tesla and Musk closely. ""There is a group of founders and CEOs that are controversial but do a great job for shareholders, and that's Steve Jobs and that's Elon.""  Investors and analysts point to more recent concerning signs. Just this month, Tesla said in a business filing that it had invested $1.5 billion in bitcoin and would begin accepting the cryptocurrency as a payment. While it's a potentially savvy move to benefit from the volatile cryptocurrency, analysts also said it entails serious financial risk.  After Musk last weekend opined on Twitter that the value of cryptocurrencies seemed too high, bitcoin values fell by around $10,000.  ""We're seeing this with Elon Musk: a lack of impulse control,"" said Chatman, the UC-Berkeley professor.  One employee, who spoke on the condition of anonymity because he was not authorized to speak publicly about company matters, said he winced as he learned a fellow factory employee had poured $70,000 derived from company-issued Tesla stock into bitcoin, following Musk's lead.  ""He knows whatever he says, people do and he's taking advantage of it,"" the worker said. He recalled warning his co-worker that Musk ""doesn't care about you; he'll ruin you.""  faiz.siddiqui@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20210228MUSK  CO 	 spaetc : Space Exploration Technologies Corp. | teslmi : Tesla, Inc.  IN 	 iaut : Automotive | i35104 : Alternative Fuel Vehicles | i351 : Motor Vehicles | i364 : Aerospace Products/Parts | i3640046 : Space Vehicles | iaer : Aerospace/Defense | iindstrls : Industrial Goods  NS 	 ccat : Corporate/Industrial News | reqrau : Suggested Reading Automobiles | redit : Selection of Top Stories/Trends/Analysis | reqr : Suggested Reading Industry News  RE 	 usca : California | namz : North America | usa : United States | usw : Western U.S.  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020201022egam0002a","	A-Section","	Tesla moves toward 'full self-driving' amid criticism the tech is not ready","	Faiz Siddiqui","	1867 words","	22 October 2020","	The Washington Post","	WP","	FINAL","	A22",NA,"	English","	Copyright 2020, The Washington Post Co. All Rights Reserved","  SAN FRANCISCO - In a year when Tesla might have been forgiven for extending its timeline on a key initiative, Elon Musk is forging ahead with a vision for what he calls ""Full Self-Driving.""  This week, a group of drivers was selected to receive a software update that downloaded automatically into their cars, enabling the vehicles to better steer and accelerate without human hands and feet. According to Tesla, hundreds of thousands of its cars will be able to drive themselves as soon as this year, probably making them the first large fleet of vehicles billed as autonomous owned by ordinary consumers. ","  Tesla is forging ahead despite skepticism among some safety advocates about whether Tesla's technology is ready - and whether the rest of the world is ready for cars that drive themselves. An industry coalition consisting of General Motors' Cruise, Ford, Uber and Waymo, among others, this week criticized the move by Tesla, saying its vehicles are not truly autonomous because they still require an active driver.  Self-driving is lightly regulated in the United States, and Tesla does not need permission to launch the new feature.  A point of contention among Tesla's critics is that the company is moving ahead without a key piece of hardware. Nearly all makers of self-driving cars have embraced lidar sensors, which are placed on the outside of vehicles and can detect the precise size, shape and depth of objects in real time, even in bad weather.  Instead, Tesla is trying to achieve full self-driving with a suite of cameras and a type of radar that are constantly connected to an advanced neural network. Tesla's technology can detect vehicles and pedestrians in the road and some objects such as trees, but it cannot always see the true shape or depth of the obstacles it encounters, according to some safety experts. That might not allow the car to distinguish between a box truck and a semi as it approached the rig from behind, for example.  Tesla CEO Musk has decried lidar as ""expensive,"" redundant and ""a fool's errand,"" calling anyone who relied on it ""doomed.""  In addition, unlike autonomous vehicle companies such as Waymo and Cruise, which have been testing their self-driving cars in controlled pilot programs, Tesla has decided to put its self-driving technology into the hands of consumers. That means the risks of a malfunction will be absorbed by ordinary drivers.  Tesla did not respond to requests for comment. The company has said it will not activate full self-driving until it receives regulatory approval, though it remains unknown exactly what certification would be needed. Musk said on Twitter the self-driving beta rollout would be ""extremely slow & cautious, as it should.""  The company reported its quarterly earnings Wednesday, posting a $331 million profit.  Demonstrating the challenges, in one such recent update, some Tesla cars could detect red lights and stop signs but would not proceed through the intersection until the driver confirmed via the accelerator or steering wheel stalk that the traffic light was green, according to Tesla.  ""The fundamental challenge of neural nets is achieving sufficient reliability to use in a safety-critical system,"" said Edward Niedermeyer, communications director for the Partners for Automated Vehicle Education (PAVE) campaign, a coalition of nonprofits seeking to help the public better understand driverless technology.  ""I'm puzzled as to where the confidence came from almost four years ago that they'd be able to do this,"" said Niedermeyer, who wrote the 2019 book ""Ludicrous: The Unvarnished Story of Tesla Motors."" ""The reason you do these things is because it's an extremely hard problem, and it's not realistic to solve this problem with some cameras.""  Virtual lidar  Silicon Valley regards autonomous vehicles as the holy grail of transportation's future, enabling customers to deploy their cars as driverless robo-taxis, making the owners money even when they would be typically parked in the garage, in Tesla's case. It could also shrink the cost of an Uber or Lyft trip to just cents on the mile by eliminating the need to pay a driver.  Several companies are making slow but steady progress on that goal, too. Waymo announced this month that it would be launching driverless vehicles in the Phoenix metro area, becoming the first entity to bring the vision of fully autonomous cars to consumers as part of a dedicated ride-hailing service. Last week, Cruise said it would launch driverless cars in San Francisco, becoming the first company to debut unmanned vehicles in such a complex city environment and the country's second-densest metropolis.  Tesla's public timeline has been rapid. Musk promised in 2019 Tesla would have 1 million robo-taxis on the road by 2020, a reference to the company's full-self-driving ambitions.  The company's self-driving technology will make use of the eight surrounding-view cameras attached to its cars. Those cameras collect critical data on how to navigate chaotic freeways, labyrinthine city streets and dense traffic.  Musk has said the new software being delivered this week will better capture the view outside the cars and more seamlessly integrate the footage Tesla collects, creating a kind of stitched-together, multidimensional view. It will collect data that the company's engineers can label and help the computers better interpret. The cameras would replicate a core function of lidar, seeing what is happening around the cars.  In essence, Tesla is aiming to compensate for its hardware limitations by supercharging its software, almost to create a virtual lidar using Tesla's existing suite of cameras, said Eshak Mir, a former Tesla Autopilot engineer who reviewed and worked with data aimed at training Tesla's neural network.  ""They're trying to combine all the feeds from the cameras into one full video and label it in real time,"" Mir said. ""With that, you'll be able to pick up a full sense of depth.""  There is no true industry hardware standard for a self-driving car. But before Tesla came along, there was little question that a sophisticated sensor in the vein of lidar was necessary for the redundancy and complex image processing required of self-driving vehicles. Some experts continue to hold that view.  Overcast skies, rain, snowstorms and especially bright sunlight can challenge mere cameras' perception. ""In normal daylight conditions, the cameras work perfectly fine,"" Mir said.  ""Just from my experience, cameras are very dependable, but at the same time there can be a challenge when there's harsh conditions,"" added Mir, who supports Tesla's current approach.  For the broader, lidar-equipped fleets, safety setbacks - including a fatal crash when a pedestrian was struck by a self-driving Uber in 2018 - have led to delays and slower timelines for autonomous vehicles as a whole. And some are questioning whether truly driverless vehicles are possible.  ""They say that it's just around the corner, but you don't realize that the effort to get just around the corner gets more and more and more [complicated] as you get closer to the corner,"" said Ted Pavlic, an Arizona State University assistant professor in the School of Computing, Informatics, and Decision Systems Engineering, who works in robotics and autonomous systems.  Companies developing dedicated robo-cars for ride-hailing purposes, such as Waymo, Amazon-acquired Zoox, Uber and Cruise, all use lidar in their vehicles. They consider lidar a critical element of redundancy capable of making rapid-fire observations in all manner of conditions, filling in gaps where the cameras fall short.  On a recent autonomous vehicle trip in downtown San Francisco, for example, the lidar sensor spotted vehicle traffic over a steep hill before the camera suite or view out the windshield showed it, and the car began making adjustments earlier than a human driver might have. Most testing of autonomous vehicles has been with lidar.  Waymo conducted 1.45 million miles' worth of autonomous vehicle testing in California last year, the company reported to the state Department of Motor Vehicles. Tesla vehicles drove a total of 12.2 autonomous miles, to record what it called a ""demo run"" around its Palo Alto headquarters. Tesla has argued that it ""has a fleet of hundreds of thousands of customer-owned vehicles that test autonomous technology in 'shadow-mode' during their normal operation,"" constantly improving through billions of miles of real-world driving. Shadow Mode allows it to test some of those automated features without actually activating them in the real world.  Autopilot concerns  Still, Tesla has been dogged by safety concerns, including regulatory investigations and multiple crashes involving Autopilot that have resulted in fatalities and injuries. The National Highway Traffic Safety Administration has said it is looking into more than a dozen incidents involving the Autopilot software. Tesla has also faced lawsuits from the families of victims in Autopilot-related crashes.  Tesla has repeatedly defended the Autopilot system, saying it is merely there to assist the driver, who is ultimately responsible for the safe operation of the car.  Autopilot, Tesla's driver-assistance system that operates like an advanced cruise control function, has been criticized for giving users an exaggerated view of its cars' capabilities. At this stage, the cars are capable of highway driving from on-ramp to off-ramp, self-parking and summoning - where they can navigate to the driver in a crowded parking lot, for example. In cities, Tesla's vehicles can detect traffic lights and stop signs. It is not autonomous, however, and Tesla has faced criticism for giving users the impression the system is capable of driving the car itself - without supervision.  ""Autopilot is not an autonomous system and does not make our vehicles autonomous,"" the company noted in a disclosure to the state DMV. California's vehicle codes, for example, state that autonomous test vehicles must be capable of ""performing the dynamic driving task on a sustained basis without the constant control or active monitoring of a natural person.""  Pavlic, who works with autonomous systems, recently purchased a Tesla Model 3 but didn't opt for the $8,000 ""Full Self-Driving"" package.  He said Tesla risks giving users an exaggerated impression of the cars' capabilities with the over-the-air updates, various iterations of Autopilot and ""Full Self-Driving"" marketing.  ""It requires you to be very educated to be able to parse these things,"" he said. ""I would say I can definitely see how someone might think that Autopilot did more than it did . . . as they're rolling out these new features.""  Tesla owners are no stranger to the challenges, observing how new and previous unpredicted sights can leave their cars confused.  Zlatko Unger, a 36-year-old Model 3 owner who lives in Redwood City, Calif., recalled taking his car to a horse park he frequents on a weekend in late July, when his car detected a hazard it displayed on its info screen.  ""I noticed it picked up the piles of poop as [traffic] cones, and I was like, hey, this is not right,"" he said.  faiz.siddiqui@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20201022TESLAFULLSELFDRIVING  CO 	 waymmo : Waymo LLC | teslmi : Tesla, Inc. | ubrti : Uber Technologies Inc. | goog : Alphabet Inc. | ubrib : Uber International B.V.  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology | i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iecom : E-commerce | iint : Online Service Providers | itnsv : Sharing/On-demand Economy Services  NS 	 gcar : Cars | ccat : Corporate/Industrial News | gcat : Political/General News | glife : Living/Lifestyle  RE 	 sfra : San Francisco | namz : North America | usa : United States | usca : California | usw : Western U.S.  IPD 	 Technology  PUB 	 Washington Post ",NA
"Document WP00000020200301eg310004a","	Metro","	NHTSA suspends self-driving shuttles","	Ian Duncan","	978 words","	1 March 2020","	The Washington Post","	WP","	FINAL","	C02",NA,"	English","	Copyright 2020, The Washington Post Co. All Rights Reserved","  The self-driving shuttle had just pulled away from the curb in a Columbus, Ohio, neighborhood and had not even reached 10 mph, but the sudden stop was enough to fling its safety operator across the inside and throw a passenger from her seat.  The seemingly unexplained incident a few weeks ago, captured by onboard cameras, led federal highway safety regulators to take swift action and all but order the vehicles off the road while they launched a review. In a letter to operators using the same kind of shuttle, an official with the National Highway Traffic Safety Administration wrote that continuing to carry passengers ""may present an unacceptable safety risk."" ","  As the footage from the Columbus shuttle begins, the safety operator and two passengers are aboard, chatting with one another about how the shuttle works. In mid-sentence, the operator is thrown from his feet.  ""What the hell,"" he says. ""I don't know what the hell happened.""  The operator starts the shuttle back up to get it out of the road.  ""No, don't move this damn thing it just threw me out of my f---ing seat,"" says one of the passengers. ""Why are we moving?""  The city fire department sent medics, who took the 44-year-old woman to the hospital with minor injuries.  NHTSA said the suspension order affects 16 French-made EasyMile shuttles being used in projects in 10 states.  Two of them are in Virginia: one at the Virginia Tech Transportation Institute and the other in a partnership between Fairfax County and utility Dominion Energy. But neither project is carrying passengers, and officials say they do not expect the NHTSA order to disrupt their plans.  About 100 people die in traffic crashes every day when humans are at the wheel, so the incident in Columbus might have been barely a blip. But NHTSA's sweeping action underscores the continuing uncertainty about how to handle the self-driving vehicles that are being tested on public roads across the country.  The agency has faced repeated criticism in recent months that it is doing too little to set standards and ensure safety, and yet in a case where it did take decisive action, it faced new questions about its motivations.  Jason Levine, the executive director of the Center for Auto Safety, said the decision to halt EasyMile's operations might have been the right move.  But he said the announcement, coming on the same day as a National Transportation Safety Board hearing during which NHTSA was faulted for its oversight of Tesla's partially automated cars, ""smacks of a PR stunt.""  Because of the rules governing how the EasyMile shuttles are imported, NHTSA had the legal authority to suspend operations, according to its letter to operators. The agency took a similar action to rein in another project using an EasyMile shuttle in 2018 that it said was operating an unapproved school bus.  Officials in Columbus are using the shuttles as part of a federally funded test project, one of dozens using low-speed vehicles that are in theory safer than full-size cars or SUVs. Alyssa Chenault, a spokeswoman for the city's smart transportation initiative, said the vehicles began running through a residential area in early February, with the aim of connecting people to social services and regular transit.  Chenault said a team from EasyMile came to Columbus this week to begin an investigation into the cause of the incident. In a statement, the company said the vehicle was traveling at 7.1 mph before it stopped.  The shuttle ""made an emergency stop as it is programmed to do,"" the company said. ""We operate at such low speeds precisely for this reason: our shuttles can make sudden stops when they detect a safety risk.""  But video captured by the cameras on the shuttles' front and back don't show anything in the street at the moment it lurches to a halt - something a NHTSA official noted in the letter to operators.  ""Evaluation of the vehicle's recorded data remains ongoing to identify the underlying cause,"" the official wrote.  The company did not respond to a call or email seeking further comment.  A similar sudden-braking episode in Utah last year left a 76-year-old state employee badly hurt. At the time, a company spokesman told the Deseret News that there was no indication the shuttle had malfunctioned. The vehicle was put back in service.  John Gleason, a spokesman for the Utah Department of Transportation, said no one ever determined what it was that the shuttle detected.  ""There were some theories that it could have been a large insect or something like that,"" he said.  Tom Dingus, the director of the Virginia Tech Transportation Institute, has been leading the university's work involving EasyMile shuttles. Researchers there are interested in public perceptions of autonomous vehicles.  Dingus said people are willing to accept pretty high levels of risk when they are driving themselves, lulled by the feeling of being in control and an overestimation of their own skills. But take that feeling away, Dingus said, and people's tolerance for risk drops precipitously.  ""People are only going to accept fatalities in these systems that are in the range of 100 times lower than manual driving,"" he said.  Virginia Tech had run a simple shuttle service using an EasyMile vehicle last year, but the project ended, so current research will not be affected by NHTSA's order, Dingus said.  The Fairfax County project, which is envisioned as a shuttle between the Mosaic District, a mixed-use property development, and the Dunn Loring Metro station, has yet to launch. Robin Geiger, a spokeswoman for the county transportation department, said no start date has been set and that planning will continue during the suspension.  ian.duncan@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20200301shuttlesuspension0301  CO 	 nathg : National Highway Traffic Safety Administration  IN 	 iadrive : Autonomous Driving Technologies | iaut : Automotive | itech : Technology  NS 	 c26 : Product/Consumer Safety | c13 : Regulation/Government Policy | ccat : Corporate/Industrial News | cexpro : Products/Services | ncat : Content Types | nfact : Factiva Filters | nfcpin : C&E Industry News Filter  RE 	 usa : United States | usoh : Ohio | namz : North America | usc : Midwest U.S.  IPD 	 Development-Transportation  PUB 	 Washington Post ",NA
"Document WP00000020200226eg2q0001i","	A-Section","	NTSB notes tech and driver failures in fatal 2018 Tesla crash","	Michael Laris","	1012 words","	26 February 2020","	The Washington Post","	WP","	FINAL","	A02",NA,"	English","	Copyright 2020, The Washington Post Co. All Rights Reserved","  Both car and driver contributed to the 2018 crash of a Tesla in California that left a father of two dead, and federal regulators have shown a 'lack of leadership' in addressing safety problems with partly automated vehicles, investigators said Tuesday.  The investigation underscored questions about the safety and marketing of Tesla's 'Autopilot' system. ","  Robert L. Sumwalt III, chairman of the National Transportation Safety Board, pointed to a 'lack of system safeguards to prevent foreseeable misuses of technology.'  'Industry keeps implementing technology in such a way that people can get injured or killed,' Sumwalt said. 'If you own a car with partial automation, you do not own a self-driving car. Don't pretend that you do.'  The NTSB also cited 'shortfalls' in how the U.S. Transportation Department has overseen partial automation in cars made by Tesla and other manufacturers. NTSB officials said that although the National Highway Traffic Safety Administration has numerous open investigations into Tesla vehicles, the regulator has been 'misguided, because it essentially relies on waiting for problems to occur rather than addressing safety issues proactively.'  NHTSA said it is reviewing the findings and has long recommended that technology developers use 'appropriate driver-vehicle interaction strategies in deployed technology' and has offered resources to make it easier for them to do so.  The March-23 crash that killed Walter Huang after he dropped off his son at preschool was one of 36,560 road deaths in the United States in 2018.  But it drew broad "" and, to Tesla, unwelcome "" attention to the company and potential problems with the high-end technology that is central to the Silicon Valley electric car pioneer's brand. After the crash, Tesla placed blame on Huang, an Apple engineer, saying 'the only way for this accident to have occurred is if Mr. Huang was not paying attention to the road.'  But days before Huang's Tesla drove off Highway-101 and into a barrier in Mountain View, the car's Autopilot had made a 'left steering movement toward' the same area, the NTSB found. Huang caught it in time, investigators said, and he told relatives the same problem had occurred in the same place multiple times before.  Despite that history, Huang was over-reliant on the Autopilot system, the NTSB found, noting that he used his iPhone-8 while behind the wheel and that a strategy game called 'Three Kingdoms' was 'active during his commute to work.'  The five-member NTSB board on Tuesday unanimously found that the crash was caused by 'system limitations' in Tesla's Autopilot feature, 'and the driver's lack of response due to distraction likely from a cellphone game application and overreliance on the Autopilot partial driving automation system.'  The NTSB also said Tesla's 'ineffective monitoring of driver engagement' "" it gauges the 'torque' a driver puts on the steering wheel as a proxy for whether the person is paying attention while using Autopilot "" also contributed to the crash and 'facilitated the driver's complacency.'  And it said Huang probably would not have been killed if California state transportation officials had repaired a crash 'attenuator' that was supposed to offer protection when a car hits a highway barrier; the attenuator had been struck earlier and was not yet fixed.  Tesla's collision avoidance systems 'were not designed to, and did not, detect the crash attenuator,' so there was no warning to Huang as his car headed toward the barrier and there was no automatic emergency braking, the NTSB said.  The car veered off the road 'due to limitations of the Tesla Autopilot vision system's processing software to accurately maintain the appropriate lane of travel,' the NTSB said. And the company did not address an earlier recommendation that it should restrict use of Autopilot to the particular conditions it is designed to handle, investigators said.  Tesla executives did not respond to questions about the technological problems or what has been done to fix them.  Among its recommendations, the NTSB called on NHTSA to evaluate whether Tesla's partly automated systems 'pose an unreasonable risk to safety' and to use NHTSA's 'applicable enforcement authority to ensure that Tesla Inc. takes corrective action' if they do. It also called on phone and other electronics manufacturers, including Apple, to install a 'lockout mechanism' that would, by default, disable distracting functions when a car is moving, among other measures.  Huang's crash was not the first time a Tesla driver was killed while using Autopilot, nor would it be the last, and NTSB officials voiced frustration because they said sufficient changes had not been made by the company and others.  In 2016, a speeding Tesla driver in Williston, Fla., crashed into a truck that turned in front of him. At the time, Tesla said 'neither Autopilot nor the driver noticed the white side of the tractor-trailer against a brightly lit sky, so the brake was not applied.'  Musk later said that it was 'very likely' a new radar-based braking system would have prevented the crash.  In 2017, NHTSA said it found no defects in the Autopilot system in use at the time of that crash. The regulator's broader federal review of dozens of Autopilot crashes did point to industry-wide challenges.  'Many of the crashes appear to involve driver behavior factors, including traveling too fast for conditions, mode confusion, and distraction,' the investigators wrote. Mode confusion is the idea that it is unclear who is in control, the car or the driver, and occurred 'during attempted Autopilot activations' and 'after inadvertent overrides.'  In 2019, a driver using Autopilot in Delray Beach, Fla., crashed into a tractor-trailer that emerged from a private driveway and slowed in the middle of a highway, blocking the Tesla's path, the NTSB said.  Neither the Tesla driver nor the Autopilot system 'executed evasive maneuvers,' and the car's roof sheared off as it went under the truck, according to the NTSB.  michael.laris@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20200226NTSBtesla0226  CO 	 ntsbd : National Transportation Safety Board | usdot : United States Department of Transportation | teslmi : Tesla, Inc.  IN 	 i351 : Motor Vehicles | i35104 : Alternative Fuel Vehicles | iaut : Automotive  NS 	 gdis : Disasters/Accidents | gcar : Cars | gtacc : Transport Accidents | gcat : Political/General News | glife : Living/Lifestyle | gmmdis : Accidents/Man-made Disasters | gtrans : Transport  RE 	 usa : United States | namz : North America  IPD 	 Development-Transportation  PUB 	 Washington Post ",NA
"Document WP00000020200212eg2c0002p","	A-Section","	Driver: Tesla kept veering in same spot","	Michael Laris","	772 words","	12 February 2020","	The Washington Post","	WP","	FINAL","	A20",NA,"	English","	Copyright 2020, The Washington Post Co. All Rights Reserved","  Four days before Walter Huang's Tesla veered off U.S. 101 in Northern California and into a concrete barrier, killing the father of two, Huang sent a text message describing the car's 'Autopilot' system making a similar error in the same spot, according to documents released Tuesday by federal investigators.  Investigators with the National Transportation Safety Board, using data recorded by Huang's 2017 Tesla Model X, 'confirmed that the Tesla Autosteer system made a left steering movement toward' the area on March 19, 2018. Huang had his hands on the steering wheel at the time and 'made a right corrective steering movement' within one second, according to the NTSB. ","  Huang told relatives that his car had tried to steer off the road multiple times before in the same place, according to NTSB interviews. 'The family explained that it happened so often that he had told both his brother and his wife about the problem,' according to the NTSB.  But on March 23, after Huang dropped his son off at preschool and headed toward the office, he used his iPhone 8 while behind the wheel, according to the NTSB. Recovered phone logs show that a strategy game called 'Three Kingdoms' 'was active during the driver's trip to work,' the NTSB said. Investigators said the log data 'does not provide enough information to ascertain' whether Huang 'was holding the phone or how interactive he was,' though it said 'most players have both hands on the phone to support the device and manipulate game actions.' Huang's data usage was 'consistent' with online game activity 'about the time of the crash,' the NTSB said.  When Huang's Tesla SUV reached the exit ramp area in Mountain View, where he said the problems had previously occurred, the car again steered out of its lane and hit a barrier at about 71 miles per hour, according to the NTSB.  Tesla did not immediately respond Tuesday to questions about the Autopilot flaw Huang described or whether it had been fixed.  During the final minute of the trip, Huang's hands were detected on the steering 'on three separate occasions, for a total of 34 seconds,' the NTSB previously reported. For the six seconds before the crash, 'the vehicle did not detect the driver's hands on the steering wheel.' In its final seconds, the car also sped up from 62-miles per hour, investigators said.  Huang had Autopilot on for the last nearly 19 minutes before the crash, and the system detected that his hands were not on the wheel for 34-percent of that time, according to the newly released NTSB documents. The system gave him two 'visual alerts' and an audible one during that time, the documents say.  Tesla has faced sharp criticism from some lawmakers in Congress and elsewhere for calling its driver assistance features 'Autopilot,' which critics say is a clear overstatement of the system's capabilities that can encourage customers to let their guard down. The features are supposed to keep the car in its lane and apply the brakes in an emergency, but Tesla tells drivers they need to keep their hands on the wheel and stay in control of the vehicle.  Tesla, responding to questions from Sen. Edward J. Markey (D-Mass.) in December, provided data indicating that its customers who use Autopilot are significantly less likely to crash.  'Tesla takes the risk of improper use or abuse of Autopilot very seriously. Making sure the driver is attentive and able to take over at any time is a cornerstone of our feature development and validation, and something we continue to improve through fleet learning, customer feedback, and over-the-air ('OTA') updates,' the company wrote.  Federal investigators on Tuesday also released information on a second deadly crash, in 2019, as a driver used Autopilot in Delray Beach, Fla. In that crash, a tractor trailer drove out from a private driveway and slowed in the middle of a highway, blocking the Tesla's path, federal investigators said.  Neither the Tesla driver, Jeremy Banner, nor the Autopilot system 'executed evasive maneuvers,' and the car's roof sheared off as it drove under the truck, according to the NTSB.  The speed limit was 55-mph. Banner set the 'Traffic Aware Cruise Control,' part of Autopilot, at 69-mph about 12 seconds before the crash, investigators said. He activated 'Autosteer' about 10 seconds before the crash. His hands were not detected on the wheel during final 7.7-seconds before impact, the NTSB said.  michael.laris@washpost.com   CT 	 http://www.washingtonpost.com[http://www.washingtonpost.com]  RF 	 WP20200212NTSBTESLA  CO 	 ntsbd : National Transportation Safety Board  NS 	 gtacc : Transport Accidents | gcat : Political/General News | gdis : Disasters/Accidents | gmmdis : Accidents/Man-made Disasters | gtrans : Transport  RE 	 usa : United States | namz : North America  IPD 	 Local  PUB 	 Washington Post ",NA
